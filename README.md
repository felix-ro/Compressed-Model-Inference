# Compressed Model Inference
In this repo we try to determine the impacts of compression on inference speeds. 

1. Motivational Example
2. ResNet
3. MobileNet
4. BERT
