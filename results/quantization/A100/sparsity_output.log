&&&& RUNNING TensorRT.trtexec [TensorRT v8601] # trtexec --onnx=scripts/quantization/model_qat.onnx --int8 --sparsity=force --saveEngine=scripts/quantization/model_qat.engine --verbose
[01/10/2024-10:50:57] [I] === Model Options ===
[01/10/2024-10:50:57] [I] Format: ONNX
[01/10/2024-10:50:57] [I] Model: scripts/quantization/model_qat.onnx
[01/10/2024-10:50:57] [I] Output:
[01/10/2024-10:50:57] [I] === Build Options ===
[01/10/2024-10:50:57] [I] Max batch: explicit batch
[01/10/2024-10:50:57] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[01/10/2024-10:50:57] [I] minTiming: 1
[01/10/2024-10:50:57] [I] avgTiming: 8
[01/10/2024-10:50:57] [I] Precision: FP32+INT8
[01/10/2024-10:50:57] [I] LayerPrecisions: 
[01/10/2024-10:50:57] [I] Layer Device Types: 
[01/10/2024-10:50:57] [I] Calibration: Dynamic
[01/10/2024-10:50:57] [I] Refit: Disabled
[01/10/2024-10:50:57] [I] Version Compatible: Disabled
[01/10/2024-10:50:57] [I] TensorRT runtime: full
[01/10/2024-10:50:57] [I] Lean DLL Path: 
[01/10/2024-10:50:57] [I] Tempfile Controls: { in_memory: allow, temporary: allow }
[01/10/2024-10:50:57] [I] Exclude Lean Runtime: Disabled
[01/10/2024-10:50:57] [I] Sparsity: Forced
[01/10/2024-10:50:57] [I] Safe mode: Disabled
[01/10/2024-10:50:57] [I] Build DLA standalone loadable: Disabled
[01/10/2024-10:50:57] [I] Allow GPU fallback for DLA: Disabled
[01/10/2024-10:50:57] [I] DirectIO mode: Disabled
[01/10/2024-10:50:57] [I] Restricted mode: Disabled
[01/10/2024-10:50:57] [I] Skip inference: Disabled
[01/10/2024-10:50:57] [I] Save engine: scripts/quantization/model_qat.engine
[01/10/2024-10:50:57] [I] Load engine: 
[01/10/2024-10:50:57] [I] Profiling verbosity: 0
[01/10/2024-10:50:57] [I] Tactic sources: Using default tactic sources
[01/10/2024-10:50:57] [I] timingCacheMode: local
[01/10/2024-10:50:57] [I] timingCacheFile: 
[01/10/2024-10:50:57] [I] Heuristic: Disabled
[01/10/2024-10:50:57] [I] Preview Features: Use default preview flags.
[01/10/2024-10:50:57] [I] MaxAuxStreams: -1
[01/10/2024-10:50:57] [I] BuilderOptimizationLevel: -1
[01/10/2024-10:50:57] [I] Input(s)s format: fp32:CHW
[01/10/2024-10:50:57] [I] Output(s)s format: fp32:CHW
[01/10/2024-10:50:57] [I] Input build shapes: model
[01/10/2024-10:50:57] [I] Input calibration shapes: model
[01/10/2024-10:50:57] [I] === System Options ===
[01/10/2024-10:50:57] [I] Device: 0
[01/10/2024-10:50:57] [I] DLACore: 
[01/10/2024-10:50:57] [I] Plugins:
[01/10/2024-10:50:57] [I] setPluginsToSerialize:
[01/10/2024-10:50:57] [I] dynamicPlugins:
[01/10/2024-10:50:57] [I] ignoreParsedPluginLibs: 0
[01/10/2024-10:50:57] [I] 
[01/10/2024-10:50:57] [I] === Inference Options ===
[01/10/2024-10:50:57] [I] Batch: Explicit
[01/10/2024-10:50:57] [I] Input inference shapes: model
[01/10/2024-10:50:57] [I] Iterations: 10
[01/10/2024-10:50:57] [I] Duration: 3s (+ 200ms warm up)
[01/10/2024-10:50:57] [I] Sleep time: 0ms
[01/10/2024-10:50:57] [I] Idle time: 0ms
[01/10/2024-10:50:57] [I] Inference Streams: 1
[01/10/2024-10:50:57] [I] ExposeDMA: Disabled
[01/10/2024-10:50:57] [I] Data transfers: Enabled
[01/10/2024-10:50:57] [I] Spin-wait: Disabled
[01/10/2024-10:50:57] [I] Multithreading: Disabled
[01/10/2024-10:50:57] [I] CUDA Graph: Disabled
[01/10/2024-10:50:57] [I] Separate profiling: Disabled
[01/10/2024-10:50:57] [I] Time Deserialize: Disabled
[01/10/2024-10:50:57] [I] Time Refit: Disabled
[01/10/2024-10:50:57] [I] NVTX verbosity: 0
[01/10/2024-10:50:57] [I] Persistent Cache Ratio: 0
[01/10/2024-10:50:57] [I] Inputs:
[01/10/2024-10:50:57] [I] === Reporting Options ===
[01/10/2024-10:50:57] [I] Verbose: Enabled
[01/10/2024-10:50:57] [I] Averages: 10 inferences
[01/10/2024-10:50:57] [I] Percentiles: 90,95,99
[01/10/2024-10:50:57] [I] Dump refittable layers:Disabled
[01/10/2024-10:50:57] [I] Dump output: Disabled
[01/10/2024-10:50:57] [I] Profile: Disabled
[01/10/2024-10:50:57] [I] Export timing to JSON file: 
[01/10/2024-10:50:57] [I] Export output to JSON file: 
[01/10/2024-10:50:57] [I] Export profile to JSON file: 
[01/10/2024-10:50:57] [I] 
[01/10/2024-10:50:57] [I] === Device Information ===
[01/10/2024-10:50:57] [I] Selected Device: NVIDIA A100-SXM4-80GB
[01/10/2024-10:50:57] [I] Compute Capability: 8.0
[01/10/2024-10:50:57] [I] SMs: 108
[01/10/2024-10:50:57] [I] Device Global Memory: 81050 MiB
[01/10/2024-10:50:57] [I] Shared Memory per SM: 164 KiB
[01/10/2024-10:50:57] [I] Memory Bus Width: 5120 bits (ECC enabled)
[01/10/2024-10:50:57] [I] Application Compute Clock Rate: 1.41 GHz
[01/10/2024-10:50:57] [I] Application Memory Clock Rate: 1.593 GHz
[01/10/2024-10:50:57] [I] 
[01/10/2024-10:50:57] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.
[01/10/2024-10:50:57] [I] 
[01/10/2024-10:50:57] [I] TensorRT version: 8.6.1
[01/10/2024-10:50:57] [I] Loading standard plugins
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 2
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::ModulatedDeformConv2d version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::Proposal version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::ROIAlign_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::Split version 1
[01/10/2024-10:50:59] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1
[01/10/2024-10:51:00] [I] [TRT] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 20, GPU 428 (MiB)
[01/10/2024-10:51:00] [V] [TRT] Trying to load shared library libnvinfer_builder_resource.so.8.6.1
[01/10/2024-10:51:00] [V] [TRT] Loaded shared library libnvinfer_builder_resource.so.8.6.1
[01/10/2024-10:51:09] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1658, GPU +310, now: CPU 1754, GPU 738 (MiB)
[01/10/2024-10:51:09] [V] [TRT] CUDA lazy loading is enabled.
[01/10/2024-10:51:09] [I] Start parsing network model.
[01/10/2024-10:51:09] [I] [TRT] ----------------------------------------------------------------
[01/10/2024-10:51:09] [I] [TRT] Input filename:   scripts/quantization/model_qat.onnx
[01/10/2024-10:51:09] [I] [TRT] ONNX IR version:  0.0.7
[01/10/2024-10:51:09] [I] [TRT] Opset version:    13
[01/10/2024-10:51:09] [I] [TRT] Producer name:    tf2onnx
[01/10/2024-10:51:09] [I] [TRT] Producer version: 1.10.1 a37f29
[01/10/2024-10:51:09] [I] [TRT] Domain:           
[01/10/2024-10:51:09] [I] [TRT] Model version:    0
[01/10/2024-10:51:09] [I] [TRT] Doc string:       
[01/10/2024-10:51:09] [I] [TRT] ----------------------------------------------------------------
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::CoordConvAC version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::CropAndResizeDynamic version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::DecodeBbox3DPlugin version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::GenerateDetection_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 2
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::ModulatedDeformConv2d version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::NMSDynamic_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::PillarScatterPlugin version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::ProposalDynamic version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::ROIAlign_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::Split version 1
[01/10/2024-10:51:09] [V] [TRT] Plugin creator already registered - ::VoxelGeneratorPlugin version 1
[01/10/2024-10:51:09] [V] [TRT] Adding network input: input_1:0 with dtype: float32, dimensions: (-1, 224, 224, 3)
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: input_1:0 for ONNX tensor: input_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: zero_point__833
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: zero_point__793
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: quant_scale__832
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: quant_scale__804
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: pad_const__1129
[01/10/2024-10:51:09] [W] [TRT] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: pad_const__1120
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: const_axes__1726
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block3_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block3_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block3_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block3_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block3_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block3_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block2_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block2_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block2_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block2_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block2_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block2_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block6_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block6_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block6_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block6_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block6_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block6_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block5_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block5_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block5_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block5_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block5_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block5_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block4_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block4_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block4_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block4_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block4_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block4_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block3_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block3_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block3_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block3_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block3_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block3_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block2_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block2_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block2_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block2_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block2_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block2_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block4_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block4_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block4_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block4_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block4_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block4_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block3_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block3_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block3_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block3_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block3_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block3_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block2_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block2_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block2_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block2_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block2_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block2_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block3_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block3_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block3_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block3_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block3_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block3_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block2_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block2_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block2_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block2_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block2_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block2_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_0_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Importing initializer: StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv1_pad/Pad [Pad]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: input_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: pad_const__1120
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv1_pad/Pad [Pad] inputs: [input_1:0 -> (-1, 224, 224, 3)[FLOAT]], [pad_const__1120 -> (8)[INT32]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv1_pad/Pad for ONNX node: StatefulPartitionedCall/resnet50/conv1_pad/Pad
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv1_pad/Pad:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv1_pad/Pad:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv1_pad/Pad [Pad] outputs: [StatefulPartitionedCall/resnet50/conv1_pad/Pad:0 -> (-1, 230, 230, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__838 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv1_pad/Pad:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__838 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv1_pad/Pad:0 -> (-1, 230, 230, 3)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: quant_scale__1064 for ONNX node: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Registering layer: zero_point__965 for ONNX node: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__838:0 for ONNX tensor: QuantLinearNode__838:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__838 [QuantizeLinear] outputs: [QuantLinearNode__838:0 -> (-1, 230, 230, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__834 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__832
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__833
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__834 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (2048, 1000)[FLOAT]], [quant_scale__832 -> (1000)[FLOAT]], [zero_point__833 -> (1000)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering layer: quant_scale__832 for ONNX node: quant_scale__832
[01/10/2024-10:51:09] [V] [TRT] Registering layer: zero_point__833 for ONNX node: zero_point__833
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__834:0 for ONNX tensor: QuantLinearNode__834:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__834 [QuantizeLinear] outputs: [QuantLinearNode__834:0 -> (2048, 1000)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__830 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__804
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__793
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__830 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (2048, 512, 1, 1)[FLOAT]], [quant_scale__804 -> (2048)[FLOAT]], [zero_point__793 -> (2048)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering layer: quant_scale__804 for ONNX node: quant_scale__804
[01/10/2024-10:51:09] [V] [TRT] Registering layer: zero_point__793 for ONNX node: zero_point__793
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__830:0 for ONNX tensor: QuantLinearNode__830:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__830 [QuantizeLinear] outputs: [QuantLinearNode__830:0 -> (2048, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__826 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__826 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (512, 512, 3, 3)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering layer: quant_scale__688 for ONNX node: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Registering layer: zero_point__821 for ONNX node: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__826:0 for ONNX tensor: QuantLinearNode__826:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__826 [QuantizeLinear] outputs: [QuantLinearNode__826:0 -> (512, 512, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__822 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__822 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (512, 2048, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__822:0 for ONNX tensor: QuantLinearNode__822:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__822 [QuantizeLinear] outputs: [QuantLinearNode__822:0 -> (512, 2048, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__818 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__804
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__793
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__818 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (2048, 512, 1, 1)[FLOAT]], [quant_scale__804 -> (2048)[FLOAT]], [zero_point__793 -> (2048)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__818:0 for ONNX tensor: QuantLinearNode__818:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__818 [QuantizeLinear] outputs: [QuantLinearNode__818:0 -> (2048, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__814 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__814 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (512, 512, 3, 3)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__814:0 for ONNX tensor: QuantLinearNode__814:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__814 [QuantizeLinear] outputs: [QuantLinearNode__814:0 -> (512, 512, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__810 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__810 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (512, 2048, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__810:0 for ONNX tensor: QuantLinearNode__810:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__810 [QuantizeLinear] outputs: [QuantLinearNode__810:0 -> (512, 2048, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__806 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__804
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__793
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__806 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (2048, 512, 1, 1)[FLOAT]], [quant_scale__804 -> (2048)[FLOAT]], [zero_point__793 -> (2048)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__806:0 for ONNX tensor: QuantLinearNode__806:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__806 [QuantizeLinear] outputs: [QuantLinearNode__806:0 -> (2048, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__802 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__802 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (512, 512, 3, 3)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__802:0 for ONNX tensor: QuantLinearNode__802:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__802 [QuantizeLinear] outputs: [QuantLinearNode__802:0 -> (512, 512, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__798 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__798 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (512, 1024, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__798:0 for ONNX tensor: QuantLinearNode__798:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__798 [QuantizeLinear] outputs: [QuantLinearNode__798:0 -> (512, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__794 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__804
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__793
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__794 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (2048, 1024, 1, 1)[FLOAT]], [quant_scale__804 -> (2048)[FLOAT]], [zero_point__793 -> (2048)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__794:0 for ONNX tensor: QuantLinearNode__794:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__794 [QuantizeLinear] outputs: [QuantLinearNode__794:0 -> (2048, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__790 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__790 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (1024, 256, 1, 1)[FLOAT]], [quant_scale__776 -> (1024)[FLOAT]], [zero_point__741 -> (1024)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering layer: quant_scale__776 for ONNX node: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Registering layer: zero_point__741 for ONNX node: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__790:0 for ONNX tensor: QuantLinearNode__790:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__790 [QuantizeLinear] outputs: [QuantLinearNode__790:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__786 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__786 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 256, 3, 3)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering layer: quant_scale__772 for ONNX node: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Registering layer: zero_point__737 for ONNX node: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__786:0 for ONNX tensor: QuantLinearNode__786:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__786 [QuantizeLinear] outputs: [QuantLinearNode__786:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__782 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__782 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 1024, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__782:0 for ONNX tensor: QuantLinearNode__782:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__782 [QuantizeLinear] outputs: [QuantLinearNode__782:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__778 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__778 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (1024, 256, 1, 1)[FLOAT]], [quant_scale__776 -> (1024)[FLOAT]], [zero_point__741 -> (1024)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__778:0 for ONNX tensor: QuantLinearNode__778:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__778 [QuantizeLinear] outputs: [QuantLinearNode__778:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__774 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__774 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 256, 3, 3)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__774:0 for ONNX tensor: QuantLinearNode__774:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__774 [QuantizeLinear] outputs: [QuantLinearNode__774:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__770 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__770 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 1024, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__770:0 for ONNX tensor: QuantLinearNode__770:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__770 [QuantizeLinear] outputs: [QuantLinearNode__770:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__766 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__766 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (1024, 256, 1, 1)[FLOAT]], [quant_scale__776 -> (1024)[FLOAT]], [zero_point__741 -> (1024)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__766:0 for ONNX tensor: QuantLinearNode__766:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__766 [QuantizeLinear] outputs: [QuantLinearNode__766:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__762 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__762 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 256, 3, 3)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__762:0 for ONNX tensor: QuantLinearNode__762:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__762 [QuantizeLinear] outputs: [QuantLinearNode__762:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__758 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__758 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 1024, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__758:0 for ONNX tensor: QuantLinearNode__758:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__758 [QuantizeLinear] outputs: [QuantLinearNode__758:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__754 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__754 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (1024, 256, 1, 1)[FLOAT]], [quant_scale__776 -> (1024)[FLOAT]], [zero_point__741 -> (1024)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__754:0 for ONNX tensor: QuantLinearNode__754:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__754 [QuantizeLinear] outputs: [QuantLinearNode__754:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__750 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__750 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 256, 3, 3)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__750:0 for ONNX tensor: QuantLinearNode__750:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__750 [QuantizeLinear] outputs: [QuantLinearNode__750:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__746 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__746 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 1024, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__746:0 for ONNX tensor: QuantLinearNode__746:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__746 [QuantizeLinear] outputs: [QuantLinearNode__746:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__742 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__742 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (1024, 256, 1, 1)[FLOAT]], [quant_scale__776 -> (1024)[FLOAT]], [zero_point__741 -> (1024)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__742:0 for ONNX tensor: QuantLinearNode__742:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__742 [QuantizeLinear] outputs: [QuantLinearNode__742:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__738 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__738 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 256, 3, 3)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__738:0 for ONNX tensor: QuantLinearNode__738:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__738 [QuantizeLinear] outputs: [QuantLinearNode__738:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__734 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__734 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 1024, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__734:0 for ONNX tensor: QuantLinearNode__734:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__734 [QuantizeLinear] outputs: [QuantLinearNode__734:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__730 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__730 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (1024, 256, 1, 1)[FLOAT]], [quant_scale__776 -> (1024)[FLOAT]], [zero_point__741 -> (1024)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__730:0 for ONNX tensor: QuantLinearNode__730:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__730 [QuantizeLinear] outputs: [QuantLinearNode__730:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__726 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__726 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 256, 3, 3)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__726:0 for ONNX tensor: QuantLinearNode__726:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__726 [QuantizeLinear] outputs: [QuantLinearNode__726:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__722 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__722 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 512, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__722:0 for ONNX tensor: QuantLinearNode__722:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__722 [QuantizeLinear] outputs: [QuantLinearNode__722:0 -> (256, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__718 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__718 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (1024, 512, 1, 1)[FLOAT]], [quant_scale__776 -> (1024)[FLOAT]], [zero_point__741 -> (1024)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__718:0 for ONNX tensor: QuantLinearNode__718:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__718 [QuantizeLinear] outputs: [QuantLinearNode__718:0 -> (1024, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__714 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__714 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (512, 128, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__714:0 for ONNX tensor: QuantLinearNode__714:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__714 [QuantizeLinear] outputs: [QuantLinearNode__714:0 -> (512, 128, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__710 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__710 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (128, 128, 3, 3)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering layer: quant_scale__684 for ONNX node: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Registering layer: zero_point__705 for ONNX node: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__710:0 for ONNX tensor: QuantLinearNode__710:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__710 [QuantizeLinear] outputs: [QuantLinearNode__710:0 -> (128, 128, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__706 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__706 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (128, 512, 1, 1)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__706:0 for ONNX tensor: QuantLinearNode__706:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__706 [QuantizeLinear] outputs: [QuantLinearNode__706:0 -> (128, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__702 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__702 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (512, 128, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__702:0 for ONNX tensor: QuantLinearNode__702:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__702 [QuantizeLinear] outputs: [QuantLinearNode__702:0 -> (512, 128, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__698 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__698 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (128, 128, 3, 3)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__698:0 for ONNX tensor: QuantLinearNode__698:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__698 [QuantizeLinear] outputs: [QuantLinearNode__698:0 -> (128, 128, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__694 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__694 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (128, 512, 1, 1)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__694:0 for ONNX tensor: QuantLinearNode__694:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__694 [QuantizeLinear] outputs: [QuantLinearNode__694:0 -> (128, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__690 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__690 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (512, 128, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__690:0 for ONNX tensor: QuantLinearNode__690:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__690 [QuantizeLinear] outputs: [QuantLinearNode__690:0 -> (512, 128, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__686 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__686 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (128, 128, 3, 3)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__686:0 for ONNX tensor: QuantLinearNode__686:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__686 [QuantizeLinear] outputs: [QuantLinearNode__686:0 -> (128, 128, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__682 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__682 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (128, 512, 1, 1)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__682:0 for ONNX tensor: QuantLinearNode__682:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__682 [QuantizeLinear] outputs: [QuantLinearNode__682:0 -> (128, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__678 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__678 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (512, 128, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__678:0 for ONNX tensor: QuantLinearNode__678:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__678 [QuantizeLinear] outputs: [QuantLinearNode__678:0 -> (512, 128, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__674 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__674 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (128, 128, 3, 3)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__674:0 for ONNX tensor: QuantLinearNode__674:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__674 [QuantizeLinear] outputs: [QuantLinearNode__674:0 -> (128, 128, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__670 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__670 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (128, 256, 1, 1)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__670:0 for ONNX tensor: QuantLinearNode__670:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__670 [QuantizeLinear] outputs: [QuantLinearNode__670:0 -> (128, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__666 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__666 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (512, 256, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__666:0 for ONNX tensor: QuantLinearNode__666:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__666 [QuantizeLinear] outputs: [QuantLinearNode__666:0 -> (512, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__662 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__662 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 64, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__662:0 for ONNX tensor: QuantLinearNode__662:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__662 [QuantizeLinear] outputs: [QuantLinearNode__662:0 -> (256, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__658 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__658 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (64, 64, 3, 3)[FLOAT]], [quant_scale__644 -> (64)[FLOAT]], [zero_point__653 -> (64)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering layer: quant_scale__644 for ONNX node: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Registering layer: zero_point__653 for ONNX node: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__658:0 for ONNX tensor: QuantLinearNode__658:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__658 [QuantizeLinear] outputs: [QuantLinearNode__658:0 -> (64, 64, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__654 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__654 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (64, 256, 1, 1)[FLOAT]], [quant_scale__644 -> (64)[FLOAT]], [zero_point__653 -> (64)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__654:0 for ONNX tensor: QuantLinearNode__654:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__654 [QuantizeLinear] outputs: [QuantLinearNode__654:0 -> (64, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__650 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__650 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 64, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__650:0 for ONNX tensor: QuantLinearNode__650:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__650 [QuantizeLinear] outputs: [QuantLinearNode__650:0 -> (256, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__646 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__646 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (64, 64, 3, 3)[FLOAT]], [quant_scale__644 -> (64)[FLOAT]], [zero_point__653 -> (64)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__646:0 for ONNX tensor: QuantLinearNode__646:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__646 [QuantizeLinear] outputs: [QuantLinearNode__646:0 -> (64, 64, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__642 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__642 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (64, 256, 1, 1)[FLOAT]], [quant_scale__644 -> (64)[FLOAT]], [zero_point__653 -> (64)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__642:0 for ONNX tensor: QuantLinearNode__642:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__642 [QuantizeLinear] outputs: [QuantLinearNode__642:0 -> (64, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__638 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__638 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 64, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__638:0 for ONNX tensor: QuantLinearNode__638:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__638 [QuantizeLinear] outputs: [QuantLinearNode__638:0 -> (256, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__634 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__634 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (64, 64, 3, 3)[FLOAT]], [quant_scale__644 -> (64)[FLOAT]], [zero_point__653 -> (64)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__634:0 for ONNX tensor: QuantLinearNode__634:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__634 [QuantizeLinear] outputs: [QuantLinearNode__634:0 -> (64, 64, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__630 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__630 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (64, 64, 1, 1)[FLOAT]], [quant_scale__644 -> (64)[FLOAT]], [zero_point__653 -> (64)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__630:0 for ONNX tensor: QuantLinearNode__630:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__630 [QuantizeLinear] outputs: [QuantLinearNode__630:0 -> (64, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__626 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__626 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (256, 64, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__626:0 for ONNX tensor: QuantLinearNode__626:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__626 [QuantizeLinear] outputs: [QuantLinearNode__626:0 -> (256, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__622 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__622 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 -> (64, 3, 7, 7)[FLOAT]], [quant_scale__644 -> (64)[FLOAT]], [zero_point__653 -> (64)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__622:0 for ONNX tensor: QuantLinearNode__622:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__622 [QuantizeLinear] outputs: [QuantLinearNode__622:0 -> (64, 3, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__839 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__838:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__839 [DequantizeLinear] inputs: [QuantLinearNode__838:0 -> (-1, 230, 230, 3)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__839 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 230, 230, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121 [Transpose]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121 [Transpose] inputs: [StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 230, 230, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121 for ONNX node: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121 [Transpose] outputs: [StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121:0 -> (-1, 3, 230, 230)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__835 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__834:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__832
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__833
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__835 [DequantizeLinear] inputs: [QuantLinearNode__834:0 -> (2048, 1000)[FLOAT]], [quant_scale__832 -> (1000)[FLOAT]], [zero_point__833 -> (1000)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__835 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4:0 -> (2048, 1000)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__831 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__830:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__804
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__793
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__831 [DequantizeLinear] inputs: [QuantLinearNode__830:0 -> (2048, 512, 1, 1)[FLOAT]], [quant_scale__804 -> (2048)[FLOAT]], [zero_point__793 -> (2048)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__831 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (2048, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__827 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__826:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__827 [DequantizeLinear] inputs: [QuantLinearNode__826:0 -> (512, 512, 3, 3)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__827 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 512, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__823 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__822:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__823 [DequantizeLinear] inputs: [QuantLinearNode__822:0 -> (512, 2048, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__823 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 2048, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__819 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__818:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__804
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__793
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__819 [DequantizeLinear] inputs: [QuantLinearNode__818:0 -> (2048, 512, 1, 1)[FLOAT]], [quant_scale__804 -> (2048)[FLOAT]], [zero_point__793 -> (2048)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__819 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (2048, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__815 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__814:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__815 [DequantizeLinear] inputs: [QuantLinearNode__814:0 -> (512, 512, 3, 3)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__815 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 512, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__811 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__810:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__811 [DequantizeLinear] inputs: [QuantLinearNode__810:0 -> (512, 2048, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__811 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 2048, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__807 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__806:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__804
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__793
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__807 [DequantizeLinear] inputs: [QuantLinearNode__806:0 -> (2048, 512, 1, 1)[FLOAT]], [quant_scale__804 -> (2048)[FLOAT]], [zero_point__793 -> (2048)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__807 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (2048, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__803 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__802:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__803 [DequantizeLinear] inputs: [QuantLinearNode__802:0 -> (512, 512, 3, 3)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__803 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 512, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__799 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__798:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__799 [DequantizeLinear] inputs: [QuantLinearNode__798:0 -> (512, 1024, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__799 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__795 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__794:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__804
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__793
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__795 [DequantizeLinear] inputs: [QuantLinearNode__794:0 -> (2048, 1024, 1, 1)[FLOAT]], [quant_scale__804 -> (2048)[FLOAT]], [zero_point__793 -> (2048)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__795 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (2048, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__791 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__790:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__791 [DequantizeLinear] inputs: [QuantLinearNode__790:0 -> (1024, 256, 1, 1)[FLOAT]], [quant_scale__776 -> (1024)[FLOAT]], [zero_point__741 -> (1024)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__791 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__787 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__786:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__787 [DequantizeLinear] inputs: [QuantLinearNode__786:0 -> (256, 256, 3, 3)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__787 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__783 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__782:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__783 [DequantizeLinear] inputs: [QuantLinearNode__782:0 -> (256, 1024, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__783 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__779 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__778:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__779 [DequantizeLinear] inputs: [QuantLinearNode__778:0 -> (1024, 256, 1, 1)[FLOAT]], [quant_scale__776 -> (1024)[FLOAT]], [zero_point__741 -> (1024)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__779 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__775 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__774:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__775 [DequantizeLinear] inputs: [QuantLinearNode__774:0 -> (256, 256, 3, 3)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__775 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__771 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__770:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__771 [DequantizeLinear] inputs: [QuantLinearNode__770:0 -> (256, 1024, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__771 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__767 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__766:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__767 [DequantizeLinear] inputs: [QuantLinearNode__766:0 -> (1024, 256, 1, 1)[FLOAT]], [quant_scale__776 -> (1024)[FLOAT]], [zero_point__741 -> (1024)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__767 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__763 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__762:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__763 [DequantizeLinear] inputs: [QuantLinearNode__762:0 -> (256, 256, 3, 3)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__763 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__759 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__758:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__759 [DequantizeLinear] inputs: [QuantLinearNode__758:0 -> (256, 1024, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__759 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__755 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__754:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__755 [DequantizeLinear] inputs: [QuantLinearNode__754:0 -> (1024, 256, 1, 1)[FLOAT]], [quant_scale__776 -> (1024)[FLOAT]], [zero_point__741 -> (1024)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__755 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__751 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__750:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__751 [DequantizeLinear] inputs: [QuantLinearNode__750:0 -> (256, 256, 3, 3)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__751 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__747 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__746:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__747 [DequantizeLinear] inputs: [QuantLinearNode__746:0 -> (256, 1024, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__747 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__743 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__742:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__743 [DequantizeLinear] inputs: [QuantLinearNode__742:0 -> (1024, 256, 1, 1)[FLOAT]], [quant_scale__776 -> (1024)[FLOAT]], [zero_point__741 -> (1024)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__743 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__739 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__738:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__739 [DequantizeLinear] inputs: [QuantLinearNode__738:0 -> (256, 256, 3, 3)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__739 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__735 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__734:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__735 [DequantizeLinear] inputs: [QuantLinearNode__734:0 -> (256, 1024, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__735 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__731 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__730:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__731 [DequantizeLinear] inputs: [QuantLinearNode__730:0 -> (1024, 256, 1, 1)[FLOAT]], [quant_scale__776 -> (1024)[FLOAT]], [zero_point__741 -> (1024)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__731 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__727 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__726:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__727 [DequantizeLinear] inputs: [QuantLinearNode__726:0 -> (256, 256, 3, 3)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__727 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__723 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__722:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__723 [DequantizeLinear] inputs: [QuantLinearNode__722:0 -> (256, 512, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__723 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__719 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__718:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__776
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__741
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__719 [DequantizeLinear] inputs: [QuantLinearNode__718:0 -> (1024, 512, 1, 1)[FLOAT]], [quant_scale__776 -> (1024)[FLOAT]], [zero_point__741 -> (1024)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__719 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (1024, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__715 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__714:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__715 [DequantizeLinear] inputs: [QuantLinearNode__714:0 -> (512, 128, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__715 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 128, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__711 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__710:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__711 [DequantizeLinear] inputs: [QuantLinearNode__710:0 -> (128, 128, 3, 3)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__711 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 128, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__707 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__706:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__707 [DequantizeLinear] inputs: [QuantLinearNode__706:0 -> (128, 512, 1, 1)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__707 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__703 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__702:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__703 [DequantizeLinear] inputs: [QuantLinearNode__702:0 -> (512, 128, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__703 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 128, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__699 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__698:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__699 [DequantizeLinear] inputs: [QuantLinearNode__698:0 -> (128, 128, 3, 3)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__699 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 128, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__695 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__694:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__695 [DequantizeLinear] inputs: [QuantLinearNode__694:0 -> (128, 512, 1, 1)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__695 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__691 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__690:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__691 [DequantizeLinear] inputs: [QuantLinearNode__690:0 -> (512, 128, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__691 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 128, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__687 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__686:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__687 [DequantizeLinear] inputs: [QuantLinearNode__686:0 -> (128, 128, 3, 3)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__687 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 128, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__683 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__682:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__683 [DequantizeLinear] inputs: [QuantLinearNode__682:0 -> (128, 512, 1, 1)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__683 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__679 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__678:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__679 [DequantizeLinear] inputs: [QuantLinearNode__678:0 -> (512, 128, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__679 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 128, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__675 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__674:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__675 [DequantizeLinear] inputs: [QuantLinearNode__674:0 -> (128, 128, 3, 3)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__675 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 128, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__671 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__670:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__684
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__705
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__671 [DequantizeLinear] inputs: [QuantLinearNode__670:0 -> (128, 256, 1, 1)[FLOAT]], [quant_scale__684 -> (128)[FLOAT]], [zero_point__705 -> (128)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__671 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__667 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__666:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__688
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__821
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__667 [DequantizeLinear] inputs: [QuantLinearNode__666:0 -> (512, 256, 1, 1)[FLOAT]], [quant_scale__688 -> (512)[FLOAT]], [zero_point__821 -> (512)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__667 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__663 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__662:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__663 [DequantizeLinear] inputs: [QuantLinearNode__662:0 -> (256, 64, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__663 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__659 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__658:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__659 [DequantizeLinear] inputs: [QuantLinearNode__658:0 -> (64, 64, 3, 3)[FLOAT]], [quant_scale__644 -> (64)[FLOAT]], [zero_point__653 -> (64)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__659 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (64, 64, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__655 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__654:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__655 [DequantizeLinear] inputs: [QuantLinearNode__654:0 -> (64, 256, 1, 1)[FLOAT]], [quant_scale__644 -> (64)[FLOAT]], [zero_point__653 -> (64)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__655 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (64, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__651 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__650:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__651 [DequantizeLinear] inputs: [QuantLinearNode__650:0 -> (256, 64, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__651 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__647 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__646:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__647 [DequantizeLinear] inputs: [QuantLinearNode__646:0 -> (64, 64, 3, 3)[FLOAT]], [quant_scale__644 -> (64)[FLOAT]], [zero_point__653 -> (64)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__647 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (64, 64, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__643 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__642:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__643 [DequantizeLinear] inputs: [QuantLinearNode__642:0 -> (64, 256, 1, 1)[FLOAT]], [quant_scale__644 -> (64)[FLOAT]], [zero_point__653 -> (64)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__643 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (64, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__639 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__638:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__639 [DequantizeLinear] inputs: [QuantLinearNode__638:0 -> (256, 64, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__639 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__635 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__634:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__635 [DequantizeLinear] inputs: [QuantLinearNode__634:0 -> (64, 64, 3, 3)[FLOAT]], [quant_scale__644 -> (64)[FLOAT]], [zero_point__653 -> (64)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__635 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (64, 64, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__631 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__630:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__631 [DequantizeLinear] inputs: [QuantLinearNode__630:0 -> (64, 64, 1, 1)[FLOAT]], [quant_scale__644 -> (64)[FLOAT]], [zero_point__653 -> (64)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__631 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (64, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__627 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__626:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__772
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__737
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__627 [DequantizeLinear] inputs: [QuantLinearNode__626:0 -> (256, 64, 1, 1)[FLOAT]], [quant_scale__772 -> (256)[FLOAT]], [zero_point__737 -> (256)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__627 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__623 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__622:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__644
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__653
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__623 [DequantizeLinear] inputs: [QuantLinearNode__622:0 -> (64, 3, 7, 7)[FLOAT]], [quant_scale__644 -> (64)[FLOAT]], [zero_point__653 -> (64)[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__623 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (64, 3, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121:0 -> (-1, 3, 230, 230)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (64, 3, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd/ReadVariableOp:0 -> (64)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd for ONNX node: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd:0 -> (-1, 64, 112, 112)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd:0 -> (-1, 64, 112, 112)[FLOAT]], [StatefulPartitionedCall/resnet50/conv1_bn/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv1_bn/ReadVariableOp_1:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (64)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3:0 -> (-1, 64, 112, 112)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3:0 -> (-1, 64, 112, 112)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv1_relu/Relu:0 -> (-1, 64, 112, 112)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/pool1_pad/Pad [Pad]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: pad_const__1129
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/pool1_pad/Pad [Pad] inputs: [StatefulPartitionedCall/resnet50/conv1_relu/Relu:0 -> (-1, 64, 112, 112)[FLOAT]], [pad_const__1129 -> (8)[INT32]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/pool1_pad/Pad for ONNX node: StatefulPartitionedCall/resnet50/pool1_pad/Pad
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/pool1_pad/Pad:0 for ONNX tensor: StatefulPartitionedCall/resnet50/pool1_pad/Pad:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/pool1_pad/Pad [Pad] outputs: [StatefulPartitionedCall/resnet50/pool1_pad/Pad:0 -> (-1, 64, 114, 114)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/pool1_pool/MaxPool [MaxPool]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/pool1_pad/Pad:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/pool1_pool/MaxPool [MaxPool] inputs: [StatefulPartitionedCall/resnet50/pool1_pad/Pad:0 -> (-1, 64, 114, 114)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/pool1_pool/MaxPool for ONNX node: StatefulPartitionedCall/resnet50/pool1_pool/MaxPool
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/pool1_pool/MaxPool:0 for ONNX tensor: StatefulPartitionedCall/resnet50/pool1_pool/MaxPool:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/pool1_pool/MaxPool [MaxPool] outputs: [StatefulPartitionedCall/resnet50/pool1_pool/MaxPool:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__846 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/pool1_pool/MaxPool:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__846 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/pool1_pool/MaxPool:0 -> (-1, 64, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__846:0 for ONNX tensor: QuantLinearNode__846:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__846 [QuantizeLinear] outputs: [QuantLinearNode__846:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__847 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__846:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__847 [DequantizeLinear] inputs: [QuantLinearNode__846:0 -> (-1, 64, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__847 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (64, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D:0 -> (-1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_1_bn/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_1_bn/ReadVariableOp_1:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (64)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block1_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block1_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block1_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv2_block1_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block1_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block1_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block1_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv2_block1_1_relu/Relu:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__850 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__850 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv2_block1_1_relu/Relu:0 -> (-1, 64, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__850:0 for ONNX tensor: QuantLinearNode__850:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__850 [QuantizeLinear] outputs: [QuantLinearNode__850:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__851 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__850:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__851 [DequantizeLinear] inputs: [QuantLinearNode__850:0 -> (-1, 64, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__851 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (64, 64, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D:0 -> (-1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_2_bn/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_2_bn/ReadVariableOp_1:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (64)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block1_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block1_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block1_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv2_block1_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block1_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block1_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block1_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv2_block1_2_relu/Relu:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__854 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__854 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv2_block1_2_relu/Relu:0 -> (-1, 64, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__854:0 for ONNX tensor: QuantLinearNode__854:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__854 [QuantizeLinear] outputs: [QuantLinearNode__854:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__855 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__854:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__855 [DequantizeLinear] inputs: [QuantLinearNode__854:0 -> (-1, 64, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__855 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D:0 -> (-1, 256, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_3_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_3_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__858 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__858 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3:0 -> (-1, 256, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__858:0 for ONNX tensor: QuantLinearNode__858:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__858 [QuantizeLinear] outputs: [QuantLinearNode__858:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__859 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__858:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__859 [DequantizeLinear] inputs: [QuantLinearNode__858:0 -> (-1, 256, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__859 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_0_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D:0 -> (-1, 256, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_0_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_3_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3:0 -> (-1, 256, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv2_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block1_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block1_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block1_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv2_block1_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block1_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block1_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block1_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv2_block1_out/Relu:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__862 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block1_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__862 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv2_block1_out/Relu:0 -> (-1, 256, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__862:0 for ONNX tensor: QuantLinearNode__862:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__862 [QuantizeLinear] outputs: [QuantLinearNode__862:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__867 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__862:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__867 [DequantizeLinear] inputs: [QuantLinearNode__862:0 -> (-1, 256, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__867 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (64, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D:0 -> (-1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block2_1_bn/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block2_1_bn/ReadVariableOp_1:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (64)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block2_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block2_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block2_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv2_block2_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block2_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block2_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block2_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv2_block2_1_relu/Relu:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__870 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__870 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv2_block2_1_relu/Relu:0 -> (-1, 64, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__870:0 for ONNX tensor: QuantLinearNode__870:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__870 [QuantizeLinear] outputs: [QuantLinearNode__870:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__871 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__870:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__871 [DequantizeLinear] inputs: [QuantLinearNode__870:0 -> (-1, 64, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__871 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (64, 64, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D:0 -> (-1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block2_2_bn/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block2_2_bn/ReadVariableOp_1:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (64)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block2_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block2_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block2_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv2_block2_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block2_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block2_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block2_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv2_block2_2_relu/Relu:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__874 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__874 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv2_block2_2_relu/Relu:0 -> (-1, 64, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__874:0 for ONNX tensor: QuantLinearNode__874:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__874 [QuantizeLinear] outputs: [QuantLinearNode__874:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__875 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__874:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__875 [DequantizeLinear] inputs: [QuantLinearNode__874:0 -> (-1, 64, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__875 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D:0 -> (-1, 256, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block2_3_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block2_3_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block2_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block2_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block2_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv2_block2_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block2_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block2_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block2_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv2_block2_out/Relu:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__882 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block2_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__882 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv2_block2_out/Relu:0 -> (-1, 256, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__882:0 for ONNX tensor: QuantLinearNode__882:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__882 [QuantizeLinear] outputs: [QuantLinearNode__882:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__879 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__882:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__879 [DequantizeLinear] inputs: [QuantLinearNode__882:0 -> (-1, 256, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__879 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 256, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (64, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D:0 -> (-1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block3_1_bn/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block3_1_bn/ReadVariableOp_1:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (64)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block3_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block3_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block3_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv2_block3_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block3_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block3_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block3_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv2_block3_1_relu/Relu:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__886 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__886 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv2_block3_1_relu/Relu:0 -> (-1, 64, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__886:0 for ONNX tensor: QuantLinearNode__886:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__886 [QuantizeLinear] outputs: [QuantLinearNode__886:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__887 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__886:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__887 [DequantizeLinear] inputs: [QuantLinearNode__886:0 -> (-1, 64, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__887 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (64, 64, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D:0 -> (-1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block3_2_bn/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block3_2_bn/ReadVariableOp_1:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (64)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block3_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block3_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block3_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv2_block3_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block3_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block3_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block3_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv2_block3_2_relu/Relu:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__890 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__890 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv2_block3_2_relu/Relu:0 -> (-1, 64, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__890:0 for ONNX tensor: QuantLinearNode__890:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__890 [QuantizeLinear] outputs: [QuantLinearNode__890:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__891 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__890:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__891 [DequantizeLinear] inputs: [QuantLinearNode__890:0 -> (-1, 64, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__891 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 64, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D:0 -> (-1, 256, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block3_3_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block3_3_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 256, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv2_block3_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block3_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv2_block3_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv2_block3_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv2_block3_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv2_block3_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv2_block3_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv2_block3_out/Relu:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__898 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv2_block3_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__898 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv2_block3_out/Relu:0 -> (-1, 256, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__898:0 for ONNX tensor: QuantLinearNode__898:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__898 [QuantizeLinear] outputs: [QuantLinearNode__898:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__899 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__898:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__899 [DequantizeLinear] inputs: [QuantLinearNode__898:0 -> (-1, 256, 56, 56)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__899 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 56, 56)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_1_bn/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_1_bn/ReadVariableOp_1:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (128)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block1_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block1_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block1_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv3_block1_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block1_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block1_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block1_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv3_block1_1_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__902 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__902 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv3_block1_1_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__902:0 for ONNX tensor: QuantLinearNode__902:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__902 [QuantizeLinear] outputs: [QuantLinearNode__902:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__903 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__902:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__903 [DequantizeLinear] inputs: [QuantLinearNode__902:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__903 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 128, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_2_bn/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_2_bn/ReadVariableOp_1:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (128)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block1_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block1_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block1_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv3_block1_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block1_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block1_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block1_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv3_block1_2_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__906 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__906 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv3_block1_2_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__906:0 for ONNX tensor: QuantLinearNode__906:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__906 [QuantizeLinear] outputs: [QuantLinearNode__906:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__907 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__906:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__907 [DequantizeLinear] inputs: [QuantLinearNode__906:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__907 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 128, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D:0 -> (-1, 512, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_3_bn/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_0_bn/ReadVariableOp_1:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (512)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__910 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__910 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3:0 -> (-1, 512, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__910:0 for ONNX tensor: QuantLinearNode__910:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__910 [QuantizeLinear] outputs: [QuantLinearNode__910:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__911 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__910:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__911 [DequantizeLinear] inputs: [QuantLinearNode__910:0 -> (-1, 512, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__911 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 56, 56)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D:0 -> (-1, 512, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_0_bn/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_0_bn/ReadVariableOp_1:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (512)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3:0 -> (-1, 512, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv3_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block1_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block1_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block1_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv3_block1_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block1_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block1_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block1_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv3_block1_out/Relu:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__918 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block1_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__918 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv3_block1_out/Relu:0 -> (-1, 512, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__918:0 for ONNX tensor: QuantLinearNode__918:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__918 [QuantizeLinear] outputs: [QuantLinearNode__918:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__915 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__918:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__915 [DequantizeLinear] inputs: [QuantLinearNode__918:0 -> (-1, 512, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_add/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__915 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block2_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 512, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block2_1_bn/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block2_1_bn/ReadVariableOp_1:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (128)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block2_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block2_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block2_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv3_block2_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block2_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block2_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block2_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv3_block2_1_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__922 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__922 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv3_block2_1_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__922:0 for ONNX tensor: QuantLinearNode__922:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__922 [QuantizeLinear] outputs: [QuantLinearNode__922:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__923 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__922:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__923 [DequantizeLinear] inputs: [QuantLinearNode__922:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__923 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 128, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block2_2_bn/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block2_2_bn/ReadVariableOp_1:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (128)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block2_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block2_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block2_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv3_block2_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block2_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block2_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block2_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv3_block2_2_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__926 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__926 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv3_block2_2_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__926:0 for ONNX tensor: QuantLinearNode__926:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__926 [QuantizeLinear] outputs: [QuantLinearNode__926:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__927 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__926:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__927 [DequantizeLinear] inputs: [QuantLinearNode__926:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__927 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 128, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D:0 -> (-1, 512, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block2_3_bn/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block2_3_bn/ReadVariableOp_1:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (512)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block2_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 512, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block2_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block2_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block2_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv3_block2_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block2_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block2_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block2_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv3_block2_out/Relu:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__930 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block2_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__930 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv3_block2_out/Relu:0 -> (-1, 512, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__930:0 for ONNX tensor: QuantLinearNode__930:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__930 [QuantizeLinear] outputs: [QuantLinearNode__930:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__931 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__930:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__931 [DequantizeLinear] inputs: [QuantLinearNode__930:0 -> (-1, 512, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__931 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 512, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block3_1_bn/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block3_1_bn/ReadVariableOp_1:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (128)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block3_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block3_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block3_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv3_block3_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block3_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block3_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block3_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv3_block3_1_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__938 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__938 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv3_block3_1_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__938:0 for ONNX tensor: QuantLinearNode__938:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__938 [QuantizeLinear] outputs: [QuantLinearNode__938:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__939 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__938:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__939 [DequantizeLinear] inputs: [QuantLinearNode__938:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__939 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 128, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block3_2_bn/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block3_2_bn/ReadVariableOp_1:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (128)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block3_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block3_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block3_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv3_block3_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block3_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block3_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block3_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv3_block3_2_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__942 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__942 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv3_block3_2_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__942:0 for ONNX tensor: QuantLinearNode__942:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__942 [QuantizeLinear] outputs: [QuantLinearNode__942:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__943 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__942:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__943 [DequantizeLinear] inputs: [QuantLinearNode__942:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__943 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 128, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D:0 -> (-1, 512, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block3_3_bn/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block3_3_bn/ReadVariableOp_1:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (512)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 512, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block3_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block3_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block3_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv3_block3_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block3_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block3_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block3_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv3_block3_out/Relu:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__946 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block3_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__946 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv3_block3_out/Relu:0 -> (-1, 512, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__946:0 for ONNX tensor: QuantLinearNode__946:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__946 [QuantizeLinear] outputs: [QuantLinearNode__946:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__951 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__946:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__951 [DequantizeLinear] inputs: [QuantLinearNode__946:0 -> (-1, 512, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__951 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block4_1_bn/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block4_1_bn/ReadVariableOp_1:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (128)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block4_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block4_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block4_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv3_block4_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block4_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block4_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block4_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv3_block4_1_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__954 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__954 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv3_block4_1_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__954:0 for ONNX tensor: QuantLinearNode__954:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__954 [QuantizeLinear] outputs: [QuantLinearNode__954:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__955 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__954:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__955 [DequantizeLinear] inputs: [QuantLinearNode__954:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__955 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (128, 128, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block4_2_bn/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block4_2_bn/ReadVariableOp_1:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (128)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block4_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block4_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block4_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv3_block4_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block4_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block4_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block4_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv3_block4_2_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__958 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__958 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv3_block4_2_relu/Relu:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__958:0 for ONNX tensor: QuantLinearNode__958:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__958 [QuantizeLinear] outputs: [QuantLinearNode__958:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__959 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__958:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__959 [DequantizeLinear] inputs: [QuantLinearNode__958:0 -> (-1, 128, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__959 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 128, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D:0 -> (-1, 512, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block4_3_bn/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block4_3_bn/ReadVariableOp_1:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (512)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv3_block4_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block4_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv3_block4_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv3_block4_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv3_block4_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv3_block4_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv3_block4_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv3_block4_out/Relu:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__966 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv3_block4_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__966 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv3_block4_out/Relu:0 -> (-1, 512, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__966:0 for ONNX tensor: QuantLinearNode__966:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__966 [QuantizeLinear] outputs: [QuantLinearNode__966:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__967 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__966:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__967 [DequantizeLinear] inputs: [QuantLinearNode__966:0 -> (-1, 512, 28, 28)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__967 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 28, 28)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_1_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_1_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block1_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block1_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block1_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block1_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block1_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block1_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block1_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block1_1_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__970 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__970 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block1_1_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__970:0 for ONNX tensor: QuantLinearNode__970:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__970 [QuantizeLinear] outputs: [QuantLinearNode__970:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__971 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__970:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__971 [DequantizeLinear] inputs: [QuantLinearNode__970:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__971 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_2_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_2_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block1_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block1_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block1_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block1_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block1_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block1_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block1_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block1_2_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__974 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__974 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block1_2_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__974:0 for ONNX tensor: QuantLinearNode__974:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__974 [QuantizeLinear] outputs: [QuantLinearNode__974:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__975 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__974:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__975 [DequantizeLinear] inputs: [QuantLinearNode__974:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__975 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_3_bn/ReadVariableOp:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_0_bn/ReadVariableOp_1:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (1024)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__978 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__978 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3:0 -> (-1, 1024, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__978:0 for ONNX tensor: QuantLinearNode__978:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__978 [QuantizeLinear] outputs: [QuantLinearNode__978:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__979 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__978:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__979 [DequantizeLinear] inputs: [QuantLinearNode__978:0 -> (-1, 1024, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__979 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 28, 28)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (1024, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_0_bn/ReadVariableOp:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_0_bn/ReadVariableOp_1:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3/ReadVariableOp:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (1024)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block1_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block1_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block1_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block1_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block1_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block1_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block1_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block1_out/Relu:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__986 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block1_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__986 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block1_out/Relu:0 -> (-1, 1024, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__986:0 for ONNX tensor: QuantLinearNode__986:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__986 [QuantizeLinear] outputs: [QuantLinearNode__986:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__987 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__986:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__987 [DequantizeLinear] inputs: [QuantLinearNode__986:0 -> (-1, 1024, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__987 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block2_1_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block2_1_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block2_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block2_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block2_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block2_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block2_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block2_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block2_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block2_1_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__990 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__990 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block2_1_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__990:0 for ONNX tensor: QuantLinearNode__990:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__990 [QuantizeLinear] outputs: [QuantLinearNode__990:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__991 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__990:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__991 [DequantizeLinear] inputs: [QuantLinearNode__990:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__991 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block2_2_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block2_2_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block2_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block2_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block2_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block2_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block2_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block2_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block2_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block2_2_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__994 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__994 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block2_2_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__994:0 for ONNX tensor: QuantLinearNode__994:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__994 [QuantizeLinear] outputs: [QuantLinearNode__994:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__995 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__994:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__995 [DequantizeLinear] inputs: [QuantLinearNode__994:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__995 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block2_3_bn/ReadVariableOp:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block2_3_bn/ReadVariableOp_1:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (1024)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block2_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block2_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block2_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block2_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block2_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block2_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block2_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block2_out/Relu:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1002 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block2_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1002 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block2_out/Relu:0 -> (-1, 1024, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1002:0 for ONNX tensor: QuantLinearNode__1002:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1002 [QuantizeLinear] outputs: [QuantLinearNode__1002:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1003 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1002:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1003 [DequantizeLinear] inputs: [QuantLinearNode__1002:0 -> (-1, 1024, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1003 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block3_1_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block3_1_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block3_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block3_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block3_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block3_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block3_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block3_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block3_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block3_1_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1006 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1006 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block3_1_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1006:0 for ONNX tensor: QuantLinearNode__1006:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1006 [QuantizeLinear] outputs: [QuantLinearNode__1006:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1007 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1006:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1007 [DequantizeLinear] inputs: [QuantLinearNode__1006:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1007 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block3_2_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block3_2_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block3_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block3_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block3_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block3_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block3_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block3_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block3_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block3_2_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1010 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1010 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block3_2_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1010:0 for ONNX tensor: QuantLinearNode__1010:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1010 [QuantizeLinear] outputs: [QuantLinearNode__1010:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1011 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1010:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1011 [DequantizeLinear] inputs: [QuantLinearNode__1010:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1011 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block3_3_bn/ReadVariableOp:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block3_3_bn/ReadVariableOp_1:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (1024)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block3_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block3_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block3_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block3_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block3_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block3_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block3_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block3_out/Relu:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1018 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block3_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1018 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block3_out/Relu:0 -> (-1, 1024, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1018:0 for ONNX tensor: QuantLinearNode__1018:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1018 [QuantizeLinear] outputs: [QuantLinearNode__1018:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1015 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1018:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1015 [DequantizeLinear] inputs: [QuantLinearNode__1018:0 -> (-1, 1024, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_add/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1015 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block4_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block4_1_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block4_1_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block4_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block4_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block4_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block4_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block4_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block4_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block4_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block4_1_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1022 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1022 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block4_1_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1022:0 for ONNX tensor: QuantLinearNode__1022:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1022 [QuantizeLinear] outputs: [QuantLinearNode__1022:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1023 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1022:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1023 [DequantizeLinear] inputs: [QuantLinearNode__1022:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1023 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block4_2_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block4_2_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block4_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block4_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block4_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block4_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block4_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block4_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block4_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block4_2_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1026 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1026 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block4_2_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1026:0 for ONNX tensor: QuantLinearNode__1026:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1026 [QuantizeLinear] outputs: [QuantLinearNode__1026:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1027 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1026:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1027 [DequantizeLinear] inputs: [QuantLinearNode__1026:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1027 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block4_3_bn/ReadVariableOp:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block4_3_bn/ReadVariableOp_1:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (1024)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block4_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block4_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block4_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block4_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block4_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block4_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block4_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block4_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block4_out/Relu:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1034 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block4_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1034 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block4_out/Relu:0 -> (-1, 1024, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1034:0 for ONNX tensor: QuantLinearNode__1034:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1034 [QuantizeLinear] outputs: [QuantLinearNode__1034:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1031 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1034:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1031 [DequantizeLinear] inputs: [QuantLinearNode__1034:0 -> (-1, 1024, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_add/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1031 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block5_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block5_1_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block5_1_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block5_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block5_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block5_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block5_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block5_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block5_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block5_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block5_1_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1038 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1038 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block5_1_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1038:0 for ONNX tensor: QuantLinearNode__1038:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1038 [QuantizeLinear] outputs: [QuantLinearNode__1038:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1039 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1038:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1039 [DequantizeLinear] inputs: [QuantLinearNode__1038:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1039 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block5_2_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block5_2_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block5_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block5_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block5_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block5_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block5_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block5_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block5_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block5_2_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1042 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1042 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block5_2_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1042:0 for ONNX tensor: QuantLinearNode__1042:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1042 [QuantizeLinear] outputs: [QuantLinearNode__1042:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1043 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1042:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1043 [DequantizeLinear] inputs: [QuantLinearNode__1042:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1043 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block5_3_bn/ReadVariableOp:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block5_3_bn/ReadVariableOp_1:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (1024)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block5_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block5_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block5_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block5_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block5_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block5_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block5_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block5_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block5_out/Relu:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1050 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block5_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1050 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block5_out/Relu:0 -> (-1, 1024, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1050:0 for ONNX tensor: QuantLinearNode__1050:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1050 [QuantizeLinear] outputs: [QuantLinearNode__1050:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1051 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1050:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1051 [DequantizeLinear] inputs: [QuantLinearNode__1050:0 -> (-1, 1024, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1051 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block6_1_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block6_1_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block6_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block6_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block6_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block6_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block6_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block6_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block6_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block6_1_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1054 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1054 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block6_1_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1054:0 for ONNX tensor: QuantLinearNode__1054:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1054 [QuantizeLinear] outputs: [QuantLinearNode__1054:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1055 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1054:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1055 [DequantizeLinear] inputs: [QuantLinearNode__1054:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1055 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (256, 256, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block6_2_bn/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block6_2_bn/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block6_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block6_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block6_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block6_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block6_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block6_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block6_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block6_2_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1058 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1058 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block6_2_relu/Relu:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1058:0 for ONNX tensor: QuantLinearNode__1058:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1058 [QuantizeLinear] outputs: [QuantLinearNode__1058:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1059 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1058:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1059 [DequantizeLinear] inputs: [QuantLinearNode__1058:0 -> (-1, 256, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1059 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (1024, 256, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block6_3_bn/ReadVariableOp:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block6_3_bn/ReadVariableOp_1:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (1024)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (1024)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv4_block6_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block6_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv4_block6_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv4_block6_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv4_block6_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv4_block6_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv4_block6_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv4_block6_out/Relu:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1062 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv4_block6_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1062 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv4_block6_out/Relu:0 -> (-1, 1024, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1062:0 for ONNX tensor: QuantLinearNode__1062:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1062 [QuantizeLinear] outputs: [QuantLinearNode__1062:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1063 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1062:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1063 [DequantizeLinear] inputs: [QuantLinearNode__1062:0 -> (-1, 1024, 14, 14)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1063 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D:0 -> (-1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_1_bn/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_1_bn/ReadVariableOp_1:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (512)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block1_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block1_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block1_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv5_block1_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block1_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block1_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block1_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv5_block1_1_relu/Relu:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1070 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1070 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv5_block1_1_relu/Relu:0 -> (-1, 512, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1070:0 for ONNX tensor: QuantLinearNode__1070:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1070 [QuantizeLinear] outputs: [QuantLinearNode__1070:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1071 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1070:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1071 [DequantizeLinear] inputs: [QuantLinearNode__1070:0 -> (-1, 512, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1071 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 512, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D:0 -> (-1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_2_bn/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_2_bn/ReadVariableOp_1:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (512)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block1_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block1_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block1_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv5_block1_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block1_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block1_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block1_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv5_block1_2_relu/Relu:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1074 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1074 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv5_block1_2_relu/Relu:0 -> (-1, 512, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1074:0 for ONNX tensor: QuantLinearNode__1074:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1074 [QuantizeLinear] outputs: [QuantLinearNode__1074:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1075 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1074:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1075 [DequantizeLinear] inputs: [QuantLinearNode__1074:0 -> (-1, 512, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1075 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (2048, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D:0 -> (-1, 2048, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_3_bn/ReadVariableOp:0 -> (2048)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_0_bn/ReadVariableOp_1:0 -> (2048)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (2048)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (2048)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1078 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1078 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3:0 -> (-1, 2048, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1078:0 for ONNX tensor: QuantLinearNode__1078:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1078 [QuantizeLinear] outputs: [QuantLinearNode__1078:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1079 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1078:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1079 [DequantizeLinear] inputs: [QuantLinearNode__1078:0 -> (-1, 2048, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1079 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 1024, 14, 14)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (2048, 1024, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D:0 -> (-1, 2048, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_0_bn/ReadVariableOp:0 -> (2048)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_0_bn/ReadVariableOp_1:0 -> (2048)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3/ReadVariableOp:0 -> (2048)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (2048)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3:0 -> (-1, 2048, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv5_block1_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block1_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block1_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block1_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv5_block1_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block1_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block1_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block1_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv5_block1_out/Relu:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1086 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block1_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1086 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv5_block1_out/Relu:0 -> (-1, 2048, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1086:0 for ONNX tensor: QuantLinearNode__1086:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1086 [QuantizeLinear] outputs: [QuantLinearNode__1086:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1087 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1086:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1087 [DequantizeLinear] inputs: [QuantLinearNode__1086:0 -> (-1, 2048, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1087 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 2048, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 2048, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D:0 -> (-1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block2_1_bn/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block2_1_bn/ReadVariableOp_1:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (512)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block2_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block2_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block2_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv5_block2_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block2_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block2_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block2_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv5_block2_1_relu/Relu:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1090 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1090 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv5_block2_1_relu/Relu:0 -> (-1, 512, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1090:0 for ONNX tensor: QuantLinearNode__1090:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1090 [QuantizeLinear] outputs: [QuantLinearNode__1090:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1091 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1090:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1091 [DequantizeLinear] inputs: [QuantLinearNode__1090:0 -> (-1, 512, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1091 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 512, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D:0 -> (-1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block2_2_bn/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block2_2_bn/ReadVariableOp_1:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (512)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block2_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block2_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block2_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv5_block2_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block2_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block2_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block2_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv5_block2_2_relu/Relu:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1094 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1094 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv5_block2_2_relu/Relu:0 -> (-1, 512, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1094:0 for ONNX tensor: QuantLinearNode__1094:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1094 [QuantizeLinear] outputs: [QuantLinearNode__1094:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1095 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1094:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1095 [DequantizeLinear] inputs: [QuantLinearNode__1094:0 -> (-1, 512, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1095 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (2048, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D:0 -> (-1, 2048, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block2_3_bn/ReadVariableOp:0 -> (2048)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block2_3_bn/ReadVariableOp_1:0 -> (2048)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (2048)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (2048)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 2048, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block2_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block2_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block2_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv5_block2_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block2_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block2_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block2_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv5_block2_out/Relu:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1102 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block2_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1102 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv5_block2_out/Relu:0 -> (-1, 2048, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1102:0 for ONNX tensor: QuantLinearNode__1102:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1102 [QuantizeLinear] outputs: [QuantLinearNode__1102:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1099 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1102:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1099 [DequantizeLinear] inputs: [QuantLinearNode__1102:0 -> (-1, 2048, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1099 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 2048, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 2048, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_1_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_1_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D:0 -> (-1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block3_1_bn/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block3_1_bn/ReadVariableOp_1:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (512)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block3_1_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block3_1_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block3_1_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv5_block3_1_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block3_1_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block3_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block3_1_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv5_block3_1_relu/Relu:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1106 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_1_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1106 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv5_block3_1_relu/Relu:0 -> (-1, 512, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1106:0 for ONNX tensor: QuantLinearNode__1106:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1106 [QuantizeLinear] outputs: [QuantLinearNode__1106:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1107 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1106:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1107 [DequantizeLinear] inputs: [QuantLinearNode__1106:0 -> (-1, 512, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1107 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (512, 512, 3, 3)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_2_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_2_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D:0 -> (-1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block3_2_bn/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block3_2_bn/ReadVariableOp_1:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (512)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block3_2_relu/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block3_2_relu/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block3_2_relu/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv5_block3_2_relu/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block3_2_relu/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block3_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block3_2_relu/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv5_block3_2_relu/Relu:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1110 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_2_relu/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1110 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv5_block3_2_relu/Relu:0 -> (-1, 512, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1110:0 for ONNX tensor: QuantLinearNode__1110:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1110 [QuantizeLinear] outputs: [QuantLinearNode__1110:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1111 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1110:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1111 [DequantizeLinear] inputs: [QuantLinearNode__1110:0 -> (-1, 512, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1111 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D [Conv]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D [Conv] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4:0 -> (2048, 512, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D [Conv] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3 [BatchNormalization]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_3_bn/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_3_bn/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D:0 -> (-1, 2048, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block3_3_bn/ReadVariableOp:0 -> (2048)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block3_3_bn/ReadVariableOp_1:0 -> (2048)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp:0 -> (2048)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1:0 -> (2048)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add [Add] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_add/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 2048, 7, 7)[FLOAT]], [StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add for ONNX node: StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add [Add] outputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/conv5_block3_out/Relu [Relu]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block3_out/Relu [Relu] inputs: [StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/conv5_block3_out/Relu for ONNX node: StatefulPartitionedCall/resnet50/conv5_block3_out/Relu
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/conv5_block3_out/Relu:0 for ONNX tensor: StatefulPartitionedCall/resnet50/conv5_block3_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/conv5_block3_out/Relu [Relu] outputs: [StatefulPartitionedCall/resnet50/conv5_block3_out/Relu:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1114 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/conv5_block3_out/Relu:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1114 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/conv5_block3_out/Relu:0 -> (-1, 2048, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1114:0 for ONNX tensor: QuantLinearNode__1114:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1114 [QuantizeLinear] outputs: [QuantLinearNode__1114:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1115 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1114:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1115 [DequantizeLinear] inputs: [QuantLinearNode__1114:0 -> (-1, 2048, 7, 7)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_avg_pool/LastValueQuant/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_avg_pool/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1115 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_avg_pool/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean [GlobalAveragePool]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_avg_pool/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_avg_pool/Mean [GlobalAveragePool] inputs: [StatefulPartitionedCall/resnet50/quant_avg_pool/LastValueQuant/QuantizeAndDequantizeV4:0 -> (-1, 2048, 7, 7)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean for ONNX node: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_avg_pool/Mean [GlobalAveragePool] outputs: [StatefulPartitionedCall/resnet50/quant_avg_pool/Mean:0 -> (-1, 2048, 1, 1)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727 [Squeeze]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: const_axes__1726
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727 [Squeeze] inputs: [StatefulPartitionedCall/resnet50/quant_avg_pool/Mean:0 -> (-1, 2048, 1, 1)[FLOAT]], [const_axes__1726 -> (2)[INT32]], 
[01/10/2024-10:51:09] [V] [TRT] Original shape: (_, 2048, 1, 1), squeezing to: (_, _)
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727 for ONNX node: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727 [Squeeze] outputs: [StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727:0 -> (-1, 2048)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: QuantLinearNode__1118 [QuantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1118 [QuantizeLinear] inputs: [StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727:0 -> (-1, 2048)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: QuantLinearNode__1118:0 for ONNX tensor: QuantLinearNode__1118:0
[01/10/2024-10:51:09] [V] [TRT] QuantLinearNode__1118 [QuantizeLinear] outputs: [QuantLinearNode__1118:0 -> (-1, 2048)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: DequantLinearNode__1119 [DequantizeLinear]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: QuantLinearNode__1118:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: quant_scale__1064
[01/10/2024-10:51:09] [V] [TRT] Searching for input: zero_point__965
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1119 [DequantizeLinear] inputs: [QuantLinearNode__1118:0 -> (-1, 2048)[FLOAT]], [quant_scale__1064 -> ()[FLOAT]], [zero_point__965 -> ()[INT8]], 
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant_1/QuantizeAndDequantizeV4:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] DequantLinearNode__1119 [DequantizeLinear] outputs: [StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 2048)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_predictions/MatMul [MatMul]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant_1/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_predictions/MatMul [MatMul] inputs: [StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> (-1, 2048)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4:0 -> (2048, 1000)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_predictions/MatMul for ONNX node: StatefulPartitionedCall/resnet50/quant_predictions/MatMul
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_predictions/MatMul:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_predictions/MatMul:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_predictions/MatMul [MatMul] outputs: [StatefulPartitionedCall/resnet50/quant_predictions/MatMul:0 -> (-1, 1000)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd [Add]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_predictions/MatMul:0
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd [Add] inputs: [StatefulPartitionedCall/resnet50/quant_predictions/MatMul:0 -> (-1, 1000)[FLOAT]], [StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 -> (1000)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd for ONNX node: StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd:0 for ONNX tensor: StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd [Add] outputs: [StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd:0 -> (-1, 1000)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Parsing node: StatefulPartitionedCall/resnet50/quant_predictions/Softmax [Softmax]
[01/10/2024-10:51:09] [V] [TRT] Searching for input: StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_predictions/Softmax [Softmax] inputs: [StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd:0 -> (-1, 1000)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Registering layer: StatefulPartitionedCall/resnet50/quant_predictions/Softmax for ONNX node: StatefulPartitionedCall/resnet50/quant_predictions/Softmax
[01/10/2024-10:51:09] [V] [TRT] Registering tensor: Identity:0_121 for ONNX tensor: Identity:0
[01/10/2024-10:51:09] [V] [TRT] StatefulPartitionedCall/resnet50/quant_predictions/Softmax [Softmax] outputs: [Identity:0 -> (-1, 1000)[FLOAT]], 
[01/10/2024-10:51:09] [V] [TRT] Marking Identity:0_121 as output: Identity:0
[01/10/2024-10:51:09] [I] Finished parsing network model. Parse time: 0.512295
[01/10/2024-10:51:09] [W] Dynamic dimensions required for input: input_1:0, but no shapes were provided. Automatically overriding shape to: 1x224x224x3
[01/10/2024-10:51:09] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:09] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:09] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:09] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:09] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:09] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:09] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:09] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:09] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:09] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:09] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [E] Error[3]: [convolutionLayer.h::setKernelWeights::30] Error Code 3: API Usage Error (Parameter check failed at: /_src/build/x86_64-gnu/release/optimizer/api/layers/convolutionLayer.h::setKernelWeights::30, condition: kernelWeights.values != nullptr
)
[01/10/2024-10:51:10] [I] FP32 and INT8 precisions have been specified - more performance might be enabled by additionally specifying --fp16 or --best
[01/10/2024-10:51:10] [W] [TRT] Calibrator won't be used in explicit precision mode. Use quantization aware training to generate network with Quantize/Dequantize nodes.
[01/10/2024-10:51:10] [V] [TRT] Original: 471 layers
[01/10/2024-10:51:10] [V] [TRT] After dead-layer removal: 471 layers
[01/10/2024-10:51:10] [V] [TRT] Graph construction completed in 0.0143403 seconds.
[01/10/2024-10:51:10] [V] [TRT] Running: ConstShuffleFusion on StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstShuffleFusion: Fusing StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 with (Unnamed Layer* 478) [Shuffle]
[01/10/2024-10:51:10] [V] [TRT] Running: ShuffleErasure on (Unnamed Layer* 481) [Shuffle]
[01/10/2024-10:51:10] [V] [TRT] Removing (Unnamed Layer* 481) [Shuffle]
[01/10/2024-10:51:10] [V] [TRT] QDQ graph optimizer - constant folding of Q/DQ initializers
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__834
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__830
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__826
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__822
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__818
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__814
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__810
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__806
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__802
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__798
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__794
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__790
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__786
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__782
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__778
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__774
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__770
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__766
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__762
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__758
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__754
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__750
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__746
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__742
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__738
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__734
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__730
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__726
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__722
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__718
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__714
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__710
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__706
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__702
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__698
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__694
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__690
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__686
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__682
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__678
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__674
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__670
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__666
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__662
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__658
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__654
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__650
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__646
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__642
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__638
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__634
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__630
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__626
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__622
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__835
[01/10/2024-10:51:10] [V] [TRT] Removing zero_point__833
[01/10/2024-10:51:10] [V] [TRT] Removing quant_scale__832
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__827
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__823
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__819
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__815
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__811
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__807
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__803
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__799
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__795
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__791
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__787
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__783
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__779
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__775
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__771
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__767
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__763
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__759
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__755
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__751
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__747
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__743
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__739
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__735
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__731
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__727
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__723
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__719
[01/10/2024-10:51:10] [V] [TRT] Removing zero_point__741
[01/10/2024-10:51:10] [V] [TRT] Removing quant_scale__776
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__711
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__707
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__703
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__699
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__695
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__691
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__687
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__683
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__679
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__675
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__671
[01/10/2024-10:51:10] [V] [TRT] Removing zero_point__705
[01/10/2024-10:51:10] [V] [TRT] Removing quant_scale__684
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__663
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__659
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__655
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__651
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__647
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__643
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__639
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__635
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__631
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__627
[01/10/2024-10:51:10] [V] [TRT] Removing zero_point__737
[01/10/2024-10:51:10] [V] [TRT] Removing quant_scale__772
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__838
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__839
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__846
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__847
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__850
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__851
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__854
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__855
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__858
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__859
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__862
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__867
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__870
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__871
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__874
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__875
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__882
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__879
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__886
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__887
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__890
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__891
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__898
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__899
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__902
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__903
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__906
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__907
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__910
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__911
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__918
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__915
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__922
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__923
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__926
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__927
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__930
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__931
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__938
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__939
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__942
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__943
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__946
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__951
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__954
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__955
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__958
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__959
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__966
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__967
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__970
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__971
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__974
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__975
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__978
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__979
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__986
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__987
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__990
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__991
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__994
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__995
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1002
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1003
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1006
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1007
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1010
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1011
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1018
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1015
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1022
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1023
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1026
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1027
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1034
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1031
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1038
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1039
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1042
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1043
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1050
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1051
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1054
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1055
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1058
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1059
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1062
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1063
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1070
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1071
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1074
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1075
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1078
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1079
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1086
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1087
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1090
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1091
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1094
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1095
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1102
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1099
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1106
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1107
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1110
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1111
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1114
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1115
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on QuantLinearNode__1118
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__1119
[01/10/2024-10:51:10] [V] [TRT] Removing zero_point__965
[01/10/2024-10:51:10] [V] [TRT] Removing quant_scale__1064
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__831
[01/10/2024-10:51:10] [V] [TRT] Removing zero_point__793
[01/10/2024-10:51:10] [V] [TRT] Removing quant_scale__804
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__715
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__667
[01/10/2024-10:51:10] [V] [TRT] Removing zero_point__821
[01/10/2024-10:51:10] [V] [TRT] Removing quant_scale__688
[01/10/2024-10:51:10] [V] [TRT] Running: ConstQDQInitializersFusion on DequantLinearNode__623
[01/10/2024-10:51:10] [V] [TRT] Removing zero_point__653
[01/10/2024-10:51:10] [V] [TRT] Removing quant_scale__644
[01/10/2024-10:51:10] [V] [TRT] After Myelin optimization: 453 layers
[01/10/2024-10:51:10] [V] [TRT] QDQ graph optimizer - constant folding of Q/DQ initializers
[01/10/2024-10:51:10] [V] [TRT] QDQ graph optimizer forward pass - DQ motions and fusions
[01/10/2024-10:51:10] [V] [TRT] QDQ graph optimizer backward pass
[01/10/2024-10:51:10] [V] [TRT] QDQ graph optimizer quantization pass - Generate quantized ops
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__847
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__847
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__867
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__867
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__879
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__879
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__899
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__899
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__915
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__915
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__931
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__931
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__951
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__951
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__967
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__967
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__987
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__987
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__1003
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1003
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__1015
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1015
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__1031
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1031
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__1051
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1051
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__1063
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1063
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__1087
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1087
[01/10/2024-10:51:10] [V] [TRT] Running: SplitDQAcrossFanOut on DequantLinearNode__1099
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1099
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add with StatefulPartitionedCall/resnet50/conv2_block1_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add with StatefulPartitionedCall/resnet50/conv2_block2_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add with StatefulPartitionedCall/resnet50/conv2_block3_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add with StatefulPartitionedCall/resnet50/conv3_block1_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add with StatefulPartitionedCall/resnet50/conv3_block2_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add with StatefulPartitionedCall/resnet50/conv3_block3_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add with StatefulPartitionedCall/resnet50/conv3_block4_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add with StatefulPartitionedCall/resnet50/conv4_block1_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add with StatefulPartitionedCall/resnet50/conv4_block2_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add with StatefulPartitionedCall/resnet50/conv4_block3_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add with StatefulPartitionedCall/resnet50/conv4_block4_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add with StatefulPartitionedCall/resnet50/conv4_block5_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add with StatefulPartitionedCall/resnet50/conv4_block6_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add with StatefulPartitionedCall/resnet50/conv5_block1_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add with StatefulPartitionedCall/resnet50/conv5_block2_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: EltReluFusion on StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add
[01/10/2024-10:51:10] [V] [TRT] EltReluFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add with StatefulPartitionedCall/resnet50/conv5_block3_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv2_block1_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv2_block1_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv2_block2_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv2_block2_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv2_block3_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv2_block3_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv3_block1_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv3_block1_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv3_block2_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv3_block2_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv3_block3_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv3_block3_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv3_block4_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv3_block4_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv4_block1_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv4_block1_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv4_block2_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv4_block2_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv4_block3_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv4_block3_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv4_block4_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv4_block4_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv4_block5_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv4_block5_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv4_block6_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv4_block6_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv5_block1_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv5_block1_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv5_block2_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv5_block2_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv5_block3_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ScaleActivationFusion on StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3 with StatefulPartitionedCall/resnet50/conv5_block3_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: ReduceToPoolingFusion on StatefulPartitionedCall/resnet50/quant_avg_pool/Mean
[01/10/2024-10:51:10] [V] [TRT] Swap the layer type of StatefulPartitionedCall/resnet50/quant_avg_pool/Mean from REDUCE to POOLING
[01/10/2024-10:51:10] [V] [TRT] Running: VanillaSwapWithPreceedingDQ on DequantLinearNode__839
[01/10/2024-10:51:10] [V] [TRT] Swapping DequantLinearNode__839 with StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__834
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__830
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__826
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__822
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__818
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__814
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__810
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__806
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__802
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__798
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__794
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__790
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__786
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__782
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__778
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__774
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__770
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__766
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__762
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__758
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__754
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__750
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__746
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__742
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__738
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__734
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__730
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__726
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__722
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__718
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__714
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__710
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__706
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__702
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__698
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__694
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__690
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__686
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__682
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__678
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__674
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__670
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__666
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__662
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__658
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__654
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__650
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__646
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__642
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__638
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__634
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__630
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__626
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsQuantizeFusion on StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsQuantizeFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 with QuantLinearNode__622
[01/10/2024-10:51:10] [V] [TRT] Running: MatMulToConvTransform on StatefulPartitionedCall/resnet50/quant_predictions/MatMul
[01/10/2024-10:51:10] [V] [TRT] Convert layer type of StatefulPartitionedCall/resnet50/quant_predictions/MatMul from MATRIX_MULTIPLY to CONVOLUTION
[01/10/2024-10:51:10] [V] [TRT] Running: VanillaSwapWithPreceedingDQ on DequantLinearNode__835
[01/10/2024-10:51:10] [V] [TRT] Swapping DequantLinearNode__835 with transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul
[01/10/2024-10:51:10] [V] [TRT] Running: VanillaSwapWithPreceedingDQ on DequantLinearNode__1119
[01/10/2024-10:51:10] [V] [TRT] Swapping DequantLinearNode__1119 with reshape_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul
[01/10/2024-10:51:10] [V] [TRT] Running: ConstShuffleFusion on StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834
[01/10/2024-10:51:10] [V] [TRT] ConstShuffleFusion: Fusing StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 with transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul
[01/10/2024-10:51:10] [V] [TRT] Running: VanillaSwapWithFollowingQ on StatefulPartitionedCall/resnet50/pool1_pool/MaxPool
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/pool1_pool/MaxPool with QuantLinearNode__846
[01/10/2024-10:51:10] [V] [TRT] Running: VanillaSwapWithFollowingQ on StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727 with QuantLinearNode__1118
[01/10/2024-10:51:10] [V] [TRT] Running: VanillaSwapWithFollowingQ on StatefulPartitionedCall/resnet50/pool1_pad/Pad
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/pool1_pad/Pad with QuantLinearNode__846
[01/10/2024-10:51:10] [V] [TRT] Running: ShuffleShuffleFusion on StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727
[01/10/2024-10:51:10] [V] [TRT] ShuffleShuffleFusion: Fusing StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727 with reshape_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul
[01/10/2024-10:51:10] [V] [TRT] Running: ShuffleErasure on StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727 + reshape_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727 + reshape_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul
[01/10/2024-10:51:10] [V] [TRT] Running: SqueezePushDownJoin on reshape_after_StatefulPartitionedCall/resnet50/quant_predictions/MatMul
[01/10/2024-10:51:10] [V] [TRT] -----------SqueezePushDown kSQUEEZE_JOIN case: StatefulPartitionedCall/resnet50/quant_predictions/MatMul --> reshape_after_StatefulPartitionedCall/resnet50/quant_predictions/MatMul --> StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd
[01/10/2024-10:51:10] [V] [TRT] Running: ConstShuffleFusion on StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]
[01/10/2024-10:51:10] [V] [TRT] ConstShuffleFusion: Fusing StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] with unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output
[01/10/2024-10:51:10] [V] [TRT] Running: ConstEltFusion on StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output
[01/10/2024-10:51:10] [V] [TRT] ConstEltFusion: Fusing StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output with StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd
[01/10/2024-10:51:10] [V] [TRT] Running: ConvScaleFusion on StatefulPartitionedCall/resnet50/quant_predictions/MatMul
[01/10/2024-10:51:10] [V] [TRT] ConvScaleFusion: Fusing StatefulPartitionedCall/resnet50/quant_predictions/MatMul with StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv2_block1_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv2_block1_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv2_block1_0_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv2_block1_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv2_block1_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv2_block1_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv2_block2_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv2_block2_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv2_block2_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv2_block2_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv2_block2_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv2_block3_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv2_block3_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv2_block3_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv2_block3_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv2_block3_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv3_block1_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv3_block1_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv3_block1_0_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv3_block1_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv3_block1_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv3_block1_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv3_block2_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv3_block2_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv3_block2_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv3_block2_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv3_block2_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv3_block3_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv3_block3_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv3_block3_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv3_block3_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv3_block3_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv3_block4_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv3_block4_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv3_block4_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv3_block4_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv3_block4_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block1_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv4_block1_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block1_0_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block1_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv4_block1_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block1_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block2_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv4_block2_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block2_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv4_block2_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block2_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block3_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv4_block3_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block3_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv4_block3_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block3_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block4_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv4_block4_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block4_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv4_block4_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block4_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block5_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv4_block5_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block5_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv4_block5_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block5_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block6_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv4_block6_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block6_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv4_block6_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv4_block6_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv5_block1_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv5_block1_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv5_block1_0_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv5_block1_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv5_block1_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv5_block1_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv5_block2_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv5_block2_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv5_block2_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv5_block2_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv5_block2_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv5_block3_1_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv5_block3_1_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv5_block3_2_bn/FusedBatchNormV3 + StatefulPartitionedCall/resnet50/conv5_block3_2_relu/Relu
[01/10/2024-10:51:10] [V] [TRT] Running: QConvScaleFusion on StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing StatefulPartitionedCall/resnet50/conv5_block3_3_bn/FusedBatchNormV3
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu with QuantLinearNode__862
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__862 into StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__847_clone_1 and DequantLinearNode__627) into StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__862
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__847_clone_1
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__627
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 with StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__859
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add + StatefulPartitionedCall/resnet50/conv2_block2_out/Relu with QuantLinearNode__882
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__882 into StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__875 and DequantLinearNode__651) into StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__882
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__875
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__651
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__650 with StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__650 + StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add + StatefulPartitionedCall/resnet50/conv2_block2_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__867_clone_1
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add + StatefulPartitionedCall/resnet50/conv2_block3_out/Relu with QuantLinearNode__898
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__898 into StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__891 and DequantLinearNode__663) into StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__898
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__891
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__663
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__662 with StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__662 + StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add + StatefulPartitionedCall/resnet50/conv2_block3_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__879_clone_1
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu with QuantLinearNode__918
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__918 into StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__899_clone_1 and DequantLinearNode__667) into StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__918
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__899_clone_1
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__667
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 with StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__911
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu with QuantLinearNode__930
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__930 into StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__927 and DequantLinearNode__691) into StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__930
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__927
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__691
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 with StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__915_clone_1
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add + StatefulPartitionedCall/resnet50/conv3_block3_out/Relu with QuantLinearNode__946
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__946 into StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__943 and DequantLinearNode__703) into StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__946
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__943
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__703
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__702 with StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__702 + StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add + StatefulPartitionedCall/resnet50/conv3_block3_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__931_clone_1
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add + StatefulPartitionedCall/resnet50/conv3_block4_out/Relu with QuantLinearNode__966
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__966 into StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__959 and DequantLinearNode__715) into StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__966
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__959
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__715
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__714 with StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__714 + StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add + StatefulPartitionedCall/resnet50/conv3_block4_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__951_clone_1
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu with QuantLinearNode__986
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__986 into StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__967_clone_1 and DequantLinearNode__719) into StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__986
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__967_clone_1
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__719
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 with StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__979
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu with QuantLinearNode__1002
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1002 into StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__995 and DequantLinearNode__743) into StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1002
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__995
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__743
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 with StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__987_clone_1
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add + StatefulPartitionedCall/resnet50/conv4_block3_out/Relu with QuantLinearNode__1018
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1018 into StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1011 and DequantLinearNode__755) into StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1018
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1011
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__755
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__754 with StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__754 + StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add + StatefulPartitionedCall/resnet50/conv4_block3_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1003_clone_1
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add + StatefulPartitionedCall/resnet50/conv4_block4_out/Relu with QuantLinearNode__1034
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1034 into StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1027 and DequantLinearNode__767) into StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1034
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1027
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__767
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__766 with StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__766 + StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add + StatefulPartitionedCall/resnet50/conv4_block4_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1015_clone_1
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add + StatefulPartitionedCall/resnet50/conv4_block5_out/Relu with QuantLinearNode__1050
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1050 into StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1043 and DequantLinearNode__779) into StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1050
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1043
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__779
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__778 with StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__778 + StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add + StatefulPartitionedCall/resnet50/conv4_block5_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1031_clone_1
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add + StatefulPartitionedCall/resnet50/conv4_block6_out/Relu with QuantLinearNode__1062
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1062 into StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1059 and DequantLinearNode__791) into StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1062
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1059
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__791
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__790 with StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__790 + StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add + StatefulPartitionedCall/resnet50/conv4_block6_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1051_clone_1
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu with QuantLinearNode__1086
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1086 into StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1063_clone_1 and DequantLinearNode__795) into StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1086
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1063_clone_1
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__795
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 with StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1079
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu with QuantLinearNode__1102
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1102 into StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1095 and DequantLinearNode__819) into StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1102
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1095
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__819
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 with StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1087_clone_1
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeConvWithResidualAdd on StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Swapping StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add + StatefulPartitionedCall/resnet50/conv5_block3_out/Relu with QuantLinearNode__1114
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1114 into StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1111 and DequantLinearNode__831) into StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1114
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1111
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__831
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__830 with StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__830 + StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D with StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add + StatefulPartitionedCall/resnet50/conv5_block3_out/Relu
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1099_clone_1
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__846 into StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__839 and DequantLinearNode__623) into StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__846
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__839
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__623
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__850 into StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__847_clone_0 and DequantLinearNode__631) into StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__850
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__847_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__631
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__854 into StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__851 and DequantLinearNode__635) into StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__854
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__851
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__635
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__858 into StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__855 and DequantLinearNode__639) into StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__858
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__855
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__639
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__870 into StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__867_clone_0 and DequantLinearNode__643) into StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__870
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__867_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__643
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__874 into StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__871 and DequantLinearNode__647) into StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__874
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__871
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__647
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__886 into StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__879_clone_0 and DequantLinearNode__655) into StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__886
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__879_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__655
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__890 into StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__887 and DequantLinearNode__659) into StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__890
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__887
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__659
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__902 into StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__899_clone_0 and DequantLinearNode__671) into StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__902
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__899_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__671
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__906 into StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__903 and DequantLinearNode__675) into StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__906
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__903
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__675
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__910 into StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__907 and DequantLinearNode__679) into StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__910
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__907
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__679
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__922 into StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__915_clone_0 and DequantLinearNode__683) into StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__922
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__915_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__683
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__926 into StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__923 and DequantLinearNode__687) into StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__926
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__923
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__687
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__938 into StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__931_clone_0 and DequantLinearNode__695) into StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__938
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__931_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__695
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__942 into StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__939 and DequantLinearNode__699) into StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__942
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__939
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__699
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__954 into StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__951_clone_0 and DequantLinearNode__707) into StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__954
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__951_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__707
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__958 into StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__955 and DequantLinearNode__711) into StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__958
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__955
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__711
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__970 into StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__967_clone_0 and DequantLinearNode__723) into StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__970
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__967_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__723
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__974 into StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__971 and DequantLinearNode__727) into StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__974
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__971
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__727
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__978 into StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__975 and DequantLinearNode__731) into StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__978
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__975
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__731
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__990 into StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__987_clone_0 and DequantLinearNode__735) into StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__990
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__987_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__735
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__994 into StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__991 and DequantLinearNode__739) into StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__994
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__991
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__739
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1006 into StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1003_clone_0 and DequantLinearNode__747) into StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1006
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1003_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__747
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1010 into StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1007 and DequantLinearNode__751) into StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1010
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1007
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__751
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1022 into StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1015_clone_0 and DequantLinearNode__759) into StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1022
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1015_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__759
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1026 into StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1023 and DequantLinearNode__763) into StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1026
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1023
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__763
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1038 into StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1031_clone_0 and DequantLinearNode__771) into StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1038
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1031_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__771
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1042 into StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1039 and DequantLinearNode__775) into StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1042
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1039
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__775
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1054 into StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1051_clone_0 and DequantLinearNode__783) into StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1054
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1051_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__783
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1058 into StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1055 and DequantLinearNode__787) into StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1058
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1055
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__787
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1070 into StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1063_clone_0 and DequantLinearNode__799) into StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1070
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1063_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__799
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1074 into StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1071 and DequantLinearNode__803) into StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1074
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1071
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__803
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1078 into StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1075 and DequantLinearNode__807) into StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1078
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1075
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__807
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1090 into StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1087_clone_0 and DequantLinearNode__811) into StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1090
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1087_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__811
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1094 into StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1091 and DequantLinearNode__815) into StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1094
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1091
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__815
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1106 into StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1099_clone_0 and DequantLinearNode__823) into StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1106
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1099_clone_0
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__823
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantLinearNode__1110 into StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1107 and DequantLinearNode__827) into StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1110
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1107
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__827
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeDoubleInputNodes on StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd
[01/10/2024-10:51:10] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantLinearNode__1119 and DequantLinearNode__835) into StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1119
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__835
[01/10/2024-10:51:10] [V] [TRT] Running: QuantizeSingleInputNodes on StatefulPartitionedCall/resnet50/quant_avg_pool/Mean
[01/10/2024-10:51:10] [V] [TRT] Removing QuantLinearNode__1118
[01/10/2024-10:51:10] [V] [TRT] Removing DequantLinearNode__1115
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul with StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__826
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__826 with StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__822
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__822 with StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__814
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__814 with StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 with StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 with StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 with StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 with StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__786
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__786 with StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__782
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__782 with StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__774
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__774 with StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__770
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__770 with StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__762
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__762 with StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__758
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__758 with StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__750
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__750 with StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__746
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__746 with StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__738
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__738 with StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 with StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 with StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 with StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 with StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__710
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__710 with StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__706
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__706 with StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__698
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__698 with StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__694
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__694 with StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__686
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__686 with StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 with StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 with StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 with StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 with StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__658
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__658 with StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__654
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__654 with StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__646
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__646 with StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 with StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 with StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 with StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 with StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D
[01/10/2024-10:51:10] [V] [TRT] Running: ConstWeightsFusion on StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622
[01/10/2024-10:51:10] [V] [TRT] ConstWeightsFusion: Fusing StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 with StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd
[01/10/2024-10:51:10] [V] [TRT] After dupe layer removal: 62 layers
[01/10/2024-10:51:10] [V] [TRT] After final dead-layer removal: 62 layers
[01/10/2024-10:51:11] [V] [TRT] After tensor merging: 62 layers
[01/10/2024-10:51:11] [V] [TRT] QDQ graph optimizer quantization epilogue pass
[01/10/2024-10:51:11] [V] [TRT] QDQ optimization pass
[01/10/2024-10:51:11] [V] [TRT] QDQ graph optimizer constant fold dangling QDQ pass
[01/10/2024-10:51:11] [V] [TRT] Running: QDQToCopy on QuantLinearNode__838
[01/10/2024-10:51:11] [V] [TRT] Swap the layer type of QuantLinearNode__838 from QUANTIZE to kQDQ
[01/10/2024-10:51:11] [V] [TRT] After dupe layer removal: 62 layers
[01/10/2024-10:51:11] [V] [TRT] After final dead-layer removal: 62 layers
[01/10/2024-10:51:12] [V] [TRT] After tensor merging: 62 layers
[01/10/2024-10:51:12] [V] [TRT] After vertical fusions: 62 layers
[01/10/2024-10:51:12] [V] [TRT] After dupe layer removal: 62 layers
[01/10/2024-10:51:12] [V] [TRT] After final dead-layer removal: 62 layers
[01/10/2024-10:51:13] [V] [TRT] After tensor merging: 62 layers
[01/10/2024-10:51:13] [V] [TRT] After slice removal: 62 layers
[01/10/2024-10:51:13] [V] [TRT] After concat removal: 62 layers
[01/10/2024-10:51:13] [V] [TRT] Trying to split Reshape and strided tensor
[01/10/2024-10:51:13] [I] [TRT] Graph optimization time: 3.00826 seconds.
[01/10/2024-10:51:13] [V] [TRT] Building graph using backend strategy 2
[01/10/2024-10:51:13] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[01/10/2024-10:51:13] [V] [TRT] Constructing optimization profile number 0 [1/1].
[01/10/2024-10:51:13] [V] [TRT] Applying generic optimizations to the graph for inference.
[01/10/2024-10:51:13] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes
[01/10/2024-10:51:13] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/conv1_pad/Pad
[01/10/2024-10:51:13] [V] [TRT] *************** Autotuning format combination: Float(150528,672,3,1) -> Float(158700,690,3,1) ***************
[01/10/2024-10:51:13] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/conv1_pad/Pad (Slice[0x8000001b])
[01/10/2024-10:51:13] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00501407
[01/10/2024-10:51:13] [V] [TRT] StatefulPartitionedCall/resnet50/conv1_pad/Pad (Slice[0x8000001b]) profiling completed in 0.0897849 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00501407
[01/10/2024-10:51:13] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/conv1_pad/Pad (Padding[0x8000000c])
[01/10/2024-10:51:13] [V] [TRT] Padding has no valid tactics for this config, skipping
[01/10/2024-10:51:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Slice Tactic: 0x0000000000000000
[01/10/2024-10:51:13] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121
[01/10/2024-10:51:13] [V] [TRT] *************** Autotuning format combination: Int8(158700,690,3,1) -> Int8(158700,52900,230,1) ***************
[01/10/2024-10:51:13] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121 (Shuffle[0x8000000d])
[01/10/2024-10:51:14] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00549384
[01/10/2024-10:51:14] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0275992
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121 (Shuffle[0x8000000d]) profiling completed in 0.14278 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00549384
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(158700,690,3,1) -> Int8(52900,1:16,230,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121 (Shuffle[0x8000000d])
[01/10/2024-10:51:14] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0133519
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121 (Shuffle[0x8000000d]) profiling completed in 0.00172697 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0133519
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(40020,690:4,3,1) -> Int8(52900,52900:4,230,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121 (Shuffle[0x8000000d])
[01/10/2024-10:51:14] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00610133
[01/10/2024-10:51:14] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0172617
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121 (Shuffle[0x8000000d]) profiling completed in 0.00395562 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00610133
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(10350,1:16,45,15) -> Int8(158700,52900,230,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121 (Shuffle[0x8000000d])
[01/10/2024-10:51:14] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00766075
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121 (Shuffle[0x8000000d]) profiling completed in 0.00197247 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00766075
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(5520,690:32,3,1) -> Int8(52900,52900:32,230,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121 (Shuffle[0x8000000d])
[01/10/2024-10:51:14] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0319781
[01/10/2024-10:51:14] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0157989
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121 (Shuffle[0x8000000d]) profiling completed in 0.00346218 seconds. Fastest Tactic: 0x0000000000000001 Time: 0.0157989
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[01/10/2024-10:51:14] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(158700,52900,230,1) -> Int8(802816,12544,112,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd (CaskConvolution[0x80000009])
[01/10/2024-10:51:14] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:14] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(158700,52900,230,1) -> Int8(25088,12544:32,112,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd (CaskConvolution[0x80000009])
[01/10/2024-10:51:14] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:14] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(52900,52900:4,230,1) -> Int8(200704,12544:4,112,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd (CaskConvolution[0x80000009])
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0187794
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.013578
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd (CaskConvolution[0x80000009]) profiling completed in 0.103239 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.013578
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:14] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(52900,52900:4,230,1) -> Int8(25088,12544:32,112,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd (CaskConvolution[0x80000009])
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0183771
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_first_layer_i8i8_i8i32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_vect_c_32_tilesize8x16x32x32_stage1_warpsize4x1x1_tensor16x8x16_r7s7_u2v2_aligna4_alignc8 Tactic: 0x16bd6a3aa2577457 Time: 0.00777624
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_first_layer_i8i8_i8i32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_vect_c_32_tilesize16x16x32x32_stage1_warpsize4x1x1_tensor16x8x16_r7s7_u2v2_aligna4_alignc8 Tactic: 0x77e275948c7dace9 Time: 0.00678899
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.018688
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0191451
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0135381
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd (CaskConvolution[0x80000009]) profiling completed in 0.0150693 seconds. Fastest Tactic: 0x77e275948c7dace9 Time: 0.00678899
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:14] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x77e275948c7dace9
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(52900,52900:32,230,1) -> Int8(25088,12544:32,112,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd (CaskConvolution[0x80000009])
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0318025
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.0188891
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0315392
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0219847
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.017408
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.0227997
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.0265752
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0242347
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x797402402ff99b58 Time: 0.0206472
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.02211
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.0346697
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.0226116
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd (CaskConvolution[0x80000009]) profiling completed in 0.0258944 seconds. Fastest Tactic: 0xbd2f48ecbf742d59 Time: 0.017408
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:14] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xbd2f48ecbf742d59
[01/10/2024-10:51:14] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/pool1_pad/Pad
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(200704,12544:4,112,1) -> Int8(207936,12996:4,114,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/pool1_pad/Pad (Padding[0x8000000c])
[01/10/2024-10:51:14] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00528196
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/pool1_pad/Pad (Padding[0x8000000c]) profiling completed in 0.0055059 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00528196
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Padding Tactic: 0x0000000000000000
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(25088,12544:32,112,1) -> Int8(25992,12996:32,114,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/pool1_pad/Pad (Padding[0x8000000c])
[01/10/2024-10:51:14] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00565451
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/pool1_pad/Pad (Padding[0x8000000c]) profiling completed in 0.00219135 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00565451
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Padding Tactic: 0x0000000000000000
[01/10/2024-10:51:14] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/pool1_pool/MaxPool
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(207936,12996:4,114,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/pool1_pool/MaxPool (CaskPooling[0x8000002f])
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP4_tQ28_tR3_tS3_tU2_tV2_tUnroll5_tThreads513 Tactic: 0x3d35b618fd3968f1 Time: 0.00734354
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP14_tQ14_tR3_tS3_tU2_tV2_tUnroll5_tThreads841 Tactic: 0xbeae815d02985cde Time: 0.00724114
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP4_tQ28_tR3_tS3_tU2_tV2_tUnroll4_tThreads513 Tactic: 0xe09c44661dba1b5c Time: 0.00658286
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP4_tQ56_tR3_tS3_tU2_tV2_tUnroll4_tThreads1017 Tactic: 0xb331e89337ca2bad Time: 0.00656291
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP14_tQ14_tR3_tS3_tU2_tV2_tUnroll3_tThreads841 Tactic: 0xc4335d27b08156bf Time: 0.00593335
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ8_tR3_tS3_tU2_tV2_tUnroll3_tThreads255 Tactic: 0xbadabf84bb0f736c Time: 0.00607695
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ28_tR3_tS3_tU2_tV2_tUnroll2_tThreads855 Tactic: 0x80d8e857bc044afb Time: 0.00630937
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ28_tR3_tS3_tU2_tV2_tUnroll4_tThreads855 Tactic: 0xfa45342d0e1d409a Time: 0.00653631
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP14_tQ14_tR3_tS3_tU2_tV2_tUnroll2_tThreads841 Tactic: 0x199aaf5950022512 Time: 0.00630937
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP3_tQ56_tR3_tS3_tU2_tV2_tUnroll5_tThreads791 Tactic: 0xf307ae442c39b4a3 Time: 0.00718263
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP3_tQ56_tR3_tS3_tU2_tV2_tUnroll4_tThreads791 Tactic: 0x2eae5c3accbac70e Time: 0.00652966
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP4_tQ56_tR3_tS3_tU2_tV2_tUnroll3_tThreads1017 Tactic: 0x923de46f0f4ddb62 Time: 0.0060221
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP4_tQ28_tR3_tS3_tU2_tV2_tUnroll2_tThreads513 Tactic: 0x9a01981cafa3113d Time: 0.00570514
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP3_tQ56_tR3_tS3_tU2_tV2_tUnroll3_tThreads791 Tactic: 0x899a723e9e20bec2 Time: 0.00724114
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ7_tR3_tS3_tU2_tV2_tUnroll6_tThreads225 Tactic: 0x3acbbd865df539ed Time: 0.00786863
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ28_tR3_tS3_tU2_tV2_tUnroll5_tThreads855 Tactic: 0x27ecc653ee9e3337 Time: 0.00720457
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ28_tR3_tS3_tU2_tV2_tUnroll6_tThreads855 Tactic: 0xd3ce7ffb6015b945 Time: 0.00782244
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kMAX Tactic: 0x1f6c40e3e09ec730 Time: 0.00547759
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ8_tR3_tS3_tU2_tV2_tUnroll1_tThreads255 Tactic: 0x9351f452d5078ab3 Time: 0.00607695
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP4_tQ28_tR3_tS3_tU2_tV2_tUnroll6_tThreads513 Tactic: 0xc9170fb073b2e283 Time: 0.00675574
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP4_tQ56_tR3_tS3_tU2_tV2_tUnroll1_tThreads1017 Tactic: 0x898e8c271f222050 Time: 0.00607695
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ7_tR3_tS3_tU2_tV2_tUnroll3_tThreads225 Tactic: 0xb474d8546167b9fe Time: 0.00611352
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP4_tQ56_tR3_tS3_tU2_tV2_tUnroll2_tThreads1017 Tactic: 0x9fe4504b077a26fb Time: 0.00632845
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP14_tQ14_tR3_tS3_tU2_tV2_tUnroll6_tThreads841 Tactic: 0x4a8c38f58c13d6ac Time: 0.00794006
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ7_tR3_tS3_tU2_tV2_tUnroll1_tThreads225 Tactic: 0x9dff93820f6f4021 Time: 0.00623304
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP3_tQ56_tR3_tS3_tU2_tV2_tUnroll1_tThreads791 Tactic: 0xa01139e8f028471d Time: 0.00655626
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ28_tR3_tS3_tU2_tV2_tUnroll3_tThreads855 Tactic: 0x5d711a295c873956 Time: 0.00588654
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ8_tR3_tS3_tU2_tV2_tUnroll5_tThreads255 Tactic: 0xc04763fe0916790d Time: 0.00725577
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ7_tR3_tS3_tU2_tV2_tUnroll4_tThreads225 Tactic: 0x1340f65033fdc032 Time: 0.00674244
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP3_tQ56_tR3_tS3_tU2_tV2_tUnroll2_tThreads791 Tactic: 0x543380407ea3cd6f Time: 0.00627756
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP3_tQ56_tR3_tS3_tU2_tV2_tUnroll6_tThreads791 Tactic: 0x072517eca2b23ed1 Time: 0.00775314
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ7_tR3_tS3_tU2_tV2_tUnroll5_tThreads225 Tactic: 0xcee9042ed37eb39f Time: 0.00736548
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP14_tQ14_tR3_tS3_tU2_tV2_tUnroll4_tThreads841 Tactic: 0x63077323e21b2f73 Time: 0.00656291
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ7_tR3_tS3_tU2_tV2_tUnroll2_tThreads225 Tactic: 0x69dd2a2a81e4ca53 Time: 0.00589239
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP4_tQ56_tR3_tS3_tU2_tV2_tUnroll5_tThreads1017 Tactic: 0xbee85cb73ffdd634 Time: 0.00721189
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP4_tQ28_tR3_tS3_tU2_tV2_tUnroll3_tThreads513 Tactic: 0x47a86a624f206290 Time: 0.00590994
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ8_tR3_tS3_tU2_tV2_tUnroll4_tThreads255 Tactic: 0x1dee9180e9950aa0 Time: 0.00660281
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ28_tR3_tS3_tU2_tV2_tUnroll1_tThreads855 Tactic: 0x74fa51ff328fc089 Time: 0.00654296
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ8_tR3_tS3_tU2_tV2_tUnroll6_tThreads255 Tactic: 0x3465da56879df37f Time: 0.00770695
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_custom_tP4_tQ32_tRS3_tUV2 Tactic: 0x0165782a59f89027 Time: 0.00654961
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP14_tQ14_tR3_tS3_tU2_tV2_tUnroll1_tThreads841 Tactic: 0xedb816f1de89af60 Time: 0.00656291
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP4_tQ56_tR3_tS3_tU2_tV2_tUnroll6_tThreads1017 Tactic: 0xa88280db27a5d09f Time: 0.00790713
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP4_tQ28_tR3_tS3_tU2_tV2_tUnroll1_tThreads513 Tactic: 0x6e2321b421289b4f Time: 0.006144
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kMAX_tP7_tQ8_tR3_tS3_tU2_tV2_tUnroll2_tThreads255 Tactic: 0x67734dfa5b8c00c1 Time: 0.00581632
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/pool1_pool/MaxPool (CaskPooling[0x8000002f]) profiling completed in 0.0961337 seconds. Fastest Tactic: 0x1f6c40e3e09ec730 Time: 0.00547759
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x1f6c40e3e09ec730
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(25992,12996:32,114,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/pool1_pool/MaxPool (CaskPooling[0x8000002f])
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kMAX Tactic: 0x94215b398b8eb3ba Time: 0.00566013
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/pool1_pool/MaxPool (CaskPooling[0x8000002f]) profiling completed in 0.00225526 seconds. Fastest Tactic: 0x94215b398b8eb3ba Time: 0.00566013
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x94215b398b8eb3ba
[01/10/2024-10:51:14] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136,56,1) -> Int8(200704,3136,56,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:14] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:14] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.00896914
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.009344
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.00875133
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.0064085 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.00875133
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:14] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.00909714
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.00875133
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.00875133
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.00935314
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.00863946
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.0107113 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.00863946
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:14] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00618057
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00628392
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.00726309
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00597943
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0113653
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdef93cbb7324a32c Time: 0.0057344
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x11bde0e1d9f2f35d Time: 0.00816762
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0104594
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0100645
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.00864807
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00616228
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91 Time: 0.00607695
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.006144
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0102922
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xcb4e43bfc9c62daf Time: 0.00527151
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254 Time: 0.00666265
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.00773004
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.006016
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.00842434
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.00615009
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0106998
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.00936229
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7 Time: 0.00723383
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.00634753
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0105221
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x10d9759eac59421f Time: 0.00551385
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.00679564
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.00958659
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.00703565
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.00639205
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b4b8ee4e3591584 Time: 0.00748983
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f Time: 0.00553635
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00638569
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e Time: 0.00663605
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7ab955b6ffcbeee7 Time: 0.00566013
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x5f7d31a0a5d7764d Time: 0.0062712
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bf090bf2a98ea29 Time: 0.00879435
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.00884598
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1 Time: 0.00583387
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8 Time: 0.00605867
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00658951
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.00802946
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00659616
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27 Time: 0.00576951
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.011219
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.00756066
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.00933486
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.00981089
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.00609524
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x2df835e0f3719216 Time: 0.0059509
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.00637297
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.00728503
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32ef760caaeaafd7 Time: 0.00551947
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e Time: 0.00961585
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.00864807
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0108251
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2 Time: 0.00613181
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.00717532
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xf845deaac51e3303 Time: 0.00588069
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 0x4713913582d43abf Time: 0.00886319
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x9328dd2fee1ef426 Time: 0.00857062
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x6826c3f4aba34a72 Time: 0.008192
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xe314ee7007c0d0b2 Time: 0.00643657
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xb840759575017742 Time: 0.00551947
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.00818387
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0xefb539b42d3e6615 Time: 0.00615009
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00658286
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x99cccc4c49473ac3 Time: 0.00808635
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x7883d01837952a88 Time: 0.00797257
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.00639205
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1c2c20adff69b217 Time: 0.00704958
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 0x594a3bc20779687a Time: 0.00912457
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d Time: 0.00620495
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.00637933
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x837a9327666fe41b Time: 0.00585143
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x235cece888514c48 Time: 0.0074752
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f Time: 0.006144
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x235fad4a7171cb36 Time: 0.00592165
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00597333
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4 Time: 0.00564888
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0135115
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00572855
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0111402
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610 Time: 0.00827327
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x648d38730af5cbb4 Time: 0.00560949
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x89403a270b0e65b3 Time: 0.00794819
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0100157
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4 Time: 0.00957684
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00568826
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00619886
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.00863946
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32f37afc87197b35 Time: 0.006144
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.0068197
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.00624576
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x3b1cf3c0bd1b7d7f Time: 0.0068824
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5 Time: 0.00841573
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.00864807
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xce5acc6c4e63526d Time: 0.00624576
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9fd2233523462778 Time: 0.00569389
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xbc24b34ef1c6bc26 Time: 0.00571685
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.00840713
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.00846736
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x4a98bf7e0361ea4c Time: 0.00605867
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac Time: 0.00871691
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.00703565
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.00756066
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x20fc70e3602cda46 Time: 0.00704958
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.006144
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.0068197
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x834cbca762798069 Time: 0.0057461
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x4445151446d948c8 Time: 0.0053313
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0x0274f8f5f953354b Time: 0.00607086
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x4795d184d0f26acf Time: 0.00616228
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x0b2f184f333057c2 Time: 0.00868249
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9 Time: 0.0115228
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xf61ad57d6312e57c Time: 0.00580462
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00658286
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xb2117280dcc1725c Time: 0.00546675
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00682667
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00634753
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7 Time: 0.00596114
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00596114
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00576951
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00597943
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0xa7ed996d55bb4583 Time: 0.00660945
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.0068615
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.00718263
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e Time: 0.00754526
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.00886319
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xa56acdcff5b4583f Time: 0.00551385
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00635389
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539 Time: 0.00656956
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x15841feb1173605d Time: 0.0059275
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdf9653df9a68d011 Time: 0.00709138
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x797402402ff99b58 Time: 0.00776854
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.00821638
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bffbf4543196223 Time: 0.00617447
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x8bac1801ff920aa5 Time: 0.00597943
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9072b4074c1cd76d Time: 0.00727771
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049 Time: 0.00733623
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00613181
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x2cb5b23f5c962046 Time: 0.0125928
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.00958659
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5 Time: 0.00963535
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539 Time: 0.0084033
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0088718
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.00775314
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e Time: 0.00754526
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0120808
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.00613181
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.00913371
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.00687543
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107 Time: 0.00658951
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.00640477
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.00748251
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a Time: 0.00553635
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xeb306d27e3a7ca01 Time: 0.005483
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9f47704ddd29929e Time: 0.0102818
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x294208a8657737e8 Time: 0.00608305
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00594505
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b64a837aa4a3454 Time: 0.00849318
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.00677569
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0106893
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x368150d268fe20d3 Time: 0.00658951
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xff52246c2f8e712b Time: 0.006144
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xbcb25c3eecd59590 Time: 0.00589824
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00656956
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.0066959
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x850b80ab7d925385 Time: 0.00590994
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x31276c9cc1913670 Time: 0.00782244
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x3ad76abbc8b651dc Time: 0.00617447
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.00710531
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1bd2865ca0bb535d Time: 0.00738011
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0101035
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85 Time: 0.00569952
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9d607f92bc49571b Time: 0.0102504
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.409991 seconds. Fastest Tactic: 0xcb4e43bfc9c62daf Time: 0.00527151
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:14] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xcb4e43bfc9c62daf
[01/10/2024-10:51:14] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136,56,1) -> Int8(200704,3136,56,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:14] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:14] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0278918
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00195187 seconds. Fastest Tactic: 0x8846c5916f34f7e9 Time: 0.0278918
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:14] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8846c5916f34f7e9
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0277211
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0303397
[01/10/2024-10:51:14] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00375187 seconds. Fastest Tactic: 0x0f47434ace2a7d18 Time: 0.0277211
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:14] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x0f47434ace2a7d18
[01/10/2024-10:51:14] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00881156
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.0102609
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4 Time: 0.00803759
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0246248
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23 Time: 0.00831391
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0172942
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.0088804
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0173105
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792 Time: 0.0142921
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0111627
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00828953
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0127756
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0145847
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0173917
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4 Time: 0.0109939
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0168879
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.0104594
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.0098304
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00893257
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da Time: 0.00864807
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00912457
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0117929
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00910629
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673 Time: 0.0098304
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.016384
[01/10/2024-10:51:14] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18 Time: 0.0138971
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee Time: 0.011174
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0147895
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0177981
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x0405e3a763219823 Time: 0.0239909
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x8a60cb2150513f2e Time: 0.0170992
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x3a7df5a005634aca Time: 0.0163027
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.0103131
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c Time: 0.0171317
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0105221
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd Time: 0.0168716
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0178143
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0104699
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x13463e9bf9ae0d73 Time: 0.01024
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.0106998
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.0103445
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00833829
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0272335
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0243566
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655 Time: 0.00863086
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00868249
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.0104176
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071 Time: 0.00794819
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x3cda2ee55a7d0cc2 Time: 0.0100352
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468 Time: 0.00982065
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0123002
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0132455
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.0116804
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d Time: 0.00823264
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00863086
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986 Time: 0.00812698
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0xa792e2a2dcc5e78f Time: 0.0116241
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00932571
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00893257
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8 Time: 0.014203
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb Time: 0.00978164
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.0104594
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0136445
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25 Time: 0.0267703
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00881156
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0146286
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0128488
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x4e4c4bf050b40a1b Time: 0.00989867
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x09727a53770225e8 Time: 0.0115228
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0143653
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96 Time: 0.0117816
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0116241
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d Time: 0.00862225
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50 Time: 0.0104803
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.00975238
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd Time: 0.00893257
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6 Time: 0.0123368
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00984015
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3 Time: 0.00982065
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.0102087
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x446f06d5a2e0bae3 Time: 0.0239909
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x61d05b8ef3670baa Time: 0.010045
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab Time: 0.00827327
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac Time: 0.0139503
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.0121295
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23 Time: 0.0147602
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b Time: 0.00914286
[01/10/2024-10:51:15] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.184146 seconds. Fastest Tactic: 0x2f34f689bfca5071 Time: 0.00794819
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:15] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x2f34f689bfca5071
[01/10/2024-10:51:15] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D
[01/10/2024-10:51:15] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136,56,1) -> Int8(802816,3136,56,1) ***************
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:15] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:15] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:15] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0110164
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0114328
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.00903314
[01/10/2024-10:51:15] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00611159 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.00903314
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:15] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:15] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0112077
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0108042
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.0109939
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0112077
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.00900572
[01/10/2024-10:51:15] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.0101447 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.00900572
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:15] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:15] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00802133
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00770695
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.0088804
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00736548
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0114103
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdef93cbb7324a32c Time: 0.0073216
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x11bde0e1d9f2f35d Time: 0.00841573
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0106162
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0102609
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0086997
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00753756
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91 Time: 0.00778394
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.00759146
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.010449
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xcb4e43bfc9c62daf Time: 0.00640477
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254 Time: 0.00684757
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.00778394
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00726308
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.00863086
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.00755296
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0109505
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.00938972
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7 Time: 0.00751908
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.00685453
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0107416
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x10d9759eac59421f Time: 0.00704261
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.00728503
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.00982065
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.00733623
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.00778394
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b4b8ee4e3591584 Time: 0.00764535
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f Time: 0.00712621
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.0081026
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e Time: 0.00857923
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7ab955b6ffcbeee7 Time: 0.00705655
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x5f7d31a0a5d7764d Time: 0.0068824
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bf090bf2a98ea29 Time: 0.00935314
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.00916114
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1 Time: 0.00783783
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8 Time: 0.00797257
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00820826
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.00879435
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00798883
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27 Time: 0.00712621
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0117254
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.00774544
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.00937143
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.010045
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.00756836
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x2df835e0f3719216 Time: 0.00734354
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.00797257
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.00771465
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32ef760caaeaafd7 Time: 0.0066427
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e Time: 0.00978164
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.00883738
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0109939
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2 Time: 0.00644293
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.00734354
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xf845deaac51e3303 Time: 0.0068824
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 0x4713913582d43abf Time: 0.00899657
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x9328dd2fee1ef426 Time: 0.00871691
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x6826c3f4aba34a72 Time: 0.00840713
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xe314ee7007c0d0b2 Time: 0.0066826
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xb840759575017742 Time: 0.00707744
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.00842434
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0xefb539b42d3e6615 Time: 0.0086997
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00711227
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x99cccc4c49473ac3 Time: 0.00833016
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x7883d01837952a88 Time: 0.00820013
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.00786863
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1c2c20adff69b217 Time: 0.0073216
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 0x594a3bc20779687a Time: 0.00925257
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d Time: 0.00686846
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.00776084
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x837a9327666fe41b Time: 0.00639841
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x235cece888514c48 Time: 0.00773004
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f Time: 0.00667595
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x235fad4a7171cb36 Time: 0.00735086
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00784553
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4 Time: 0.0074752
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0138838
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.0068824
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0113428
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610 Time: 0.00845015
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x648d38730af5cbb4 Time: 0.0068406
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x89403a270b0e65b3 Time: 0.00822451
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0104803
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4 Time: 0.0102818
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00757606
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00861365
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.00871691
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32f37afc87197b35 Time: 0.00658951
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.00729966
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.0074752
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x3b1cf3c0bd1b7d7f Time: 0.00729966
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5 Time: 0.00840713
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.00872551
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xce5acc6c4e63526d Time: 0.00680577
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9fd2233523462778 Time: 0.00791483
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xbc24b34ef1c6bc26 Time: 0.00636661
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.00867388
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.00872551
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x4a98bf7e0361ea4c Time: 0.00639841
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac Time: 0.009024
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.00756066
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.00842434
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x20fc70e3602cda46 Time: 0.00712621
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00801321
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.00709138
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x834cbca762798069 Time: 0.00605257
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x4445151446d948c8 Time: 0.0066826
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0x0274f8f5f953354b Time: 0.00723383
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x4795d184d0f26acf Time: 0.0066294
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x0b2f184f333057c2 Time: 0.00883738
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9 Time: 0.0118604
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xf61ad57d6312e57c Time: 0.00795632
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00707048
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xb2117280dcc1725c Time: 0.00675574
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.0085362
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00773774
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7 Time: 0.00751177
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.008192
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00733623
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00745326
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0xa7ed996d55bb4583 Time: 0.00710531
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.00727771
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.00752216
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e Time: 0.00769925
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.00898743
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xa56acdcff5b4583f Time: 0.00687543
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00776854
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539 Time: 0.00685453
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x15841feb1173605d Time: 0.00743131
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdf9653df9a68d011 Time: 0.00730697
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x797402402ff99b58 Time: 0.00795632
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.00841573
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bffbf4543196223 Time: 0.00646201
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x8bac1801ff920aa5 Time: 0.00735817
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9072b4074c1cd76d Time: 0.00753756
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049 Time: 0.00823264
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.0079807
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x2cb5b23f5c962046 Time: 0.0130061
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.00999619
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5 Time: 0.00980114
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539 Time: 0.00858783
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.009088
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.00794006
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e Time: 0.00755296
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0125074
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.00736548
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.00930743
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.00705655
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107 Time: 0.00711227
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.00685453
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.00776854
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a Time: 0.00691026
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xeb306d27e3a7ca01 Time: 0.00646837
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9f47704ddd29929e Time: 0.0105012
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x294208a8657737e8 Time: 0.00636025
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00735086
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b64a837aa4a3454 Time: 0.00868249
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.00705655
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0108147
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x368150d268fe20d3 Time: 0.00704261
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xff52246c2f8e712b Time: 0.00625212
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xbcb25c3eecd59590 Time: 0.00638569
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00917029
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.00707048
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x850b80ab7d925385 Time: 0.00711227
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x31276c9cc1913670 Time: 0.00802133
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x3ad76abbc8b651dc Time: 0.00748983
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.00752986
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1bd2865ca0bb535d Time: 0.00778394
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0102922
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85 Time: 0.00728503
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9d607f92bc49571b Time: 0.0104699
[01/10/2024-10:51:15] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.397695 seconds. Fastest Tactic: 0x834cbca762798069 Time: 0.00605257
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:15] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x834cbca762798069
[01/10/2024-10:51:15] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu
[01/10/2024-10:51:15] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136,56,1), Int8(802816,3136,56,1) -> Int8(802816,3136,56,1) ***************
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:15] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:15] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:15] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1), Int8(200704,3136:4,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0130859
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0136578
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.011219
[01/10/2024-10:51:15] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.00599729 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.011219
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:15] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:15] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1), Int8(25088,3136:32,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0135115
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.013046
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.0132987
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0135514
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0115791
[01/10/2024-10:51:15] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.00990835 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0115791
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:15] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:15] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1), Int8(25088,3136:32,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:15] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00846736
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00937143
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.0101522
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00821638
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0129928
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdef93cbb7324a32c Time: 0.00802946
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x11bde0e1d9f2f35d Time: 0.0105117
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.013179
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0117141
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0100254
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00850178
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91 Time: 0.00845015
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.00779164
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.012544
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xcb4e43bfc9c62daf Time: 0.00714606
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254 Time: 0.00776084
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0102818
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00823264
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0113203
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.00799695
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0123733
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0112978
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7 Time: 0.0082814
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.00751177
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0126659
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x10d9759eac59421f Time: 0.00771465
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.00782244
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0111515
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.00924343
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.00891482
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b4b8ee4e3591584 Time: 0.0102296
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f Time: 0.00758376
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00884598
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e Time: 0.00937143
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7ab955b6ffcbeee7 Time: 0.00820013
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x5f7d31a0a5d7764d Time: 0.00865667
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bf090bf2a98ea29 Time: 0.0125684
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.0104072
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1 Time: 0.00863946
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8 Time: 0.00828953
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00928
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0106998
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00999619
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27 Time: 0.00790713
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0139104
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.00892343
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0109505
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0111852
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.00779164
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x2df835e0f3719216 Time: 0.00753756
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.00818387
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0103758
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32ef760caaeaafd7 Time: 0.00760686
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e Time: 0.011399
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.0109087
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0134849
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2 Time: 0.00768385
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0096061
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xf845deaac51e3303 Time: 0.00817575
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 0x4713913582d43abf Time: 0.0118604
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x9328dd2fee1ef426 Time: 0.0122758
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x6826c3f4aba34a72 Time: 0.0112077
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xe314ee7007c0d0b2 Time: 0.00889761
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xb840759575017742 Time: 0.00775314
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.0106998
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0xefb539b42d3e6615 Time: 0.00977188
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00820013
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x99cccc4c49473ac3 Time: 0.0104594
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x7883d01837952a88 Time: 0.0100254
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.00833829
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1c2c20adff69b217 Time: 0.00888901
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 0x594a3bc20779687a Time: 0.012739
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d Time: 0.00799695
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.00800508
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x837a9327666fe41b Time: 0.00771465
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x235cece888514c48 Time: 0.0100742
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f Time: 0.00729234
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x235fad4a7171cb36 Time: 0.00776854
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00837892
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4 Time: 0.00779934
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0164003
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00734354
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0128
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610 Time: 0.00954758
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x648d38730af5cbb4 Time: 0.00781474
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x89403a270b0e65b3 Time: 0.0105953
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0129585
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4 Time: 0.0123733
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00785323
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00945371
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.00958659
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32f37afc87197b35 Time: 0.00769155
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.00824076
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.00787633
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x3b1cf3c0bd1b7d7f Time: 0.00990842
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5 Time: 0.00910629
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0100254
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xce5acc6c4e63526d Time: 0.00806197
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9fd2233523462778 Time: 0.00872551
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xbc24b34ef1c6bc26 Time: 0.00710531
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.011444
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0103236
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x4a98bf7e0361ea4c Time: 0.00768385
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac Time: 0.0100937
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.00820013
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.00943543
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x20fc70e3602cda46 Time: 0.00954758
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00859644
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.00822451
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x834cbca762798069 Time: 0.00733623
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x4445151446d948c8 Time: 0.00736548
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0x0274f8f5f953354b Time: 0.00848457
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x4795d184d0f26acf Time: 0.00778394
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x0b2f184f333057c2 Time: 0.011174
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9 Time: 0.0144677
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xf61ad57d6312e57c Time: 0.00885459
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00799695
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xb2117280dcc1725c Time: 0.00776084
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00956708
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00907886
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7 Time: 0.00820013
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00869109
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00779934
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00820826
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0xa7ed996d55bb4583 Time: 0.00766075
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.00850178
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.00941714
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e Time: 0.00982065
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0122636
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xa56acdcff5b4583f Time: 0.00757606
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00875993
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539 Time: 0.00784553
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x15841feb1173605d Time: 0.00829765
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdf9653df9a68d011 Time: 0.00860504
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x797402402ff99b58 Time: 0.0111515
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0105117
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bffbf4543196223 Time: 0.00795632
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x8bac1801ff920aa5 Time: 0.00757606
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9072b4074c1cd76d Time: 0.00896914
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049 Time: 0.00917029
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00864807
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x2cb5b23f5c962046 Time: 0.0158135
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0121051
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5 Time: 0.0114328
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539 Time: 0.00961585
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0123246
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.0100645
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e Time: 0.0096061
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0148626
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.00777624
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0111627
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.00850178
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107 Time: 0.00797257
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.00802946
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0104908
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a Time: 0.00731428
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xeb306d27e3a7ca01 Time: 0.00709834
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9f47704ddd29929e Time: 0.0119101
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x294208a8657737e8 Time: 0.00760686
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00820826
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b64a837aa4a3454 Time: 0.0108251
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.00913371
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0123124
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x368150d268fe20d3 Time: 0.00806197
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xff52246c2f8e712b Time: 0.00754526
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xbcb25c3eecd59590 Time: 0.0073216
[01/10/2024-10:51:15] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.0098499
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.00822451
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x850b80ab7d925385 Time: 0.00752216
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x31276c9cc1913670 Time: 0.00993768
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x3ad76abbc8b651dc Time: 0.00890622
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.00892343
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1bd2865ca0bb535d Time: 0.0096061
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0118604
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85 Time: 0.00803759
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9d607f92bc49571b Time: 0.0119954
[01/10/2024-10:51:16] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.388945 seconds. Fastest Tactic: 0xeb306d27e3a7ca01 Time: 0.00709834
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xeb306d27e3a7ca01
[01/10/2024-10:51:16] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(802816,3136,56,1) -> Int8(200704,3136,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136:4,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0157842
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.016384
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.013937
[01/10/2024-10:51:16] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00590934 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.013937
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0161727
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0155355
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.0139902
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0166603
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0137642
[01/10/2024-10:51:16] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00964323 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0137642
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(25088,3136:32,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00704261
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00711227
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.00825702
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00705655
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0160589
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdef93cbb7324a32c Time: 0.00659615
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x11bde0e1d9f2f35d Time: 0.0105221
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0132056
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0125806
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0103027
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00741668
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91 Time: 0.0068824
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.00750446
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0131391
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xcb4e43bfc9c62daf Time: 0.00596724
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254 Time: 0.00769155
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.00866528
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00685453
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.01024
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.00750446
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0154917
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0109819
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7 Time: 0.00822451
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.00714606
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0130859
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x10d9759eac59421f Time: 0.00642385
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.00847596
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0121417
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.00863086
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.00776084
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b4b8ee4e3591584 Time: 0.00879435
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f Time: 0.00619276
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.0073216
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e Time: 0.00755296
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7ab955b6ffcbeee7 Time: 0.00646201
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x5f7d31a0a5d7764d Time: 0.00745326
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bf090bf2a98ea29 Time: 0.010045
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.0105639
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1 Time: 0.00688936
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8 Time: 0.00689633
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00733623
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.00911543
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00736548
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27 Time: 0.00662275
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0129829
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.00847597
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0111965
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0125562
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.00754526
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x2df835e0f3719216 Time: 0.00735817
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.00787633
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.00858783
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32ef760caaeaafd7 Time: 0.00637297
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e Time: 0.0121051
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.011219
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0134982
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2 Time: 0.00704958
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.00823264
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xf845deaac51e3303 Time: 0.00664935
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 0x4713913582d43abf Time: 0.0114215
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x9328dd2fee1ef426 Time: 0.00998644
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x6826c3f4aba34a72 Time: 0.0096061
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xe314ee7007c0d0b2 Time: 0.00759146
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xb840759575017742 Time: 0.00636661
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.00956709
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0xefb539b42d3e6615 Time: 0.0073216
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00756066
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x99cccc4c49473ac3 Time: 0.0106162
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x7883d01837952a88 Time: 0.0105221
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.00797257
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1c2c20adff69b217 Time: 0.00900572
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 0x594a3bc20779687a Time: 0.0116353
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d Time: 0.00730697
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.00772235
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x837a9327666fe41b Time: 0.00689633
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x235cece888514c48 Time: 0.00882877
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f Time: 0.00705655
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x235fad4a7171cb36 Time: 0.00735817
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00700082
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4 Time: 0.0066294
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0189257
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00637297
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0160102
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610 Time: 0.0101522
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x648d38730af5cbb4 Time: 0.0066294
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x89403a270b0e65b3 Time: 0.00928914
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0114215
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4 Time: 0.0109714
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00659616
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00751177
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.0105326
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32f37afc87197b35 Time: 0.00709834
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.00779934
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.00780704
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x3b1cf3c0bd1b7d7f Time: 0.008192
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5 Time: 0.0103027
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0104803
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xce5acc6c4e63526d Time: 0.00730697
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9fd2233523462778 Time: 0.00666265
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xbc24b34ef1c6bc26 Time: 0.00663605
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.00981089
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0100645
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x4a98bf7e0361ea4c Time: 0.00686846
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac Time: 0.0105117
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.00867388
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.00867388
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x20fc70e3602cda46 Time: 0.00829765
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00712621
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.00775314
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x834cbca762798069 Time: 0.0066427
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x4445151446d948c8 Time: 0.00600381
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0x0274f8f5f953354b Time: 0.00709834
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x4795d184d0f26acf Time: 0.00711227
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x0b2f184f333057c2 Time: 0.0109714
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9 Time: 0.0147017
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xf61ad57d6312e57c Time: 0.00680577
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00756836
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xb2117280dcc1725c Time: 0.00604648
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00780704
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00729966
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7 Time: 0.00691723
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00691723
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00642385
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00658951
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0xa7ed996d55bb4583 Time: 0.00838705
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.00865667
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.00820013
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e Time: 0.00888901
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0109296
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xa56acdcff5b4583f Time: 0.00612571
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00711924
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539 Time: 0.00754526
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x15841feb1173605d Time: 0.00683363
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdf9653df9a68d011 Time: 0.00913371
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x797402402ff99b58 Time: 0.00958659
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0107102
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bffbf4543196223 Time: 0.00726308
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x8bac1801ff920aa5 Time: 0.00735086
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9072b4074c1cd76d Time: 0.00914286
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049 Time: 0.00845876
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00707048
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x2cb5b23f5c962046 Time: 0.0158281
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0111627
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5 Time: 0.012032
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539 Time: 0.0102296
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0102609
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.00913371
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e Time: 0.00879435
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0152576
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.00753756
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0109819
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.00786863
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107 Time: 0.00762225
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.00730697
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.009344
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a Time: 0.0062712
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xeb306d27e3a7ca01 Time: 0.00610743
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9f47704ddd29929e Time: 0.0150821
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x294208a8657737e8 Time: 0.00707744
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.0068197
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b64a837aa4a3454 Time: 0.010961
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.00779934
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0155209
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x368150d268fe20d3 Time: 0.00847597
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xff52246c2f8e712b Time: 0.00712621
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xbcb25c3eecd59590 Time: 0.00666265
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00799695
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.00824889
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x850b80ab7d925385 Time: 0.00732891
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x31276c9cc1913670 Time: 0.0105117
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x3ad76abbc8b651dc Time: 0.00713317
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.00894171
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1bd2865ca0bb535d Time: 0.00917029
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0125684
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85 Time: 0.00639205
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9d607f92bc49571b Time: 0.0150528
[01/10/2024-10:51:16] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.392566 seconds. Fastest Tactic: 0xcb4e43bfc9c62daf Time: 0.00596724
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xcb4e43bfc9c62daf
[01/10/2024-10:51:16] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__646 + StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136,56,1) -> Int8(200704,3136,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__646 + StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__646 + StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__650 + StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add + StatefulPartitionedCall/resnet50/conv2_block2_out/Relu
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136,56,1), Int8(802816,3136,56,1) -> Int8(802816,3136,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__650 + StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add + StatefulPartitionedCall/resnet50/conv2_block2_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__650 + StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add + StatefulPartitionedCall/resnet50/conv2_block2_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1), Int8(200704,3136:4,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1), Int8(25088,3136:32,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1), Int8(25088,3136:32,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__654 + StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(802816,3136,56,1) -> Int8(200704,3136,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__654 + StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__654 + StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136:4,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(25088,3136:32,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__658 + StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136,56,1) -> Int8(200704,3136,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__658 + StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__658 + StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__662 + StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add + StatefulPartitionedCall/resnet50/conv2_block3_out/Relu
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136,56,1), Int8(802816,3136,56,1) -> Int8(802816,3136,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__662 + StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add + StatefulPartitionedCall/resnet50/conv2_block3_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__662 + StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add + StatefulPartitionedCall/resnet50/conv2_block3_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1), Int8(200704,3136:4,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1), Int8(25088,3136:32,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1), Int8(25088,3136:32,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:16] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(802816,3136,56,1) -> Int8(100352,784,28,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136:4,56,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0158427
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0164003
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.0137908
[01/10/2024-10:51:16] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00598068 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0137908
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136:4,56,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0162215
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0155794
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.0138439
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0168554
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0138041
[01/10/2024-10:51:16] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00972923 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0138041
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(25088,3136:32,56,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00707048
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00704261
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.00820013
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00683363
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0164165
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0137775
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0132322
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0107207
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00741668
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.00683363
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0132455
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.00893257
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.0068615
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.01024
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.00731428
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0157696
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0114215
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.00727771
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0133785
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.0087083
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0127756
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.0087083
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.00759146
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b4b8ee4e3591584 Time: 0.00900572
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00706351
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.0107624
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00733623
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.00912457
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.0073216
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0130327
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.0086997
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0118266
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0131923
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.00703565
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.00731428
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.00914286
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.0120564
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.014336
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.00824076
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xf845deaac51e3303 Time: 0.0066693
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 0x4713913582d43abf Time: 0.0115678
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x9328dd2fee1ef426 Time: 0.010658
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x6826c3f4aba34a72 Time: 0.00981089
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xe314ee7007c0d0b2 Time: 0.00785323
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xb840759575017742 Time: 0.00576951
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.0102296
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0xefb539b42d3e6615 Time: 0.00618057
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00839517
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.00772235
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 0x594a3bc20779687a Time: 0.0124465
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.0072704
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00640477
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0195474
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00635389
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0160589
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x89403a270b0e65b3 Time: 0.0100742
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0115341
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00596114
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00623304
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.011084
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.00796444
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.00779934
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x3b1cf3c0bd1b7d7f Time: 0.00863946
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0104908
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xce5acc6c4e63526d Time: 0.00813511
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0100059
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0103027
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x4a98bf7e0361ea4c Time: 0.00729234
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.00893257
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.0088804
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00681274
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.00797257
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0x0274f8f5f953354b Time: 0.00686846
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x4795d184d0f26acf Time: 0.0072704
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x0b2f184f333057c2 Time: 0.0116916
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xf61ad57d6312e57c Time: 0.00576951
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00775314
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00769155
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00709834
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.0059275
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00619886
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00658286
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.00895086
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.00820826
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0113765
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xa56acdcff5b4583f Time: 0.00599162
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00707744
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x15841feb1173605d Time: 0.00619276
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x797402402ff99b58 Time: 0.00965486
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0109401
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00664935
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.011399
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0109505
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.009344
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0160427
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.00756836
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.011174
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.00845015
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.00772235
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.00987916
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xeb306d27e3a7ca01 Time: 0.00617447
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00680577
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b64a837aa4a3454 Time: 0.011129
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.00823264
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0156087
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xbcb25c3eecd59590 Time: 0.00686846
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00703565
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.00824889
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.00922514
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0127878
[01/10/2024-10:51:16] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.24472 seconds. Fastest Tactic: 0xb840759575017742 Time: 0.00576951
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xb840759575017742
[01/10/2024-10:51:16] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(100352,784,28,1) -> Int8(100352,784,28,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.048128
[01/10/2024-10:51:16] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.0017341 seconds. Fastest Tactic: 0x8846c5916f34f7e9 Time: 0.048128
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8846c5916f34f7e9
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0478842
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0543208
[01/10/2024-10:51:16] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.0036966 seconds. Fastest Tactic: 0x0f47434ace2a7d18 Time: 0.0478842
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:16] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x0f47434ace2a7d18
[01/10/2024-10:51:16] [V] [TRT] *************** Autotuning format combination: Int8(3136,784:32,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.0107938
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.0128122
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4 Time: 0.00981089
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0392046
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23 Time: 0.00825702
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0246004
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.0111065
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.024576
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792 Time: 0.0196571
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0141365
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.0102922
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0174405
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0197303
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0241371
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4 Time: 0.0148334
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0250149
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.0132987
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.012544
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.0105012
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da Time: 0.0102609
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.0111515
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0154624
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.010961
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673 Time: 0.0125684
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0211905
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18 Time: 0.0189806
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee Time: 0.0146432
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0198583
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0264046
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x0405e3a763219823 Time: 0.0387291
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x8a60cb2150513f2e Time: 0.0253318
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x3a7df5a005634aca Time: 0.024381
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.0130194
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c Time: 0.0239909
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0130061
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd Time: 0.0237401
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0246004
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0134716
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x13463e9bf9ae0d73 Time: 0.0139902
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.0143506
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.0133519
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00894171
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0393509
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0389486
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655 Time: 0.0102713
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00868249
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.0141764
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071 Time: 0.009152
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x3cda2ee55a7d0cc2 Time: 0.0130327
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468 Time: 0.0123246
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0157989
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.01792
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.0170992
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d Time: 0.00977189
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.0102818
[01/10/2024-10:51:16] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986 Time: 0.0086997
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0xa792e2a2dcc5e78f Time: 0.016319
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.0114215
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.010752
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8 Time: 0.0194194
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb Time: 0.0125074
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.0134184
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0183406
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25 Time: 0.0392777
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.0102504
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0200411
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0164978
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x4e4c4bf050b40a1b Time: 0.0126415
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x09727a53770225e8 Time: 0.0170504
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0195657
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96 Time: 0.0152722
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0159451
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d Time: 0.0106998
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50 Time: 0.0136977
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0118942
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd Time: 0.0111177
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6 Time: 0.0158427
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.0107207
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3 Time: 0.0124587
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.0130194
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x446f06d5a2e0bae3 Time: 0.0383269
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x61d05b8ef3670baa Time: 0.0138971
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab Time: 0.0102191
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac Time: 0.0191817
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.0168716
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23 Time: 0.0185783
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b Time: 0.0114103
[01/10/2024-10:51:17] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.185113 seconds. Fastest Tactic: 0x4749124f62d8bd23 Time: 0.00825702
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:17] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x4749124f62d8bd23
[01/10/2024-10:51:17] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D
[01/10/2024-10:51:17] [V] [TRT] *************** Autotuning format combination: Int8(100352,784,28,1) -> Int8(401408,784,28,1) ***************
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:17] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:17] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0137509
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0141365
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.0105535
[01/10/2024-10:51:17] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00616634 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0105535
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:17] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:17] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0137243
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0137376
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.0107938
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0146139
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0103654
[01/10/2024-10:51:17] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.0101393 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0103654
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:17] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:17] [V] [TRT] *************** Autotuning format combination: Int8(3136,784:32,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00679564
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00671584
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.00763765
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00645565
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0129463
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdef93cbb7324a32c Time: 0.00707048
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x11bde0e1d9f2f35d Time: 0.00914286
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0115341
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.011129
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.00937143
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00686846
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91 Time: 0.00672914
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.00728503
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0113878
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xcb4e43bfc9c62daf Time: 0.00597333
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254 Time: 0.00724846
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.00817575
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00678899
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.00910629
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.00776854
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0123733
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0100742
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7 Time: 0.00780704
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.0068197
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0116016
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x10d9759eac59421f Time: 0.00646837
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.00752986
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0107207
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.00752986
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.00785323
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b4b8ee4e3591584 Time: 0.00822451
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f Time: 0.00692419
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00795632
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e Time: 0.00724114
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7ab955b6ffcbeee7 Time: 0.00632845
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x5f7d31a0a5d7764d Time: 0.00696599
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bf090bf2a98ea29 Time: 0.00969387
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.00981089
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1 Time: 0.00693812
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8 Time: 0.00769155
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00711924
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0088718
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.0081026
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27 Time: 0.00636025
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.012227
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.00795632
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.010084
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0108042
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.00726309
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x2df835e0f3719216 Time: 0.00712621
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.00786863
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.00820013
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32ef760caaeaafd7 Time: 0.00607695
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e Time: 0.0106893
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.00957684
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0118716
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2 Time: 0.00658951
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.00773774
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xf845deaac51e3303 Time: 0.00659616
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 0x4713913582d43abf Time: 0.00995718
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x9328dd2fee1ef426 Time: 0.009152
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x6826c3f4aba34a72 Time: 0.00868249
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xe314ee7007c0d0b2 Time: 0.00682667
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xb840759575017742 Time: 0.00649381
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.00891482
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0xefb539b42d3e6615 Time: 0.00718994
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00721189
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x99cccc4c49473ac3 Time: 0.00926172
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x7883d01837952a88 Time: 0.00895086
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.00799695
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1c2c20adff69b217 Time: 0.00808635
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 0x594a3bc20779687a Time: 0.0101035
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d Time: 0.00686846
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.00743131
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x837a9327666fe41b Time: 0.00652301
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x235cece888514c48 Time: 0.008192
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f Time: 0.0066294
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x235fad4a7171cb36 Time: 0.0074752
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00713317
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4 Time: 0.00680577
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0158281
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00634753
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0130194
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610 Time: 0.00931657
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x648d38730af5cbb4 Time: 0.00611352
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x89403a270b0e65b3 Time: 0.00865667
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0107311
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4 Time: 0.0106789
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00679564
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00735817
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.00937143
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32f37afc87197b35 Time: 0.0066294
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.0073216
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.00720457
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x3b1cf3c0bd1b7d7f Time: 0.00776084
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5 Time: 0.00930743
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.00937143
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xce5acc6c4e63526d Time: 0.00688936
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9fd2233523462778 Time: 0.00676904
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xbc24b34ef1c6bc26 Time: 0.00621396
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.00911543
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.00931657
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x4a98bf7e0361ea4c Time: 0.00638569
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac Time: 0.00976213
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.00769155
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.00841573
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x20fc70e3602cda46 Time: 0.00764535
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00728503
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.00727771
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x834cbca762798069 Time: 0.00611352
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x4445151446d948c8 Time: 0.00660281
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0x0274f8f5f953354b Time: 0.00727771
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_conv_fprop_smallk_i8i8_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize32x32_stage4_warpsize2x4x1_r1s1_u1v1_hw0_c128_scalebias Tactic: 0x7ced03e1ef3cd509 Time: 0.00730697
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x4795d184d0f26acf Time: 0.0066028
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x0b2f184f333057c2 Time: 0.00956708
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9 Time: 0.0132854
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xf61ad57d6312e57c Time: 0.00692419
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00702868
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xb2117280dcc1725c Time: 0.00685453
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00729234
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.0068406
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7 Time: 0.00641749
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00713317
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00714014
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00752216
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0xa7ed996d55bb4583 Time: 0.0073216
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.00757606
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.00761456
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e Time: 0.00825702
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.00954758
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xa56acdcff5b4583f Time: 0.00666265
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00773774
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539 Time: 0.00709834
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x15841feb1173605d Time: 0.00686846
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdf9653df9a68d011 Time: 0.00802946
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x797402402ff99b58 Time: 0.00855341
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.00907886
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bffbf4543196223 Time: 0.00680577
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x8bac1801ff920aa5 Time: 0.00709834
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9072b4074c1cd76d Time: 0.00821638
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049 Time: 0.00824889
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00771465
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x2cb5b23f5c962046 Time: 0.0141099
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0107833
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5 Time: 0.0106998
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539 Time: 0.00935314
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.00955733
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.00845876
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e Time: 0.00812699
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0137775
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.00694509
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0100547
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.00738011
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107 Time: 0.007168
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.00672914
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.00847596
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a Time: 0.00633481
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xeb306d27e3a7ca01 Time: 0.0061379
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9f47704ddd29929e Time: 0.0120564
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x294208a8657737e8 Time: 0.00662275
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00635389
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b64a837aa4a3454 Time: 0.00957684
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.00712621
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0123246
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x368150d268fe20d3 Time: 0.00735086
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xff52246c2f8e712b Time: 0.00663605
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xbcb25c3eecd59590 Time: 0.00634753
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00749714
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.00725577
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x850b80ab7d925385 Time: 0.00679564
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x31276c9cc1913670 Time: 0.00881156
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x3ad76abbc8b651dc Time: 0.00681274
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.00791483
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1bd2865ca0bb535d Time: 0.00845876
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0111627
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85 Time: 0.00730697
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9d607f92bc49571b Time: 0.0120442
[01/10/2024-10:51:17] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.425233 seconds. Fastest Tactic: 0xcb4e43bfc9c62daf Time: 0.00597333
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:17] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xcb4e43bfc9c62daf
[01/10/2024-10:51:17] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu
[01/10/2024-10:51:17] [V] [TRT] *************** Autotuning format combination: Int8(802816,3136,56,1), Int8(401408,784,28,1) -> Int8(401408,784,28,1) ***************
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:17] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:17] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136:4,56,1), Int8(100352,784:4,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0219847
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0235102
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.0160264
[01/10/2024-10:51:17] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.006109 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0160264
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:17] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:17] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136:4,56,1), Int8(12544,784:32,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0230296
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0215667
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.0167091
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.023343
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0162215
[01/10/2024-10:51:17] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.0102131 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0162215
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:17] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:17] [V] [TRT] *************** Autotuning format combination: Int8(25088,3136:32,56,1), Int8(12544,784:32,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.0080701
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00822451
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.00996693
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00811073
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0177981
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0151845
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0146139
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0120686
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00896
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.00875993
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0148334
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0106893
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00891482
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0124952
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.00943543
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0173105
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0127878
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.00820013
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0148626
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.00938057
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0142163
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.0115903
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.0104908
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b4b8ee4e3591584 Time: 0.0116241
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00992792
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.0122758
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00824889
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0109505
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00999619
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0152869
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.0100547
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0127878
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0145847
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.00885459
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.00953783
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.010961
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.0140833
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0155648
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0100547
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xf845deaac51e3303 Time: 0.00882017
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 0x4713913582d43abf Time: 0.01407
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x9328dd2fee1ef426 Time: 0.0130859
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x6826c3f4aba34a72 Time: 0.0122758
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xe314ee7007c0d0b2 Time: 0.010961
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xb840759575017742 Time: 0.00775314
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.0125684
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0xefb539b42d3e6615 Time: 0.00952808
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.0096451
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.00969387
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 0x594a3bc20779687a Time: 0.0146432
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.00894171
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00868249
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0229042
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00750446
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0176681
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x89403a270b0e65b3 Time: 0.012544
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0140966
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00774544
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00944457
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.0120808
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.00911543
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.0088718
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x3b1cf3c0bd1b7d7f Time: 0.0105535
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0118266
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xce5acc6c4e63526d Time: 0.0096451
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0123733
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0117479
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x4a98bf7e0361ea4c Time: 0.00856202
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.00973288
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.0102713
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00899657
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.00930743
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0x0274f8f5f953354b Time: 0.00984015
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x4795d184d0f26acf Time: 0.00913371
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x0b2f184f333057c2 Time: 0.0141232
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xf61ad57d6312e57c Time: 0.00822451
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00927086
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00935314
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00848457
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.0082814
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00857923
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00943543
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.0102713
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.00982065
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0136578
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xa56acdcff5b4583f Time: 0.00825702
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.0101717
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x15841feb1173605d Time: 0.00857923
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x797402402ff99b58 Time: 0.0122758
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0130593
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00967436
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.013445
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0132721
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.0115791
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.018432
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.00868249
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0125074
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.0098499
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.00893257
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0116578
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xeb306d27e3a7ca01 Time: 0.00741668
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00800508
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b64a837aa4a3454 Time: 0.0134317
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0111965
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0170829
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xbcb25c3eecd59590 Time: 0.00794819
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00992792
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.00968411
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.0107624
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0143506
[01/10/2024-10:51:17] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.24865 seconds. Fastest Tactic: 0xeb306d27e3a7ca01 Time: 0.00741668
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:17] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xeb306d27e3a7ca01
[01/10/2024-10:51:17] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D
[01/10/2024-10:51:17] [V] [TRT] *************** Autotuning format combination: Int8(401408,784,28,1) -> Int8(100352,784,28,1) ***************
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:17] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:17] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] *************** Autotuning format combination: Int8(100352,784:4,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0247223
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0256731
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.0206054
[01/10/2024-10:51:17] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00557309 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0206054
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:17] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:17] [V] [TRT] *************** Autotuning format combination: Int8(100352,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0255025
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0245029
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.0208353
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0265752
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.020352
[01/10/2024-10:51:17] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00951774 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.020352
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:17] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:17] [V] [TRT] *************** Autotuning format combination: Int8(12544,784:32,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:17] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00794006
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00784553
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.00933486
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00760686
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0225698
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0167578
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0154917
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0127634
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00841573
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91 Time: 0.00772235
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.00823264
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0161727
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254 Time: 0.00891482
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0100547
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00748983
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0120564
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_conv_fprop_smallk_i8i8_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize16x32_stage4_warpsize2x4x1_r1s1_u1v1_hw0_c512_scalebias_relu Tactic: 0x1a8c6f408af8839b Time: 0.011129
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.00885459
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0218802
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0133652
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7 Time: 0.00938057
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.00800508
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0160914
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.0109192
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0159777
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.00986941
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.00900572
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f Time: 0.00651636
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00780704
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e Time: 0.00862225
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.0129585
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1 Time: 0.00636661
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8 Time: 0.00710531
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00818387
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0105012
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00823264
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27 Time: 0.00729966
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0150382
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.00969387
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0135248
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0163677
[01/10/2024-10:51:17] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.00864807
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x2df835e0f3719216 Time: 0.00845015
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.00888901
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.00955733
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e Time: 0.0150528
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.0146286
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0165953
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2 Time: 0.00811073
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.00957684
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.0109819
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00866528
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x7883d01837952a88 Time: 0.0139237
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.00956709
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d Time: 0.008192
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.00889761
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f Time: 0.00790713
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x235fad4a7171cb36 Time: 0.00866528
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00709834
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4 Time: 0.00639205
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0264533
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00704261
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0223817
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610 Time: 0.012544
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0129829
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4 Time: 0.012739
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00660281
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00682667
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.0128122
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.00912457
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.0096061
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5 Time: 0.0127147
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0125806
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0112527
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0118829
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac Time: 0.0127512
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.011129
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.010045
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00773774
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.00894171
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9 Time: 0.0185417
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00861365
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00886319
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00798883
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7 Time: 0.00748983
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00637297
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.0066161
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00711924
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0xa7ed996d55bb4583 Time: 0.0107624
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.011129
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.00936229
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e Time: 0.010334
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0130327
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00775314
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539 Time: 0.00869109
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0142296
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x8bac1801ff920aa5 Time: 0.00817575
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049 Time: 0.00980114
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.0073216
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0135913
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5 Time: 0.0151113
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539 Time: 0.0124709
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0118604
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.010543
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e Time: 0.0102087
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0190354
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.009152
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0132322
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.009088
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107 Time: 0.0088804
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.00842434
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0111515
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a Time: 0.00681274
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9f47704ddd29929e Time: 0.0216503
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00751177
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0087083
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0218802
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x368150d268fe20d3 Time: 0.010752
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00800508
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.00958659
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x850b80ab7d925385 Time: 0.00909714
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x31276c9cc1913670 Time: 0.0138705
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.011174
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0156526
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85 Time: 0.00681274
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9d607f92bc49571b Time: 0.0214413
[01/10/2024-10:51:18] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.275088 seconds. Fastest Tactic: 0x3912ca79eb9a8be1 Time: 0.00636661
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x3912ca79eb9a8be1
[01/10/2024-10:51:18] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__686 + StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(100352,784,28,1) -> Int8(100352,784,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__686 + StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__686 + StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(3136,784:32,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(100352,784,28,1), Int8(401408,784,28,1) -> Int8(401408,784,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1), Int8(100352,784:4,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0154917
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0163027
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.0125806
[01/10/2024-10:51:18] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.00614458 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0125806
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1), Int8(12544,784:32,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0157842
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0151845
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.013046
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0162215
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0128244
[01/10/2024-10:51:18] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.0101297 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0128244
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(3136,784:32,28,1), Int8(12544,784:32,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00735817
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00820013
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.00956709
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00730697
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0143799
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdef93cbb7324a32c Time: 0.00763765
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x11bde0e1d9f2f35d Time: 0.0112978
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0146139
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0125074
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0104908
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00783783
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91 Time: 0.00726309
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.00734354
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0136578
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xcb4e43bfc9c62daf Time: 0.0066294
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254 Time: 0.00815137
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0110052
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00758376
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0120564
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.00820826
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0138705
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0123124
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7 Time: 0.00864807
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.00733623
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0136711
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x10d9759eac59421f Time: 0.00688936
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.00797257
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0119467
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.00978164
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.0087083
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b4b8ee4e3591584 Time: 0.010658
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f Time: 0.00745326
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.0085362
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e Time: 0.00798883
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7ab955b6ffcbeee7 Time: 0.00702172
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x5f7d31a0a5d7764d Time: 0.00857062
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bf090bf2a98ea29 Time: 0.0126415
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.0109714
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1 Time: 0.00713317
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8 Time: 0.00794006
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00805384
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0105326
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.0100547
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27 Time: 0.00708441
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0143214
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.00913371
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.012093
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0120564
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.00751177
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x2df835e0f3719216 Time: 0.0073216
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.00799695
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.011444
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32ef760caaeaafd7 Time: 0.00694509
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e Time: 0.0121905
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.0116353
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0148187
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2 Time: 0.00762225
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.010045
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xf845deaac51e3303 Time: 0.00754526
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 0x4713913582d43abf Time: 0.0127756
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x9328dd2fee1ef426 Time: 0.0129928
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x6826c3f4aba34a72 Time: 0.0118604
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xe314ee7007c0d0b2 Time: 0.00914286
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xb840759575017742 Time: 0.00690329
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.0111965
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0xefb539b42d3e6615 Time: 0.00779934
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00837892
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x99cccc4c49473ac3 Time: 0.0112753
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x7883d01837952a88 Time: 0.0108565
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.00848457
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1c2c20adff69b217 Time: 0.00957684
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 0x594a3bc20779687a Time: 0.0139636
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d Time: 0.00805384
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.00756836
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x837a9327666fe41b Time: 0.00784553
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x235cece888514c48 Time: 0.0106266
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f Time: 0.00718263
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x235fad4a7171cb36 Time: 0.00786863
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00756066
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4 Time: 0.00705655
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0183589
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00683363
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0143506
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610 Time: 0.0103131
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x648d38730af5cbb4 Time: 0.00703565
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x89403a270b0e65b3 Time: 0.0111965
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0129928
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4 Time: 0.0126781
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00704261
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00778394
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.01024
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32f37afc87197b35 Time: 0.00774544
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.00840713
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.00759916
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x3b1cf3c0bd1b7d7f Time: 0.0109192
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5 Time: 0.00996693
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0105221
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xce5acc6c4e63526d Time: 0.00824076
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9fd2233523462778 Time: 0.00711227
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xbc24b34ef1c6bc26 Time: 0.00704261
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0121905
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0109714
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x4a98bf7e0361ea4c Time: 0.00758376
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_conv_fprop_smallk_i8i8_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize32x32_stage4_warpsize2x4x1_r1s1_u1v1_hw0_c128_scalebias_beta_relu Tactic: 0xd4023ece8df38512 Time: 0.00783783
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac Time: 0.0106893
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.00822451
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.00938057
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x20fc70e3602cda46 Time: 0.0100059
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00773774
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.00845876
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x834cbca762798069 Time: 0.00730697
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x4445151446d948c8 Time: 0.00731428
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0x0274f8f5f953354b Time: 0.008192
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x4795d184d0f26acf Time: 0.00789943
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x0b2f184f333057c2 Time: 0.0118942
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9 Time: 0.0156672
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xf61ad57d6312e57c Time: 0.00729234
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00806197
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xb2117280dcc1725c Time: 0.00774544
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00865667
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00821638
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7 Time: 0.00733623
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00734354
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00758376
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00820826
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0xa7ed996d55bb4583 Time: 0.00776854
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.00879435
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.00978164
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e Time: 0.0102713
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0134317
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xa56acdcff5b4583f Time: 0.00748251
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00849318
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539 Time: 0.00802946
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x15841feb1173605d Time: 0.00749714
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdf9653df9a68d011 Time: 0.00936229
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x797402402ff99b58 Time: 0.0120442
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0112077
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bffbf4543196223 Time: 0.00820826
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x8bac1801ff920aa5 Time: 0.00716069
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9072b4074c1cd76d Time: 0.00978164
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049 Time: 0.00936229
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00815137
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x2cb5b23f5c962046 Time: 0.0170504
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0129928
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5 Time: 0.012288
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539 Time: 0.0104594
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0131125
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.010543
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e Time: 0.0100742
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0160264
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.0073216
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0120442
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.00884598
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107 Time: 0.0079807
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.00789943
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0116578
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a Time: 0.00682667
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xeb306d27e3a7ca01 Time: 0.0066294
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9f47704ddd29929e Time: 0.0134716
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x294208a8657737e8 Time: 0.00777624
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00729966
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b64a837aa4a3454 Time: 0.0115903
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.00956709
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0138041
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x368150d268fe20d3 Time: 0.00841573
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xff52246c2f8e712b Time: 0.00792253
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xbcb25c3eecd59590 Time: 0.0071262
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00796444
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.00840713
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x850b80ab7d925385 Time: 0.00724846
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x31276c9cc1913670 Time: 0.0106998
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x3ad76abbc8b651dc Time: 0.00783783
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.00926172
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1bd2865ca0bb535d Time: 0.010201
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0125684
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85 Time: 0.00804572
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9d607f92bc49571b Time: 0.0134583
[01/10/2024-10:51:18] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.398105 seconds. Fastest Tactic: 0xeb306d27e3a7ca01 Time: 0.0066294
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xeb306d27e3a7ca01
[01/10/2024-10:51:18] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__694 + StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(401408,784,28,1) -> Int8(100352,784,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__694 + StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__694 + StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(100352,784:4,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(100352,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(12544,784:32,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__698 + StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(100352,784,28,1) -> Int8(100352,784,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__698 + StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__698 + StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(3136,784:32,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__702 + StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add + StatefulPartitionedCall/resnet50/conv3_block3_out/Relu
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(100352,784,28,1), Int8(401408,784,28,1) -> Int8(401408,784,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__702 + StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add + StatefulPartitionedCall/resnet50/conv3_block3_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__702 + StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add + StatefulPartitionedCall/resnet50/conv3_block3_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1), Int8(100352,784:4,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1), Int8(12544,784:32,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(3136,784:32,28,1), Int8(12544,784:32,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__706 + StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(401408,784,28,1) -> Int8(100352,784,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__706 + StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__706 + StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(100352,784:4,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(100352,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(12544,784:32,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__710 + StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(100352,784,28,1) -> Int8(100352,784,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__710 + StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__710 + StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(3136,784:32,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__714 + StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add + StatefulPartitionedCall/resnet50/conv3_block4_out/Relu
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(100352,784,28,1), Int8(401408,784,28,1) -> Int8(401408,784,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__714 + StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add + StatefulPartitionedCall/resnet50/conv3_block4_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__714 + StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add + StatefulPartitionedCall/resnet50/conv3_block4_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1), Int8(100352,784:4,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1), Int8(12544,784:32,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(3136,784:32,28,1), Int8(12544,784:32,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:18] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(401408,784,28,1) -> Int8(50176,196,14,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(100352,784:4,28,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0249661
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0260389
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.0205845
[01/10/2024-10:51:18] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00582202 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0205845
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(100352,784:4,28,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0258682
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0247223
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.0208353
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0269166
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0203886
[01/10/2024-10:51:18] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00992001 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0203886
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:18] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:18] [V] [TRT] *************** Autotuning format combination: Int8(12544,784:32,28,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00777624
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00801321
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.00937143
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00755296
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0225907
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0171317
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0159451
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0130194
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00839518
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.008192
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0164815
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0102818
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00776084
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.012288
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.00917029
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.02211
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0140035
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.00839518
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0165628
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.0111965
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0167416
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.0100645
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.00912457
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00779164
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.0131923
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00824076
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0111515
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00820826
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0155209
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.0100059
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0142429
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0173105
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.00864807
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.00866528
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0102713
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.015243
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0170017
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.00959634
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.0116353
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00954758
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.00976213
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.00891482
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00695902
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0279893
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00705655
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0225907
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0134317
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.0066161
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.006656
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.0134051
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.00914286
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.00981089
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0129707
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0117029
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0121661
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.0113653
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.0106893
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00769925
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.00911543
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00888901
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00884598
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00800508
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00618667
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00679564
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00724114
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.0118491
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.00956709
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0136578
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00775314
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0143506
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00730697
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0141232
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0123124
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.0107311
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0197669
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.00958659
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0134849
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.00956708
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.00892343
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0118379
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00753756
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.00931657
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0220891
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00796444
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.00959634
[01/10/2024-10:51:18] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.0118716
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.015872
[01/10/2024-10:51:19] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.19451 seconds. Fastest Tactic: 0xcddae68de84cc6ee Time: 0.00618667
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:19] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xcddae68de84cc6ee
[01/10/2024-10:51:19] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D
[01/10/2024-10:51:19] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1) -> Int8(50176,196,14,1) ***************
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:19] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:19] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0885029
[01/10/2024-10:51:19] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00228111 seconds. Fastest Tactic: 0x8846c5916f34f7e9 Time: 0.0885029
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:19] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8846c5916f34f7e9
[01/10/2024-10:51:19] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0883566
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.101449
[01/10/2024-10:51:19] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00498676 seconds. Fastest Tactic: 0x0f47434ace2a7d18 Time: 0.0883566
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:19] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x0f47434ace2a7d18
[01/10/2024-10:51:19] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.0154624
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.0181211
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4 Time: 0.013445
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0681204
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23 Time: 0.0103863
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0392046
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.0154917
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0393874
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792 Time: 0.0308955
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0202789
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.0139503
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0266484
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0301056
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.037888
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4 Time: 0.0228415
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0405943
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.0193829
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.0184503
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.0146139
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da Time: 0.0146432
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.0156965
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0234684
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.0145993
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673 Time: 0.0181211
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0321536
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18 Time: 0.0293449
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee Time: 0.0214622
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0303397
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0428983
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x0405e3a763219823 Time: 0.0674865
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x8a60cb2150513f2e Time: 0.041728
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x3a7df5a005634aca Time: 0.039936
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.0191269
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c Time: 0.0374126
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.018176
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd Time: 0.0373029
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0380709
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0193829
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x13463e9bf9ae0d73 Time: 0.0218802
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.0224862
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.0207099
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.0117929
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0601234
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0681691
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655 Time: 0.0143799
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.010961
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.0220682
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071 Time: 0.011971
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x3cda2ee55a7d0cc2 Time: 0.0204591
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468 Time: 0.0174893
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0227788
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0259901
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.0271116
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d Time: 0.0129585
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.0141232
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986 Time: 0.0112415
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0xa792e2a2dcc5e78f Time: 0.0258682
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.0157403
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.0146286
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8 Time: 0.0296375
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb Time: 0.0177331
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.0192
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0277943
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25 Time: 0.0602697
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.0136578
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0312466
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0235938
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x4e4c4bf050b40a1b Time: 0.0185966
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x09727a53770225e8 Time: 0.027136
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0299008
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96 Time: 0.0221518
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0246491
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d Time: 0.0148626
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50 Time: 0.0200046
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0166441
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd Time: 0.0153015
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6 Time: 0.0227579
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.0147749
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3 Time: 0.0182674
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.0189806
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x446f06d5a2e0bae3 Time: 0.0674865
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x61d05b8ef3670baa Time: 0.0216503
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab Time: 0.0143214
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac Time: 0.0294034
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.0264533
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23 Time: 0.0270141
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b Time: 0.0162215
[01/10/2024-10:51:19] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.212239 seconds. Fastest Tactic: 0x4749124f62d8bd23 Time: 0.0103863
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:19] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x4749124f62d8bd23
[01/10/2024-10:51:19] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D
[01/10/2024-10:51:19] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:19] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:19] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0158135
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.016449
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.013937
[01/10/2024-10:51:19] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.0065893 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.013937
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:19] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:19] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0162052
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0155941
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.014203
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0169204
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0137509
[01/10/2024-10:51:19] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.0109081 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0137509
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:19] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:19] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00707048
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00710531
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.00818387
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.0068197
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0159614
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdef93cbb7324a32c Time: 0.00657621
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x11bde0e1d9f2f35d Time: 0.0106371
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.013179
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0125318
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0104594
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00748983
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91 Time: 0.00692419
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.00773774
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0131258
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xcb4e43bfc9c62daf Time: 0.00615009
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254 Time: 0.00773774
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0086997
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00707048
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.01024
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.00844155
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0155502
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0111627
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7 Time: 0.00839518
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.0073216
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0132056
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x10d9759eac59421f Time: 0.00684757
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.0087083
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0123002
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.00863946
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.0088718
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b4b8ee4e3591584 Time: 0.0088718
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f Time: 0.00718263
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00729234
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e Time: 0.00758376
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7ab955b6ffcbeee7 Time: 0.00654296
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x5f7d31a0a5d7764d Time: 0.00773004
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bf090bf2a98ea29 Time: 0.0105117
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.0109087
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1 Time: 0.00709834
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8 Time: 0.00686846
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00732891
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.009408
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00748983
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27 Time: 0.00660281
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0133253
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.00865667
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0113765
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0125806
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.00784553
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x2df835e0f3719216 Time: 0.00773004
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.00820013
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.00850178
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32ef760caaeaafd7 Time: 0.00636025
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e Time: 0.0121295
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.0111627
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0134184
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2 Time: 0.00724846
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.00827327
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xf845deaac51e3303 Time: 0.0068197
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 0x4713913582d43abf Time: 0.0113765
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x9328dd2fee1ef426 Time: 0.00987916
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x6826c3f4aba34a72 Time: 0.00948115
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xe314ee7007c0d0b2 Time: 0.00759916
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xb840759575017742 Time: 0.0068406
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.00958659
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0xefb539b42d3e6615 Time: 0.00732891
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00757606
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x99cccc4c49473ac3 Time: 0.0106684
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x7883d01837952a88 Time: 0.0106162
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.00869109
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1c2c20adff69b217 Time: 0.00914286
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 0x594a3bc20779687a Time: 0.0116241
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d Time: 0.00733623
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.00799695
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x837a9327666fe41b Time: 0.00688936
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x235cece888514c48 Time: 0.009088
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f Time: 0.00724114
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x235fad4a7171cb36 Time: 0.00821638
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00749714
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4 Time: 0.00700082
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0184869
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_conv_fprop_smallk_i8i8_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize32x32_stage4_warpsize2x4x1_r1s1_u1v1_hw0_c256_scalebias Tactic: 0xc39d8a5d95d69acd Time: 0.0096256
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00643657
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0161727
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610 Time: 0.0102922
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x648d38730af5cbb4 Time: 0.00639205
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x89403a270b0e65b3 Time: 0.00943543
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0116691
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4 Time: 0.011444
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00711227
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00756836
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.0106998
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32f37afc87197b35 Time: 0.00724114
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.00793023
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.00786863
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x3b1cf3c0bd1b7d7f Time: 0.0080701
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5 Time: 0.0104803
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0104699
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xce5acc6c4e63526d Time: 0.00732891
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9fd2233523462778 Time: 0.00685453
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xbc24b34ef1c6bc26 Time: 0.00681274
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.00978164
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0102609
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x4a98bf7e0361ea4c Time: 0.00693116
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac Time: 0.0107311
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.00890622
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.00912457
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x20fc70e3602cda46 Time: 0.00845015
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00796444
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.00778394
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x834cbca762798069 Time: 0.00684757
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x4445151446d948c8 Time: 0.0068197
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0x0274f8f5f953354b Time: 0.00793023
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x4795d184d0f26acf Time: 0.00727771
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x0b2f184f333057c2 Time: 0.010961
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9 Time: 0.0148334
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xf61ad57d6312e57c Time: 0.00696599
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00774544
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xb2117280dcc1725c Time: 0.00637297
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00773774
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00710531
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7 Time: 0.0068197
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00713317
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00751177
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00681274
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0xa7ed996d55bb4583 Time: 0.00863086
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.0088804
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.00825702
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e Time: 0.00907886
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0108042
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xa56acdcff5b4583f Time: 0.00706351
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.0082814
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539 Time: 0.00772235
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x15841feb1173605d Time: 0.00729966
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdf9653df9a68d011 Time: 0.00926172
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x797402402ff99b58 Time: 0.0096061
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0109296
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bffbf4543196223 Time: 0.00732891
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x8bac1801ff920aa5 Time: 0.00759146
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9072b4074c1cd76d Time: 0.009344
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049 Time: 0.00899657
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00694509
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x2cb5b23f5c962046 Time: 0.0158964
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0115791
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5 Time: 0.0120808
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539 Time: 0.0102922
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0102504
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.009152
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e Time: 0.00889761
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.015477
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.00758376
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0109939
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.00796444
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107 Time: 0.00775314
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.00732891
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.00933486
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a Time: 0.00636661
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xeb306d27e3a7ca01 Time: 0.00622668
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9f47704ddd29929e Time: 0.015243
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x294208a8657737e8 Time: 0.00728503
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00680577
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b64a837aa4a3454 Time: 0.0109819
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.00808635
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0155063
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x368150d268fe20d3 Time: 0.00863946
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xff52246c2f8e712b Time: 0.00729234
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xbcb25c3eecd59590 Time: 0.00688936
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00806197
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.00838705
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x850b80ab7d925385 Time: 0.00752986
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x31276c9cc1913670 Time: 0.0105012
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x3ad76abbc8b651dc Time: 0.00710531
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.00912457
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1bd2865ca0bb535d Time: 0.00954758
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0126293
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85 Time: 0.0066028
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9d607f92bc49571b Time: 0.015243
[01/10/2024-10:51:19] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.428041 seconds. Fastest Tactic: 0xcb4e43bfc9c62daf Time: 0.00615009
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:19] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xcb4e43bfc9c62daf
[01/10/2024-10:51:19] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu
[01/10/2024-10:51:19] [V] [TRT] *************** Autotuning format combination: Int8(401408,784,28,1), Int8(200704,196,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:19] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:19] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] *************** Autotuning format combination: Int8(100352,784:4,28,1), Int8(50176,196:4,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.027453
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0284769
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.0228624
[01/10/2024-10:51:19] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.0073572 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0228624
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:19] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:19] [V] [TRT] *************** Autotuning format combination: Int8(100352,784:4,28,1), Int8(6272,196:32,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0284282
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.027453
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.0233012
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0294912
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0229042
[01/10/2024-10:51:19] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.012045 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0229042
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:19] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:19] [V] [TRT] *************** Autotuning format combination: Int8(12544,784:32,28,1), Int8(6272,196:32,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:19] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00863086
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00910629
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.0109714
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00873412
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0239177
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.018176
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0171804
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.014336
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00911543
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.00972312
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0178143
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0122392
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.0087083
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0140966
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.0107102
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0232594
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.015243
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.00909714
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0178143
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.0120442
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0180297
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.0115791
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.0110389
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00856202
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.0145115
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00901486
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0123368
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00941714
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0172292
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.0111965
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0151406
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.018432
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.0102504
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.0103131
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0118716
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.0172942
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.018048
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.011399
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.0137775
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.0107624
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.0111402
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.0104072
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00876854
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0306615
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00788403
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0240884
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0155794
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00831391
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00904229
[01/10/2024-10:51:19] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.0142828
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.0102504
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.0105221
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0141365
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0137376
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0132721
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.0123002
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.0116016
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.009472
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.0104803
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00961585
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.0103027
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00913371
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00829765
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00879435
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00891482
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.0132588
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.0109505
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0155063
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.010123
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0163515
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00834642
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0158281
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0143653
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.0129707
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0216503
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.0102504
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0148334
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.011084
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.0101425
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0131258
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00875133
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0109505
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0235102
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00966461
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.010334
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.013445
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.017343
[01/10/2024-10:51:20] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.21901 seconds. Fastest Tactic: 0x311b82feb19aef19 Time: 0.00788403
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:20] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x311b82feb19aef19
[01/10/2024-10:51:20] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D
[01/10/2024-10:51:20] [V] [TRT] *************** Autotuning format combination: Int8(200704,196,14,1) -> Int8(50176,196,14,1) ***************
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:20] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:20] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:20] [V] [TRT] *************** Autotuning format combination: Int8(50176,196:4,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0424594
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0441783
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.0340846
[01/10/2024-10:51:20] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00653563 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0340846
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:20] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:20] [V] [TRT] *************** Autotuning format combination: Int8(50176,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.044032
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0422766
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.0346697
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0467749
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0339968
[01/10/2024-10:51:20] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.0110053 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0339968
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:20] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:20] [V] [TRT] *************** Autotuning format combination: Int8(6272,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00943543
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.0100059
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.0115903
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00922514
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0354011
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0235102
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0215458
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0173105
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.0100937
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91 Time: 0.009344
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.0107102
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0224026
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254 Time: 0.0114103
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0126537
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00917943
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0159289
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.0120686
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0346697
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0180114
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7 Time: 0.0121783
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.00982065
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.02211
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.0157842
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0228206
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.012544
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.011444
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f Time: 0.00750446
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00939886
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e Time: 0.0109192
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.0175543
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1 Time: 0.00686846
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8 Time: 0.00866528
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.0100547
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0143506
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00980114
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27 Time: 0.009344
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0200594
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.0124709
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0181577
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0237401
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.0118604
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x2df835e0f3719216 Time: 0.0116128
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.0116241
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0114328
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e Time: 0.0209816
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.0212114
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0223817
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2 Time: 0.00986941
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0121295
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.0139636
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.0100352
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x7883d01837952a88 Time: 0.0207726
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.0132588
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d Time: 0.00969387
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.0120808
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f Time: 0.00959634
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x235fad4a7171cb36 Time: 0.0118491
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00813511
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4 Time: 0.00748983
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.039936
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00822451
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0352549
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610 Time: 0.0170829
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_conv_fprop_smallk_i8i8_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize16x32_stage5_warpsize1x4x2_r1s1_u1v1_hw0_c1024_scalebias_relu Tactic: 0x11898100e6875c92 Time: 0.0135381
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0168229
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4 Time: 0.0164653
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00771465
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00773004
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.017408
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.0116466
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.0132189
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5 Time: 0.017343
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0172617
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.014203
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0156379
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac Time: 0.0175543
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.0159126
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.0139237
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00935314
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.0113653
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9 Time: 0.0258926
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.0104594
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.0111402
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00958659
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7 Time: 0.00906971
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00709834
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00754526
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00843294
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0xa7ed996d55bb4583 Time: 0.0155063
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.0160102
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.0120564
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e Time: 0.0134317
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0171154
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00929829
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539 Time: 0.011129
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0212114
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x8bac1801ff920aa5 Time: 0.010543
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049 Time: 0.0138041
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00868249
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0183589
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5 Time: 0.0211905
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539 Time: 0.0171642
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0148334
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.0134583
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e Time: 0.0132455
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0265021
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.0127512
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0178306
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.0114328
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107 Time: 0.011444
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.0102713
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0146139
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a Time: 0.00800508
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9f47704ddd29929e Time: 0.0342309
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00949943
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0104908
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0348745
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x368150d268fe20d3 Time: 0.0155941
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00952686
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.0120442
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x850b80ab7d925385 Time: 0.0125562
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x31276c9cc1913670 Time: 0.0207517
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.0159289
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0216712
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85 Time: 0.00802946
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9d607f92bc49571b Time: 0.0344649
[01/10/2024-10:51:20] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.285178 seconds. Fastest Tactic: 0x3912ca79eb9a8be1 Time: 0.00686846
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:20] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x3912ca79eb9a8be1
[01/10/2024-10:51:20] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__738 + StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D
[01/10/2024-10:51:20] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1) -> Int8(50176,196,14,1) ***************
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__738 + StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:20] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__738 + StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:20] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:20] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:20] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:20] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:20] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu
[01/10/2024-10:51:20] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1), Int8(200704,196,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:20] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:20] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:20] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1), Int8(50176,196:4,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0178651
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0184869
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.0160427
[01/10/2024-10:51:20] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.00631611 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0160427
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:20] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:20] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1), Int8(6272,196:32,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0184137
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0178651
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.016384
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0191269
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0160914
[01/10/2024-10:51:20] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.0105979 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0160914
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:20] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:20] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1), Int8(6272,196:32,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00759916
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00800508
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.00977188
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00773004
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0173592
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdef93cbb7324a32c Time: 0.00707744
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x11bde0e1d9f2f35d Time: 0.012605
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0143506
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0136844
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0116128
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00863086
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91 Time: 0.00746788
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.00799695
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0144677
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xcb4e43bfc9c62daf Time: 0.00677569
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254 Time: 0.00868249
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.010449
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00817575
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0121905
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.00863946
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0167253
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.012288
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7 Time: 0.00917029
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.00796444
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0144823
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x10d9759eac59421f Time: 0.00714606
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.00918857
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0134849
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.0113653
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.00979139
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b4b8ee4e3591584 Time: 0.0112302
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f Time: 0.00748251
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00802946
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e Time: 0.00843294
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7ab955b6ffcbeee7 Time: 0.00724114
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x5f7d31a0a5d7764d Time: 0.00926172
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bf090bf2a98ea29 Time: 0.0133918
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.0120198
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1 Time: 0.00730697
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8 Time: 0.0071471
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00793792
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0109087
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00842434
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27 Time: 0.00756836
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.014965
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.00973288
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.012288
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0134982
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.00800508
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x2df835e0f3719216 Time: 0.00781474
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.00841573
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.00995718
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32ef760caaeaafd7 Time: 0.00733623
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e Time: 0.0135647
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.0129463
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0143945
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2 Time: 0.00821638
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0100937
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xf845deaac51e3303 Time: 0.0079807
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 0x4713913582d43abf Time: 0.0136977
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x9328dd2fee1ef426 Time: 0.0121173
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x6826c3f4aba34a72 Time: 0.0118154
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0xe314ee7007c0d0b2 Time: 0.0105012
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xb840759575017742 Time: 0.00723383
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.0115678
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0xefb539b42d3e6615 Time: 0.00799695
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00864807
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x99cccc4c49473ac3 Time: 0.0126415
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x7883d01837952a88 Time: 0.0123246
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.00892343
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1c2c20adff69b217 Time: 0.0106266
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 0x594a3bc20779687a Time: 0.0136711
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d Time: 0.00834641
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.00815949
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x837a9327666fe41b Time: 0.00816762
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x235cece888514c48 Time: 0.0109923
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f Time: 0.00775314
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x235fad4a7171cb36 Time: 0.00845015
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00797257
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4 Time: 0.00730697
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0207726
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00688936
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.017538
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610 Time: 0.0113315
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x648d38730af5cbb4 Time: 0.0073216
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x89403a270b0e65b3 Time: 0.0115791
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0137775
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4 Time: 0.0133918
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00731428
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.0079807
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.011399
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x32f37afc87197b35 Time: 0.00843294
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.00892343
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.00824076
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 0x3b1cf3c0bd1b7d7f Time: 0.00956709
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5 Time: 0.0111852
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0116578
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xce5acc6c4e63526d Time: 0.00844155
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9fd2233523462778 Time: 0.00722651
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xbc24b34ef1c6bc26 Time: 0.00754526
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0119101
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0115003
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x4a98bf7e0361ea4c Time: 0.00817575
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac Time: 0.0118604
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.00950857
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.010201
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x20fc70e3602cda46 Time: 0.0105535
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00863086
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.00914286
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x834cbca762798069 Time: 0.00792253
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x4445151446d948c8 Time: 0.00729966
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 0x0274f8f5f953354b Time: 0.00891482
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x4795d184d0f26acf Time: 0.0088718
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x0b2f184f333057c2 Time: 0.0130327
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9 Time: 0.0170504
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xf61ad57d6312e57c Time: 0.0073216
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00898743
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xb2117280dcc1725c Time: 0.00726309
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00932571
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00820013
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_conv_fprop_smallk_i8i8_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize32x32_stage4_warpsize2x4x1_r1s1_u1v1_hw0_c256_scalebias_beta_relu Tactic: 0x7da1544a119637e7 Time: 0.00903314
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7 Time: 0.00760686
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00731428
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00770695
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00755296
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0xa7ed996d55bb4583 Time: 0.00914286
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.0100157
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.00959634
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e Time: 0.0107833
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.012544
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xa56acdcff5b4583f Time: 0.00754526
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.009088
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539 Time: 0.0087083
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x15841feb1173605d Time: 0.00798883
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xdf9653df9a68d011 Time: 0.0106057
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 0x797402402ff99b58 Time: 0.0120686
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0127878
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x7bffbf4543196223 Time: 0.00884598
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x8bac1801ff920aa5 Time: 0.00774544
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x9072b4074c1cd76d Time: 0.0107207
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049 Time: 0.0100254
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00756066
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x2cb5b23f5c962046 Time: 0.0186331
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0131657
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5 Time: 0.0134317
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539 Time: 0.0114103
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0121295
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.011174
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e Time: 0.0106371
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0173917
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.00796444
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.012288
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.00937143
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107 Time: 0.00867388
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.00847597
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0105221
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a Time: 0.00686846
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xeb306d27e3a7ca01 Time: 0.00683363
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9f47704ddd29929e Time: 0.0163677
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x294208a8657737e8 Time: 0.00848457
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00762995
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0x6b64a837aa4a3454 Time: 0.0130194
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0108983
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0169691
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x368150d268fe20d3 Time: 0.00957684
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0xff52246c2f8e712b Time: 0.00845875
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 0xbcb25c3eecd59590 Time: 0.00773774
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00854481
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.00966461
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x850b80ab7d925385 Time: 0.00777624
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x31276c9cc1913670 Time: 0.0123002
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x3ad76abbc8b651dc Time: 0.00824889
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.0102818
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1_epifadd Tactic: 0x1bd2865ca0bb535d Time: 0.0112302
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0139902
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85 Time: 0.00746057
[01/10/2024-10:51:20] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9d607f92bc49571b Time: 0.0165953
[01/10/2024-10:51:20] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.42348 seconds. Fastest Tactic: 0xcb4e43bfc9c62daf Time: 0.00677569
[01/10/2024-10:51:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:20] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xcb4e43bfc9c62daf
[01/10/2024-10:51:20] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__746 + StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D
[01/10/2024-10:51:20] [V] [TRT] *************** Autotuning format combination: Int8(200704,196,14,1) -> Int8(50176,196,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__746 + StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__746 + StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196:4,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(6272,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__750 + StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1) -> Int8(50176,196,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__750 + StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__750 + StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__754 + StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add + StatefulPartitionedCall/resnet50/conv4_block3_out/Relu
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1), Int8(200704,196,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__754 + StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add + StatefulPartitionedCall/resnet50/conv4_block3_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__754 + StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add + StatefulPartitionedCall/resnet50/conv4_block3_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1), Int8(50176,196:4,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1), Int8(6272,196:32,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1), Int8(6272,196:32,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__758 + StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(200704,196,14,1) -> Int8(50176,196,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__758 + StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__758 + StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196:4,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(6272,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__762 + StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1) -> Int8(50176,196,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__762 + StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__762 + StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__766 + StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add + StatefulPartitionedCall/resnet50/conv4_block4_out/Relu
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1), Int8(200704,196,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__766 + StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add + StatefulPartitionedCall/resnet50/conv4_block4_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__766 + StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add + StatefulPartitionedCall/resnet50/conv4_block4_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1), Int8(50176,196:4,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1), Int8(6272,196:32,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1), Int8(6272,196:32,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__770 + StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(200704,196,14,1) -> Int8(50176,196,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__770 + StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__770 + StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196:4,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(6272,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__774 + StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1) -> Int8(50176,196,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__774 + StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__774 + StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__778 + StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add + StatefulPartitionedCall/resnet50/conv4_block5_out/Relu
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1), Int8(200704,196,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__778 + StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add + StatefulPartitionedCall/resnet50/conv4_block5_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__778 + StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add + StatefulPartitionedCall/resnet50/conv4_block5_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1), Int8(50176,196:4,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1), Int8(6272,196:32,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1), Int8(6272,196:32,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__782 + StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(200704,196,14,1) -> Int8(50176,196,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__782 + StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__782 + StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196:4,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(6272,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__786 + StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1) -> Int8(50176,196,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__786 + StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__786 + StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__790 + StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add + StatefulPartitionedCall/resnet50/conv4_block6_out/Relu
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1), Int8(200704,196,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__790 + StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add + StatefulPartitionedCall/resnet50/conv4_block6_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__790 + StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add + StatefulPartitionedCall/resnet50/conv4_block6_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1), Int8(50176,196:4,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1), Int8(6272,196:32,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1), Int8(6272,196:32,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:21] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(200704,196,14,1) -> Int8(25088,49,7,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196:4,14,1) -> Int8(6272,49:4,7,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0425691
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0444709
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.0341138
[01/10/2024-10:51:21] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.0073952 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0341138
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(50176,196:4,14,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0442514
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0423131
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.0345819
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0464091
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0338505
[01/10/2024-10:51:21] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.0121966 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0338505
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(6272,196:32,14,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00938057
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.0103131
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.0117254
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.009152
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0351378
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.024381
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0216921
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0173105
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.0102191
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.0109819
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0228206
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0134716
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00935314
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0169366
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.012288
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0344942
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0186697
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.0100157
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0222145
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.0162052
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0226325
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.0134849
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.0115566
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00954758
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.0177331
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.0102922
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0143506
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00979139
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0202789
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.0126415
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0188709
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0234684
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.0118604
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.0117366
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0132721
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.0212323
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0229042
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0123977
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.0141631
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.0109087
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.013046
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.012093
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00824889
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0375223
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00818387
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0353134
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0168229
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00773004
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00779164
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.0175218
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.0116466
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.0134184
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0172617
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0150674
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0166441
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.0160102
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.0132854
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00931657
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.0113878
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.0106893
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.0112077
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00990842
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00714014
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00761456
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00823264
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.0154185
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.0123246
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0187611
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00932571
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0209816
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.0086997
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0193463
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0157842
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.0135514
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.026819
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.0129707
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.01792
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.0115116
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.0107729
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0168066
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00895086
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0111965
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0348745
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00955733
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.0123124
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.0150821
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0216503
[01/10/2024-10:51:21] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.214089 seconds. Fastest Tactic: 0xcddae68de84cc6ee Time: 0.00714014
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xcddae68de84cc6ee
[01/10/2024-10:51:21] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(25088,49,7,1) -> Int8(25088,49,7,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1) -> Int8(6272,49:4,7,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.181394
[01/10/2024-10:51:21] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00408344 seconds. Fastest Tactic: 0x8846c5916f34f7e9 Time: 0.181394
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8846c5916f34f7e9
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.164571
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.196608
[01/10/2024-10:51:21] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00749907 seconds. Fastest Tactic: 0x0f47434ace2a7d18 Time: 0.164571
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:21] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x0f47434ace2a7d18
[01/10/2024-10:51:21] [V] [TRT] *************** Autotuning format combination: Int8(784,49:32,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.0265265
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.0284769
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4 Time: 0.0211278
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.125513
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23 Time: 0.0148187
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0683154
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.024381
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0685592
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792 Time: 0.0525653
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0325632
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.0214831
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.045312
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0505661
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0648046
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4 Time: 0.0376686
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0718263
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.0318903
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.0302519
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.0224026
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da Time: 0.0229669
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.0249173
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0382903
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.0218802
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673 Time: 0.0289061
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.053053
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18 Time: 0.0496884
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee Time: 0.0403383
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0507611
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0758491
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x0405e3a763219823 Time: 0.125147
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x8a60cb2150513f2e Time: 0.073728
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x3a7df5a005634aca Time: 0.0709486
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.0316562
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c Time: 0.064512
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0291401
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd Time: 0.0644145
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0651947
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0310126
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x13463e9bf9ae0d73 Time: 0.0374126
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.0380343
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.0348745
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.017278
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.102912
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.126098
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655 Time: 0.0229669
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.0158281
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.0370834
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071 Time: 0.0177168
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x3cda2ee55a7d0cc2 Time: 0.034699
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468 Time: 0.028672
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0369006
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0483109
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.0476526
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d Time: 0.018944
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.0218593
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986 Time: 0.0166116
[01/10/2024-10:51:21] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0xa792e2a2dcc5e78f Time: 0.0446903
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.0246979
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.0227997
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8 Time: 0.050371
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb Time: 0.0283307
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.0306907
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0478354
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25 Time: 0.105765
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.0205636
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.053053
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0384
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x4e4c4bf050b40a1b Time: 0.0315685
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x09727a53770225e8 Time: 0.0476404
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0504198
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96 Time: 0.0357669
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0427886
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d Time: 0.0234266
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50 Time: 0.032885
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0264046
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd Time: 0.0239421
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6 Time: 0.0365349
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.0232803
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3 Time: 0.0334409
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.0309541
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x446f06d5a2e0bae3 Time: 0.125367
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r3s3 Tactic: 0x61d05b8ef3670baa Time: 0.0362423
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab Time: 0.0227788
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac Time: 0.0499322
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.0451291
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23 Time: 0.043264
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b Time: 0.0258682
[01/10/2024-10:51:22] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.345733 seconds. Fastest Tactic: 0x4749124f62d8bd23 Time: 0.0148187
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:22] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x4749124f62d8bd23
[01/10/2024-10:51:22] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D
[01/10/2024-10:51:22] [V] [TRT] *************** Autotuning format combination: Int8(25088,49,7,1) -> Int8(100352,49,7,1) ***************
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:22] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:22] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:22] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0247223
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0257219
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.0205845
[01/10/2024-10:51:22] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.00822133 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0205845
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:22] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:22] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0254537
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0244785
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.0210024
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0266728
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.020352
[01/10/2024-10:51:22] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.0141163 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.020352
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:22] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:22] [V] [TRT] *************** Autotuning format combination: Int8(784,49:32,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00787633
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00796444
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.00937143
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00772235
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0223399
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.016579
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0155355
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0127634
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00838705
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91 Time: 0.00776084
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.00896914
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0161727
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254 Time: 0.00892343
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0100157
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00753756
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0121783
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.00928914
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.021922
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0134051
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7 Time: 0.00961585
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.00807822
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0160102
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.0111852
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0156965
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.00993768
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.00913371
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f Time: 0.006656
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00783783
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e Time: 0.0086997
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.0131657
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1 Time: 0.00697295
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8 Time: 0.00711227
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.00818387
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.010846
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00823264
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27 Time: 0.00734354
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0153893
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.00999619
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0136844
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0160914
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.00891482
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x2df835e0f3719216 Time: 0.00867388
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.00931657
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.00953783
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e Time: 0.0150528
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.0143799
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0164165
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2 Time: 0.00805384
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.00954758
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.0109939
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.0086997
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x7883d01837952a88 Time: 0.0139237
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.00981089
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d Time: 0.00829765
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.00909714
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f Time: 0.00796444
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x235fad4a7171cb36 Time: 0.00907886
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00706351
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4 Time: 0.00651636
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.024064
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00695206
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0224653
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610 Time: 0.0125196
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.013312
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4 Time: 0.0130992
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.0066826
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00777624
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.0129707
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.00914286
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_conv_fprop_smallk_i8i8_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize16x32_stage4_warpsize2x4x1_r1s1_u1v1_hw0_c512_scalebias Tactic: 0xd2c4ff4eec21dbcc Time: 0.0102609
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.00957684
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5 Time: 0.0127512
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0127756
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.011219
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0120564
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac Time: 0.0130194
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.0112527
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.0104803
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00777624
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.00890622
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9 Time: 0.0186331
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00862225
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00888901
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00795632
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7 Time: 0.00752986
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00711924
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00667595
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00731428
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0xa7ed996d55bb4583 Time: 0.0109401
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.0109087
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.00950857
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e Time: 0.0105117
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0129585
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00778394
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539 Time: 0.00869109
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0141897
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x8bac1801ff920aa5 Time: 0.00879435
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049 Time: 0.0102818
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00732891
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0138838
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5 Time: 0.0152283
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539 Time: 0.0125806
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0117591
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.0105012
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e Time: 0.0102922
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0191634
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.00931657
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0132455
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.0104058
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107 Time: 0.0088804
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.00843294
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.011174
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a Time: 0.00685453
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9f47704ddd29929e Time: 0.0213995
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.0074752
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0086997
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0218384
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x368150d268fe20d3 Time: 0.0107102
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00910629
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.00954758
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x850b80ab7d925385 Time: 0.00913371
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x31276c9cc1913670 Time: 0.0138971
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.0109296
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0155355
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85 Time: 0.00702172
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9d607f92bc49571b Time: 0.0216503
[01/10/2024-10:51:22] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.374384 seconds. Fastest Tactic: 0x31de506085a332d4 Time: 0.00651636
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:22] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x31de506085a332d4
[01/10/2024-10:51:22] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu
[01/10/2024-10:51:22] [V] [TRT] *************** Autotuning format combination: Int8(200704,196,14,1), Int8(100352,49,7,1) -> Int8(100352,49,7,1) ***************
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:22] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:22] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:22] [V] [TRT] *************** Autotuning format combination: Int8(50176,196:4,14,1), Int8(25088,49:4,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0449463
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0466651
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.0363154
[01/10/2024-10:51:22] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.0113364 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0363154
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:22] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:22] [V] [TRT] *************** Autotuning format combination: Int8(50176,196:4,14,1), Int8(3136,49:32,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.046592
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0447634
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.0370469
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0488594
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0362057
[01/10/2024-10:51:22] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.0184167 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0362057
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:22] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:22] [V] [TRT] *************** Autotuning format combination: Int8(6272,196:32,14,1), Int8(3136,49:32,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.01024
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.0109192
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.0132854
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.0102609
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0357303
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0250149
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.02211
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0177981
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.0106893
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.0123246
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0236774
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0146286
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.0100547
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.018304
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.0131923
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0353134
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0193646
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.0106057
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0230296
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.0168716
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0236356
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.014203
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.0120686
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.010045
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.0186697
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.0108983
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0156672
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.0107207
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0217757
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.0135913
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.019584
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0241371
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.0125074
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.0129463
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0143653
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.0227997
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.023552
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0138838
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.0157696
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.0114553
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.0138971
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.0127634
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00865667
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0407771
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00871691
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0362789
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0185783
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00808635
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.00961585
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.018048
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.0125074
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.0141365
[01/10/2024-10:51:22] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0180114
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0166116
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0177981
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.0182857
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.014336
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.0096451
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.012227
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.011354
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.0126659
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.0110502
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00895086
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00880296
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.0096256
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.0164328
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.0136844
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0202971
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00985966
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0225489
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00935314
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0207726
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0172942
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.0151845
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.028672
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.0136578
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0189257
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.0125684
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.0116128
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0177818
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00982065
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0142019
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0355474
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.0115678
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.0129707
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.0161239
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0225071
[01/10/2024-10:51:23] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.335375 seconds. Fastest Tactic: 0x596666386c88024b Time: 0.00808635
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:23] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x596666386c88024b
[01/10/2024-10:51:23] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D
[01/10/2024-10:51:23] [V] [TRT] *************** Autotuning format combination: Int8(100352,49,7,1) -> Int8(25088,49,7,1) ***************
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:23] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:23] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:23] [V] [TRT] *************** Autotuning format combination: Int8(25088,49:4,7,1) -> Int8(6272,49:4,7,1) ***************
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0778971
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0809691
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.0611474
[01/10/2024-10:51:23] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.0083721 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0611474
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:23] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:23] [V] [TRT] *************** Autotuning format combination: Int8(25088,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0807497
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0776046
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.0621227
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.0852114
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0609524
[01/10/2024-10:51:23] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.0142267 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0609524
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:23] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:23] [V] [TRT] *************** Autotuning format combination: Int8(3136,49:32,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.0127756
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.0136312
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.0162702
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.0125318
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0606598
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0361326
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0337042
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0264533
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.0136711
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91 Time: 0.012605
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.0161077
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0348745
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254 Time: 0.0160752
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0177493
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.0120564
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0241859
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.0179931
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0601234
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0269653
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7 Time: 0.0177331
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.0132056
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0340846
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.0250392
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.0364983
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.0171154
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.0164165
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f Time: 0.00938972
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.0127512
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e Time: 0.0154917
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.026941
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1 Time: 0.00848457
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8 Time: 0.0114328
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.0136312
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0199314
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.0130194
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27 Time: 0.0119101
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0287013
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.0179383
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0271604
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0381074
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.0179931
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x2df835e0f3719216 Time: 0.0179383
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.0174405
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0160914
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e Time: 0.0330898
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.0346697
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0344357
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2 Time: 0.0138307
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0168879
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.0204173
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.0150235
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x7883d01837952a88 Time: 0.0344357
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.0200411
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d Time: 0.0145847
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.0182491
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f Time: 0.0127756
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x235fad4a7171cb36 Time: 0.0177331
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.0104908
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4 Time: 0.00979139
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0577829
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.0104176
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0610499
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610 Time: 0.0262095
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0236565
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4 Time: 0.0234475
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00997669
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.0096256
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.026624
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.0164815
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.0198949
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5 Time: 0.0263314
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0262095
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0203337
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0230296
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac Time: 0.0268434
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.0250149
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.0189074
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.012288
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.0158964
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9 Time: 0.041216
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.0139104
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.0157403
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.0132056
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7 Time: 0.0123124
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00871691
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.0096256
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.0106998
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0xa7ed996d55bb4583 Time: 0.0248686
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.0236356
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.0168391
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e Time: 0.019712
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0257463
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.0121295
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539 Time: 0.0156233
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.0346697
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x8bac1801ff920aa5 Time: 0.0159614
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049 Time: 0.018688
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.0116578
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0280137
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5 Time: 0.0332946
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539 Time: 0.0263802
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0210442
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.0196023
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e Time: 0.0194011
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0416549
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.0193646
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0269653
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.0161239
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107 Time: 0.0162702
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.0145262
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.0227579
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a Time: 0.0102296
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9f47704ddd29929e Time: 0.0597333
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.012032
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.0143653
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0603672
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x368150d268fe20d3 Time: 0.0233848
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.0129463
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.017213
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x850b80ab7d925385 Time: 0.0192
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x31276c9cc1913670 Time: 0.0344064
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.0232803
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0337335
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85 Time: 0.0105012
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9d607f92bc49571b Time: 0.0599771
[01/10/2024-10:51:23] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D (CaskConvolution[0x80000009]) profiling completed in 0.352002 seconds. Fastest Tactic: 0x3912ca79eb9a8be1 Time: 0.00848457
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:23] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x3912ca79eb9a8be1
[01/10/2024-10:51:23] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__814 + StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D
[01/10/2024-10:51:23] [V] [TRT] *************** Autotuning format combination: Int8(25088,49,7,1) -> Int8(25088,49,7,1) ***************
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__814 + StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:23] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__814 + StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:23] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:23] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1) -> Int8(6272,49:4,7,1) ***************
[01/10/2024-10:51:23] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:23] [V] [TRT] *************** Autotuning format combination: Int8(784,49:32,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:23] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu
[01/10/2024-10:51:23] [V] [TRT] *************** Autotuning format combination: Int8(25088,49,7,1), Int8(100352,49,7,1) -> Int8(100352,49,7,1) ***************
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:23] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:23] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:23] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1), Int8(25088,49:4,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d Time: 0.0267215
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9 Time: 0.0276724
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c Time: 0.0226325
[01/10/2024-10:51:23] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.00877533 seconds. Fastest Tactic: 0x8a10449e6d8c189c Time: 0.0226325
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:23] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8a10449e6d8c189c
[01/10/2024-10:51:23] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1), Int8(3136,49:32,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18 Time: 0.0275749
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78 Time: 0.0266728
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2 Time: 0.023134
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4 Time: 0.028789
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85 Time: 0.0226952
[01/10/2024-10:51:23] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.0143848 seconds. Fastest Tactic: 0x7a2c2a831965ff85 Time: 0.0226952
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:23] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7a2c2a831965ff85
[01/10/2024-10:51:23] [V] [TRT] *************** Autotuning format combination: Int8(784,49:32,7,1), Int8(3136,49:32,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650 Time: 0.00846736
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9 Time: 0.00866528
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d Time: 0.0109819
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98 Time: 0.00863946
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16 Tactic: 0x85047b8e34ed27fa Time: 0.0230296
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xc2b1c1cb14a83367 Time: 0.0171804
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1 Time: 0.0161727
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61 Time: 0.0132721
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x495da4d52da4de96 Time: 0.00890622
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb3718d2455749f91 Time: 0.00821638
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xc4dfbf32da2071d6 Time: 0.009024
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0xb12f6d354b73f48d Time: 0.0170504
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa086b8faeb42b254 Time: 0.009408
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af Time: 0.0112753
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363 Time: 0.00822451
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530 Time: 0.0137509
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x99d5ca59733a76be Time: 0.00959634
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x8e961765e9b5e3ee Time: 0.0225907
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26 Time: 0.0139636
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x429236a031bfe3e7 Time: 0.0102713
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830 Time: 0.00886319
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0 Time: 0.0168879
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x83e18e91fd965e25 Time: 0.0116466
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x1d9b1bf0b28cc357 Time: 0.016449
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xbd2f48ecbf742d59 Time: 0.0107207
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x296cf726a94959d6 Time: 0.00961585
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xcae7b5888d47fe1f Time: 0.00711924
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49 Time: 0.00840713
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb14c1f9154f6db4e Time: 0.00957684
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f Time: 0.01407
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3912ca79eb9a8be1 Time: 0.00715337
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2a3be0cb61f5a9c8 Time: 0.00752986
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52 Time: 0.0086997
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b Time: 0.0123002
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0 Time: 0.00893257
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x483ad1560c6e5e27 Time: 0.00798883
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5 Time: 0.0168879
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823 Time: 0.0108042
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4 Time: 0.0142429
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16 Tactic: 0xb81aeaba4cbc0d97 Time: 0.0166766
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb649da27d0e9770f Time: 0.00892343
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x2df835e0f3719216 Time: 0.00879435
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0x58be15b6f024df52 Time: 0.00926172
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780 Time: 0.0104699
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x716fcb85e712b30e Time: 0.0159939
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x00f33fe3dac544e3 Time: 0.0159451
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163 Time: 0.0168554
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x2640501019a61dc2 Time: 0.0086997
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df Time: 0.0109505
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b Time: 0.0125806
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00918857
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage1_warpsize4x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x7883d01837952a88 Time: 0.015243
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16 Tactic: 0xfaea3ed8eff52856 Time: 0.0101425
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xffb9fbd2bfa6c47d Time: 0.00886319
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x23cd610b930e6789 Time: 0.00914286
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x3ffcb62b1c6bb94f Time: 0.00845876
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x235fad4a7171cb36 Time: 0.00933486
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_conv_fprop_smallk_i8i8_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize16x32_stage4_warpsize2x4x1_r1s1_u1v1_hw0_c512_scalebias_beta_relu Tactic: 0x231735260b035c95 Time: 0.010658
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7 Time: 0.00730697
[01/10/2024-10:51:23] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x31de506085a332d4 Time: 0.00673579
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb Time: 0.0258194
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19 Time: 0.00748983
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16 Tactic: 0xfb1f0c938b867bc9 Time: 0.0232594
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xb2cc5e08f6b66610 Time: 0.0129585
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee Time: 0.0150821
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xe56748b5b7870ba4 Time: 0.0148187
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b Time: 0.00686846
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7 Time: 0.0079807
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75 Time: 0.0134716
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76 Time: 0.00998644
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0x81994a658cdf908d Time: 0.00996693
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xa9815e06b127c3d5 Time: 0.013179
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5 Time: 0.0134716
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d Time: 0.0128853
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e Time: 0.0132588
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xd25c9876338da5ac Time: 0.013711
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdd517393a24bd0f4 Time: 0.0117254
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239 Time: 0.0114103
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x322f337abc345152 Time: 0.00803759
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe Time: 0.00987916
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xfe7287378bfa0cc9 Time: 0.0202971
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50 Time: 0.00910629
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.0105012
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c Time: 0.00896914
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5314c155321a63a7 Time: 0.00840713
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee Time: 0.00735817
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc Time: 0.00730697
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940 Time: 0.00796444
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0xa7ed996d55bb4583 Time: 0.0114215
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0x2d01166056519c42 Time: 0.0114103
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49 Time: 0.0109192
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4f35593c356e2e7e Time: 0.0116691
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xc37005486323d39b Time: 0.0143214
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423 Time: 0.00844155
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x764ba04bb839d539 Time: 0.00938057
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xb0ee01628ff73107 Time: 0.015755
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage1_warpsize2x1x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x8bac1801ff920aa5 Time: 0.00886319
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xde3cb6dda9a9f049 Time: 0.0111515
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217 Time: 0.00793023
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393 Time: 0.0151113
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x70ff342513dcddd5 Time: 0.015755
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x596d7302ab180539 Time: 0.0132455
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02 Time: 0.0132189
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b Time: 0.0120686
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x5e4918ccf433630e Time: 0.0116578
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8 Time: 0.0210651
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xeb43af4c79f37067 Time: 0.00963535
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662 Time: 0.0141232
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d Time: 0.0100254
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x4b8c9beb00181107 Time: 0.00957684
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6 Time: 0.00905143
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x0807ee84b7a22819 Time: 0.012032
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xc22b2f91e37e472a Time: 0.00734354
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage1_warpsize4x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9f47704ddd29929e Time: 0.0220891
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266 Time: 0.00817575
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0 Time: 0.00961585
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_t1r1s1 Tactic: 0xcefcf2172874c12e Time: 0.0228206
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x368150d268fe20d3 Time: 0.0111627
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x521e608938d9d612 Time: 0.00936229
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xdb2ceb83bdb264c9 Time: 0.0102087
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x850b80ab7d925385 Time: 0.00956709
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x31276c9cc1913670 Time: 0.0152869
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage1_warpsize2x2x1_g1_tensor8x8x16 Tactic: 0xdfb027065697c23b Time: 0.0116353
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830 Time: 0.0164165
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xf207dff9d0b58a85 Time: 0.00773774
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm75_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage1_warpsize2x4x1_g1_tensor8x8x16_simple_t1r1s1 Tactic: 0x9d607f92bc49571b Time: 0.0225071
[01/10/2024-10:51:24] [V] [TRT] StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu (CaskConvolution[0x80000009]) profiling completed in 0.377038 seconds. Fastest Tactic: 0x31de506085a332d4 Time: 0.00673579
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:24] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x31de506085a332d4
[01/10/2024-10:51:24] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__822 + StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(100352,49,7,1) -> Int8(25088,49,7,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__822 + StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:24] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__822 + StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:24] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(25088,49:4,7,1) -> Int8(6272,49:4,7,1) ***************
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(25088,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(3136,49:32,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:24] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__826 + StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(25088,49,7,1) -> Int8(25088,49,7,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__826 + StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D (CaskConvolution[0x80000009])
[01/10/2024-10:51:24] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__826 + StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:24] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1) -> Int8(6272,49:4,7,1) ***************
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(784,49:32,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:24] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__830 + StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add + StatefulPartitionedCall/resnet50/conv5_block3_out/Relu
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(25088,49,7,1), Int8(100352,49,7,1) -> Int8(100352,49,7,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__830 + StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add + StatefulPartitionedCall/resnet50/conv5_block3_out/Relu (CaskConvolution[0x80000009])
[01/10/2024-10:51:24] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__830 + StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add + StatefulPartitionedCall/resnet50/conv5_block3_out/Relu (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:24] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1), Int8(25088,49:4,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1), Int8(3136,49:32,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(784,49:32,7,1), Int8(3136,49:32,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:24] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_avg_pool/Mean
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(25088,49:4,7,1) -> Int8(512,1:4,1,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean (CaskPooling[0x8000002f])
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kAVERAGE Tactic: 0xb4d3d3158ab4fbc4 Time: 0.00857062
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll2_tThreads49 Tactic: 0xcf4fe88af059d783 Time: 0.00490057
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll7_tThreads49 Tactic: 0xb60746ca0229b200 Time: 0.00950857
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll4_tThreads49 Tactic: 0x1088b9ecc9039b02 Time: 0.00609524
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll5_tThreads49 Tactic: 0xfcba7617eae0767f Time: 0.00729234
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll6_tThreads49 Tactic: 0x5a35893121ca5f7d Time: 0.00812699
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll3_tThreads49 Tactic: 0x237d2771d3ba3afe Time: 0.00546675
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll8_tThreads49 Tactic: 0x3ddeb40b14b91c85 Time: 0.0106684
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll1_tThreads49 Tactic: 0x69c017ac3b73fe81 Time: 0.00476892
[01/10/2024-10:51:24] [V] [TRT] StatefulPartitionedCall/resnet50/quant_avg_pool/Mean (CaskPooling[0x8000002f]) profiling completed in 0.0200207 seconds. Fastest Tactic: 0x69c017ac3b73fe81 Time: 0.00476892
[01/10/2024-10:51:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x69c017ac3b73fe81
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(3136,49:32,7,1) -> Int8(64,1:32,1,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean (CaskPooling[0x8000002f])
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_gap Tactic: 0xa3a1a62d21de759d Time: 0.00518792
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE Tactic: 0xd9375d43b61ffbcb Time: 0.00949943
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_gapSyncCta Tactic: 0x1340e8758429064c Time: 0.00706351
[01/10/2024-10:51:24] [V] [TRT] StatefulPartitionedCall/resnet50/quant_avg_pool/Mean (CaskPooling[0x8000002f]) profiling completed in 0.00651177 seconds. Fastest Tactic: 0xa3a1a62d21de759d Time: 0.00518792
[01/10/2024-10:51:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0xa3a1a62d21de759d
[01/10/2024-10:51:24] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(512,1:4,1,1) -> Float(1000,1,1,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (CaskConvolution[0x80000009])
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x69c4e2ca38eadce2 Time: 0.0661699
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0xff6944b17d5b2e32 Time: 0.0637806
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0xfe80445f7bb61a99 Time: 0.0766537
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm70_xmma_fprop_conv1x1_i8f32_f32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_simt_small_batch_bias_relu Tactic: 0xc073b0053ce90eac Time: 0.00863946
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xa4ae2d82115c3e83 Time: 0.0740206
[01/10/2024-10:51:24] [V] [TRT] StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (CaskConvolution[0x80000009]) profiling completed in 0.0213879 seconds. Fastest Tactic: 0xc073b0053ce90eac Time: 0.00863946
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:24] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc073b0053ce90eac
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(64,1:32,1,1) -> Float(1000,1,1,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (CaskConvolution[0x80000009])
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0x733ba2a91a48d431 Time: 0.0125928
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0xf04572b287451f42 Time: 0.0166603
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0x5e4f6d7c83746fd6 Time: 0.0109939
[01/10/2024-10:51:24] [V] [TRT] StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (CaskConvolution[0x80000009]) profiling completed in 0.0113329 seconds. Fastest Tactic: 0x5e4f6d7c83746fd6 Time: 0.0109939
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:24] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x5e4f6d7c83746fd6
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Int8(64,1:32,1,1) -> Float(32,1:32,1,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (CaskConvolution[0x80000009])
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x6986b0c6a136276e Time: 0.0289938
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x2468d082d0ff7c9a Time: 0.0104699
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x271b998fe31732ef Time: 0.0139503
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcd229658c16b33cd Time: 0.0326802
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xa2f15b0a75b7dcec Time: 0.0228415
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x91930a570b557437 Time: 0.0322121
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x991db9fd58152c33 Time: 0.0209816
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x844ea9c00f711f19 Time: 0.0131923
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x1e55f8b415964e81 Time: 0.0191634
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87 Time: 0.0159289
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5f1a472d416ff35e Time: 0.0125562
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xb5f710b331ba8377 Time: 0.0332946
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x748f926574b7bdc4 Time: 0.0331191
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xb86b920539eb9c79 Time: 0.0201143
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdf7e1bd6a496d667 Time: 0.0192366
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xbeb5d91e1874a437 Time: 0.018816
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa71946688cad8664 Time: 0.010543
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5bd8221bd57baf93 Time: 0.00867388
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8141573686849b61 Time: 0.0141365
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190 Time: 0.00848457
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x9ec201b34455146e Time: 0.00937143
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x9003f5f7ff9b1aec Time: 0.0321536
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x7720f198395e7d3d Time: 0.0139104
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x33a5c6dd086942c1 Time: 0.00927086
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x960e9baa2a6cad5b Time: 0.0103967
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x65fbe45b4cb1d8a5 Time: 0.00981089
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcf64a2ae51bf6b36 Time: 0.00979139
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xe742f4598442d2f1 Time: 0.0165303
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x60b880e28fee7a0c Time: 0.0324169
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x3f2b14dec582741e Time: 0.0120564
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x84942841d92b0552 Time: 0.0198766
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6e9c17a33c93d9b0 Time: 0.0127878
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x445983715412fbda Time: 0.00959634
[01/10/2024-10:51:24] [V] [TRT] StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (CaskConvolution[0x80000009]) profiling completed in 0.122606 seconds. Fastest Tactic: 0x6d377e4222886190 Time: 0.00848457
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (CaskFlattenConvolution[0x80000036])
[01/10/2024-10:51:24] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[01/10/2024-10:51:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x6d377e4222886190
[01/10/2024-10:51:24] [V] [TRT] =============== Computing costs for copied_squeeze_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Float(1000,1,1,1) -> Float(1000,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: copied_squeeze_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (Shuffle[0x8000000d])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00321828
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0104803
[01/10/2024-10:51:24] [V] [TRT] copied_squeeze_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (Shuffle[0x8000000d]) profiling completed in 0.106114 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00321828
[01/10/2024-10:51:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Float(250,1:4,250,250) -> Float(1000,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: copied_squeeze_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (Shuffle[0x8000000d])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00381883
[01/10/2024-10:51:24] [V] [TRT] copied_squeeze_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (Shuffle[0x8000000d]) profiling completed in 0.0030876 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00381883
[01/10/2024-10:51:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[01/10/2024-10:51:24] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/resnet50/quant_predictions/Softmax
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning format combination: Float(1000,1) -> Float(1000,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/resnet50/quant_predictions/Softmax (CaskSoftMaxV2[0x80000040])
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm50_xmma_softmax_trt_NCHW_FP32_Dim2_Threads256 Tactic: 0x48c115a824ac468d Time: 0.00518792
[01/10/2024-10:51:24] [V] [TRT] Tactic Name: sm50_xmma_softmax_trt_AxisW_FP32NCHW Tactic: 0x6d55c70c4c781969 Time: 0.00468586
[01/10/2024-10:51:24] [V] [TRT] StatefulPartitionedCall/resnet50/quant_predictions/Softmax (CaskSoftMaxV2[0x80000040]) profiling completed in 0.00499728 seconds. Fastest Tactic: 0x6d55c70c4c781969 Time: 0.00468586
[01/10/2024-10:51:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskSoftMaxV2 Tactic: 0x6d55c70c4c781969
[01/10/2024-10:51:24] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:24] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:24] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:24] [V] [TRT] =============== Computing reformatting costs: QuantLinearNode__838
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Float(158700,690,3,1) -> Int8(158700,690,3,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: QuantLinearNode__838 (Reformat[0x80000006])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00448457
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00930743
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00448
[01/10/2024-10:51:24] [V] [TRT] QuantLinearNode__838 (Reformat[0x80000006]) profiling completed in 0.0637071 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00448
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: QuantLinearNode__838 (MyelinReformat[0x80000035])
[01/10/2024-10:51:24] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[01/10/2024-10:51:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Float(158700,690,3,1) -> Int8(40020,690:4,3,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: QuantLinearNode__838 (Reformat[0x80000006])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00527673
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00648109
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00401473
[01/10/2024-10:51:24] [V] [TRT] QuantLinearNode__838 (Reformat[0x80000006]) profiling completed in 0.0364327 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00401473
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: QuantLinearNode__838 (MyelinReformat[0x80000035])
[01/10/2024-10:51:24] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[01/10/2024-10:51:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Float(158700,690,3,1) -> Int8(10350,1:16,45,15) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: QuantLinearNode__838 (Reformat[0x80000006])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00686846
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00650971
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00685453
[01/10/2024-10:51:24] [V] [TRT] QuantLinearNode__838 (Reformat[0x80000006]) profiling completed in 0.0062327 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00650971
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: QuantLinearNode__838 (MyelinReformat[0x80000035])
[01/10/2024-10:51:24] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[01/10/2024-10:51:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Float(158700,690,3,1) -> Int8(5520,690:32,3,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: QuantLinearNode__838 (Reformat[0x80000006])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0103445
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00646837
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0103236
[01/10/2024-10:51:24] [V] [TRT] QuantLinearNode__838 (Reformat[0x80000006]) profiling completed in 0.00584376 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00646837
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: QuantLinearNode__838 (MyelinReformat[0x80000035])
[01/10/2024-10:51:24] [V] [TRT] MyelinReformat has no valid tactics for this config, skipping
[01/10/2024-10:51:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[01/10/2024-10:51:24] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:24] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Int8(158700,690,3,1) -> Int8(40020,690:4,3,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00579877
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00848457
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00449371
[01/10/2024-10:51:24] [V] [TRT] Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00667075 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00449371
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Int8(158700,690,3,1) -> Int8(10350,1:16,45,15) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00773774
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00956709
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00772235
[01/10/2024-10:51:24] [V] [TRT] Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0059792 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00772235
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Int8(158700,690,3,1) -> Int8(5520,690:32,3,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0109192
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00702172
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0109505
[01/10/2024-10:51:24] [V] [TRT] Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00599923 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00702172
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Int8(40020,690:4,3,1) -> Int8(158700,690,3,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00567138
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00866528
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00692419
[01/10/2024-10:51:24] [V] [TRT] Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00636613 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00567138
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Int8(40020,690:4,3,1) -> Int8(10350,1:16,45,15) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00610133
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00833016
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00602819
[01/10/2024-10:51:24] [V] [TRT] Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00651927 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00602819
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Int8(40020,690:4,3,1) -> Int8(5520,690:32,3,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00728503
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00657621
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00444177
[01/10/2024-10:51:24] [V] [TRT] Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00682642 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00444177
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Int8(10350,1:16,45,15) -> Int8(158700,690,3,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00801321
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0102296
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00800508
[01/10/2024-10:51:24] [V] [TRT] Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00587243 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00800508
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Int8(10350,1:16,45,15) -> Int8(40020,690:4,3,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00809448
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00779164
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00804572
[01/10/2024-10:51:24] [V] [TRT] Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00609553 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00779164
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Int8(10350,1:16,45,15) -> Int8(5520,690:32,3,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0122149
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00729966
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0122027
[01/10/2024-10:51:24] [V] [TRT] Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00570247 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00729966
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Int8(5520,690:32,3,1) -> Int8(158700,690,3,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00659615
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011084
[01/10/2024-10:51:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00660945
[01/10/2024-10:51:24] [V] [TRT] Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00611416 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00659615
[01/10/2024-10:51:24] [V] [TRT] *************** Autotuning Reformat: Int8(5520,690:32,3,1) -> Int8(40020,690:4,3,1) ***************
[01/10/2024-10:51:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00566576
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00653631
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00439744
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00699032 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00439744
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(5520,690:32,3,1) -> Int8(10350,1:16,45,15) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00586313
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00775314
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00587484
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__838:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00661648 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00586313
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(158700,52900,230,1) -> Int8(52900,52900:4,230,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00588654
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00704261
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0042724
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00795563 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0042724
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(158700,52900,230,1) -> Int8(52900,52900:32,230,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0313929
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110502
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0313929
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0052261 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0110502
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(52900,52900:4,230,1) -> Int8(52900,52900:32,230,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0315099
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.012093
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00627756
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00562993 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00627756
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(52900,1:16,230,1) -> Int8(52900,52900:4,230,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00605867
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00781474
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00605867
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00667926 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00605867
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(52900,1:16,230,1) -> Int8(52900,52900:32,230,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.031627
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116128
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.031627
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00533041 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0116128
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(52900,52900:32,230,1) -> Int8(52900,52900:4,230,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00622668
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00788403
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0042767
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00690421 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0042767
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,12544:4,112,1) -> Int8(25088,12544:32,112,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/pool1_pad/Pad:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0194743
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00791483
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00533672
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/pool1_pad/Pad:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00624687 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00533672
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,12544:32,112,1) -> Int8(200704,12544:4,112,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/pool1_pad/Pad:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00740206
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00789943
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00500903
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/pool1_pad/Pad:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00657084 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00500903
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(207936,12996:4,114,1) -> Int8(25992,12996:32,114,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/pool1_pool/MaxPool:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0196389
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00802133
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00519837
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/pool1_pool/MaxPool:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00610414 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00519837
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25992,12996:32,114,1) -> Int8(207936,12996:4,114,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/pool1_pool/MaxPool:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0073728
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00795632
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00500903
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/pool1_pool/MaxPool:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00647821 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00500903
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(200704,3136,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__846:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00613181
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00769925
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00615009
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__846:0) (Reformat[0x80000006]) profiling completed in 0.00660462 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00613181
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__846:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0102818
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00642385
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00408346
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__846:0) (Reformat[0x80000006]) profiling completed in 0.00662291 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00408346
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(200704,3136,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__846:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00697295
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00625848
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00698689
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__846:0) (Reformat[0x80000006]) profiling completed in 0.00623901 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00625848
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__846:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00546133
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00632209
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00433538
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__846:0) (Reformat[0x80000006]) profiling completed in 0.00700507 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00433538
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__846:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00610743
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00762995
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.004544
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__846:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00677695 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.004544
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__846:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0108878
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00625212
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0109296
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__846:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00577643 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00625212
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__846:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0102609
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00645565
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00407162
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__846:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0067131 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00407162
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__846:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00546133
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00630301
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00430252
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__846:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00711071 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00430252
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136:4,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__858:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.019968
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00790713
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00615009
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__858:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00609163 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00615009
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,3136:32,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__858:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00743131
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00786863
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0050292
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__858:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0066791 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0050292
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136:4,56,1) -> Int8(802816,3136,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__862:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0119589
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00861365
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.012032
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__862:0) (Reformat[0x80000006]) profiling completed in 0.00555592 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00861365
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136:4,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__862:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0201691
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00788403
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00611352
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__862:0) (Reformat[0x80000006]) profiling completed in 0.0061105 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00611352
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,3136:32,56,1) -> Int8(802816,3136,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__862:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0129707
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00714606
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0129707
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__862:0) (Reformat[0x80000006]) profiling completed in 0.00587183 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00714606
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,3136:32,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__862:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00744594
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00786863
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00501911
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__862:0) (Reformat[0x80000006]) profiling completed in 0.0066573 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00501911
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(802816,3136,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__862:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0118716
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0086997
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00564888
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__862:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00625313 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00564888
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(802816,3136,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__862:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0232385
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00715337
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0232803
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__862:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0056803 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00715337
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136:4,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,3136:32,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(802816,3136,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(802816,3136,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136:4,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,3136:32,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136:4,56,1) -> Int8(802816,3136,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136:4,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,3136:32,56,1) -> Int8(802816,3136,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,3136:32,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(802816,3136,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(802816,3136,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136:4,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,3136:32,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(802816,3136,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(802816,3136,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136:4,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,3136:32,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136:4,56,1) -> Int8(802816,3136,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136:4,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,3136:32,56,1) -> Int8(802816,3136,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,3136:32,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(802816,3136,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(802816,3136,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136:4,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,3136:32,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__902:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0085362
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00637933
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00404317
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__902:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00676705 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00404317
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__902:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00517747
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00636025
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00430252
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__902:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00664888 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00430252
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(802816,3136,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(802816,3136,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136:4,56,1) -> Int8(25088,3136:32,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,3136:32,56,1) -> Int8(200704,3136:4,56,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__910:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0136977
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00701475
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00543424
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__910:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00626239 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00543424
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__910:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00618667
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00691723
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00487132
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__910:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00671198 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00487132
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(401408,784,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__918:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00815949
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00895086
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00811073
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__918:0) (Reformat[0x80000006]) profiling completed in 0.00592951 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00811073
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__918:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.013711
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00698689
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00543966
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__918:0) (Reformat[0x80000006]) profiling completed in 0.00628006 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00543966
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(401408,784,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__918:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00917029
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00704261
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00917943
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__918:0) (Reformat[0x80000006]) profiling completed in 0.00605014 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00704261
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__918:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00619276
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00690329
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0047933
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__918:0) (Reformat[0x80000006]) profiling completed in 0.00672561 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0047933
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__918:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00814324
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00900572
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00496867
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__918:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00629093 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00496867
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__918:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0157989
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00755296
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0158427
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__918:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00568299 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00755296
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(401408,784,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(401408,784,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(401408,784,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(401408,784,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(401408,784,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(401408,784,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__970:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00637297
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00634117
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00404317
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__970:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00699842 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00404317
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__970:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00478842
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00626484
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0036759
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__970:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00689789 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0036759
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(401408,784,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784:4,28,1) -> Int8(12544,784:32,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,784:32,28,1) -> Int8(100352,784:4,28,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__978:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.010201
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00676239
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00497876
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__978:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00649682 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00497876
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__978:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00540173
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00652966
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00413779
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__978:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00700463 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00413779
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__986:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00611962
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0088804
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0061379
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__986:0) (Reformat[0x80000006]) profiling completed in 0.0064979 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00611962
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__986:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0102087
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00675574
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00494849
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__986:0) (Reformat[0x80000006]) profiling completed in 0.00634845 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00494849
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__986:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00680229
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111402
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00681274
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__986:0) (Reformat[0x80000006]) profiling completed in 0.00608586 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00680229
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__986:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00540715
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00653631
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00411272
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__986:0) (Reformat[0x80000006]) profiling completed in 0.00703026 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00411272
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__986:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00611352
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00892343
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00453486
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__986:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00669669 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00453486
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__986:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.011264
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00740937
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0112527
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__986:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00580505 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00740937
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(200704,196,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__1070:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00518792
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00641113
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00384193
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__1070:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00724989 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00384193
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(6272,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__1070:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00459886
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00632209
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00344816
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__1070:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0071817 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00344816
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(6272,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(200704,196,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196:4,14,1) -> Int8(6272,196:32,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,196:32,14,1) -> Int8(50176,196:4,14,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49:4,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__1078:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00707744
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00660281
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00424659
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__1078:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00690083 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00424659
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,49:32,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__1078:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00492832
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00645565
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00375467
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__1078:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00729412 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00375467
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49:4,7,1) -> Int8(100352,49,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__1086:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00519837
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00851039
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00521926
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__1086:0) (Reformat[0x80000006]) profiling completed in 0.00669921 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00519837
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49:4,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__1086:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00707048
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00662275
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00429391
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__1086:0) (Reformat[0x80000006]) profiling completed in 0.00705511 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00429391
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,49:32,7,1) -> Int8(100352,49,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__1086:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00524539
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00806197
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00524016
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__1086:0) (Reformat[0x80000006]) profiling completed in 0.00676265 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00524016
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,49:32,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> QuantLinearNode__1086:0) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0049384
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00647473
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00377263
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(<in> -> QuantLinearNode__1086:0) (Reformat[0x80000006]) profiling completed in 0.00741707 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00377263
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,49,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__1086:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00518792
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00848457
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00450286
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__1086:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00682832 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00450286
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,49,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(QuantLinearNode__1086:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0068406
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00695902
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0068197
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(QuantLinearNode__1086:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00632365 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0068197
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49:4,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,49:32,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(6272,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(6272,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,49,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,49,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49:4,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,49:32,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49:4,7,1) -> Int8(100352,49,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49:4,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,49:32,7,1) -> Int8(100352,49,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,49:32,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,49,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,49,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49:4,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,49:32,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(6272,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(6272,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,49,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(100352,49,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49:4,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,49:32,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49:4,7,1) -> Int8(3136,49:32,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(3136,49:32,7,1) -> Int8(25088,49:4,7,1) ***************
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(512,1:4,1,1) -> Int8(64,1:32,1,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00450286
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00625212
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00336797
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00716054 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00336797
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Int8(64,1:32,1,1) -> Int8(512,1:4,1,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727:0 -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00450743
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00631573
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00333055
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727:0 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00722193 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00333055
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs: 
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Float(1000,1,1,1) -> Float(250,1:4,250,250) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd_out_tensor -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00385732
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00642385
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0036608
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd_out_tensor -> <out>) (Reformat[0x80000006]) profiling completed in 0.00738361 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0036608
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Float(32,1:32,1,1) -> Float(1000,1,1,1) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd_out_tensor -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00382268
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00620495
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00382653
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd_out_tensor -> <out>) (Reformat[0x80000006]) profiling completed in 0.00716075 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00382268
[01/10/2024-10:51:25] [V] [TRT] *************** Autotuning Reformat: Float(32,1:32,1,1) -> Float(250,1:4,250,250) ***************
[01/10/2024-10:51:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd_out_tensor -> <out>) (Reformat[0x80000006])
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00387064
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00645565
[01/10/2024-10:51:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00388646
[01/10/2024-10:51:25] [V] [TRT] Optimizer Reformat(StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd_out_tensor -> <out>) (Reformat[0x80000006]) profiling completed in 0.00708071 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00387064
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] =============== Computing reformatting costs
[01/10/2024-10:51:25] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727:0) from Int8(64,1:32,1,1) to Int8(512,1:4,1,1)
[01/10/2024-10:51:25] [V] [TRT] Formats and tactics selection completed in 11.8022 seconds.
[01/10/2024-10:51:25] [V] [TRT] After reformat layers: 63 layers
[01/10/2024-10:51:25] [V] [TRT] Total number of blocks in pre-optimized block assignment: 63
[01/10/2024-10:51:25] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd Host Persistent: 4592 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/pool1_pool/MaxPool Host Persistent: 3984 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__646 + StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__650 + StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add + StatefulPartitionedCall/resnet50/conv2_block2_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__654 + StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__658 + StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__662 + StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add + StatefulPartitionedCall/resnet50/conv2_block3_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__686 + StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__694 + StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__698 + StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__702 + StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add + StatefulPartitionedCall/resnet50/conv3_block3_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__706 + StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__710 + StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__714 + StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add + StatefulPartitionedCall/resnet50/conv3_block4_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__738 + StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__746 + StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__750 + StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__754 + StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add + StatefulPartitionedCall/resnet50/conv4_block3_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__758 + StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__762 + StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__766 + StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add + StatefulPartitionedCall/resnet50/conv4_block4_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__770 + StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__774 + StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__778 + StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add + StatefulPartitionedCall/resnet50/conv4_block5_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__782 + StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__786 + StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__790 + StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add + StatefulPartitionedCall/resnet50/conv4_block6_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__814 + StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__822 + StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__826 + StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__830 + StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add + StatefulPartitionedCall/resnet50/conv5_block3_out/Relu Host Persistent: 4912 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean Host Persistent: 3984 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd Host Persistent: 5168 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Layer: StatefulPartitionedCall/resnet50/quant_predictions/Softmax Host Persistent: 1776 Device Persistent: 0 Scratch Memory: 0
[01/10/2024-10:51:25] [V] [TRT] Skipped printing memory information for 6 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.
[01/10/2024-10:51:25] [I] [TRT] Total Host Persistent Memory: 274928
[01/10/2024-10:51:25] [I] [TRT] Total Device Persistent Memory: 0
[01/10/2024-10:51:25] [I] [TRT] Total Scratch Memory: 0
[01/10/2024-10:51:25] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 123 MiB, GPU 25 MiB
[01/10/2024-10:51:25] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 62 steps to complete.
[01/10/2024-10:51:25] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.637614ms to assign 3 blocks to 62 nodes requiring 2036224 bytes.
[01/10/2024-10:51:25] [V] [TRT] Total number of blocks in optimized block assignment: 3
[01/10/2024-10:51:25] [I] [TRT] Total Activation Memory: 2036224
[01/10/2024-10:51:25] [I] [TRT] (Sparsity) Layers eligible for sparse math:
[01/10/2024-10:51:25] [I] [TRT] (Sparsity) TRT inference plan picked sparse implementation for layers:
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd Set kernel index: 0
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/pool1_pool/MaxPool Set kernel index: 1
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D Set kernel index: 2
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D Set kernel index: 3
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D Set kernel index: 4
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu Set kernel index: 5
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D Set kernel index: 2
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__646 + StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D Set kernel index: 3
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__650 + StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add + StatefulPartitionedCall/resnet50/conv2_block2_out/Relu Set kernel index: 5
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__654 + StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D Set kernel index: 2
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__658 + StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D Set kernel index: 3
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__662 + StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add + StatefulPartitionedCall/resnet50/conv2_block3_out/Relu Set kernel index: 5
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D Set kernel index: 6
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D Set kernel index: 7
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D Set kernel index: 2
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu Set kernel index: 5
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D Set kernel index: 8
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__686 + StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D Set kernel index: 7
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu Set kernel index: 5
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__694 + StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D Set kernel index: 8
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__698 + StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D Set kernel index: 7
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__702 + StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add + StatefulPartitionedCall/resnet50/conv3_block3_out/Relu Set kernel index: 5
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__706 + StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D Set kernel index: 8
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__710 + StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D Set kernel index: 7
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__714 + StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add + StatefulPartitionedCall/resnet50/conv3_block4_out/Relu Set kernel index: 5
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D Set kernel index: 9
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D Set kernel index: 7
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D Set kernel index: 2
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu Set kernel index: 10
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D Set kernel index: 8
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__738 + StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D Set kernel index: 7
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu Set kernel index: 2
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__746 + StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D Set kernel index: 8
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__750 + StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D Set kernel index: 7
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__754 + StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add + StatefulPartitionedCall/resnet50/conv4_block3_out/Relu Set kernel index: 2
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__758 + StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D Set kernel index: 8
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__762 + StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D Set kernel index: 7
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__766 + StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add + StatefulPartitionedCall/resnet50/conv4_block4_out/Relu Set kernel index: 2
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__770 + StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D Set kernel index: 8
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__774 + StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D Set kernel index: 7
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__778 + StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add + StatefulPartitionedCall/resnet50/conv4_block5_out/Relu Set kernel index: 2
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__782 + StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D Set kernel index: 8
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__786 + StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D Set kernel index: 7
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__790 + StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add + StatefulPartitionedCall/resnet50/conv4_block6_out/Relu Set kernel index: 2
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D Set kernel index: 9
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D Set kernel index: 7
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D Set kernel index: 11
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu Set kernel index: 12
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D Set kernel index: 8
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__814 + StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D Set kernel index: 7
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu Set kernel index: 11
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__822 + StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D Set kernel index: 8
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__826 + StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D Set kernel index: 7
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__830 + StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add + StatefulPartitionedCall/resnet50/conv5_block3_out/Relu Set kernel index: 11
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_avg_pool/Mean Set kernel index: 13
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd Set kernel index: 14
[01/10/2024-10:51:25] [V] [TRT] Finalize: StatefulPartitionedCall/resnet50/quant_predictions/Softmax Set kernel index: 15
[01/10/2024-10:51:25] [V] [TRT] Total number of generated kernels selected for the engine: 16
[01/10/2024-10:51:25] [V] [TRT] Kernel: 0 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 1 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 2 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 3 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 4 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 5 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 6 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 7 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 8 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 9 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 10 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 11 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 12 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 13 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 14 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Kernel: 15 CASK_STATIC
[01/10/2024-10:51:25] [V] [TRT] Disabling unused tactic source: JIT_CONVOLUTIONS
[01/10/2024-10:51:25] [V] [TRT] Engine generation completed in 12.2188 seconds.
[01/10/2024-10:51:25] [V] [TRT] Deleting timing cache: 167 entries, served 307 hits since creation.
[01/10/2024-10:51:25] [V] [TRT] Engine Layer Information:
Layer(Slice): StatefulPartitionedCall/resnet50/conv1_pad/Pad, Tactic: 0x0000000000000000, input_1:0 (Float[1,224,224,3]) -> StatefulPartitionedCall/resnet50/conv1_pad/Pad:0 (Float[1,230,230,3])
Layer(Reformat): QuantLinearNode__838, Tactic: 0x0000000000000000, StatefulPartitionedCall/resnet50/conv1_pad/Pad:0 (Float[1,230,230,3]) -> QuantLinearNode__838:0 (Int8[1,230:4,230,3])
Layer(Shuffle): StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd__1121, Tactic: 0x0000000000000000, QuantLinearNode__838:0 (Int8[1,230:4,230,3]) -> StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 (Int8[1,3:4,230,230])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__622 + StatefulPartitionedCall/resnet50/quant_conv1_conv/BiasAdd, Tactic: 0x77e275948c7dace9, StatefulPartitionedCall/resnet50/quant_conv1_conv/LastValueQuant_1/QuantizeAndDequantizeV4:0 (Int8[1,3:4,230,230]) -> StatefulPartitionedCall/resnet50/pool1_pad/Pad:0 (Int8[1,64:32,112,112])
Layer(Padding): StatefulPartitionedCall/resnet50/pool1_pad/Pad, Tactic: 0x0000000000000000, StatefulPartitionedCall/resnet50/pool1_pad/Pad:0 (Int8[1,64:32,112,112]) -> StatefulPartitionedCall/resnet50/pool1_pool/MaxPool:0 (Int8[1,64:32,114,114])
Layer(CaskPooling): StatefulPartitionedCall/resnet50/pool1_pool/MaxPool, Tactic: 0x94215b398b8eb3ba, StatefulPartitionedCall/resnet50/pool1_pool/MaxPool:0 (Int8[1,64:32,114,114]) -> QuantLinearNode__846:0 (Int8[1,64:32,56,56])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__630 + StatefulPartitionedCall/resnet50/quant_conv2_block1_1_conv/Conv2D, Tactic: 0xcb4e43bfc9c62daf, QuantLinearNode__846:0 (Int8[1,64:32,56,56]) -> QuantLinearNode__850:0 (Int8[1,64:32,56,56])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__634 + StatefulPartitionedCall/resnet50/quant_conv2_block1_2_conv/Conv2D, Tactic: 0x2f34f689bfca5071, QuantLinearNode__850:0 (Int8[1,64:32,56,56]) -> QuantLinearNode__854:0 (Int8[1,64:32,56,56])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__638 + StatefulPartitionedCall/resnet50/quant_conv2_block1_3_conv/Conv2D, Tactic: 0x834cbca762798069, QuantLinearNode__854:0 (Int8[1,64:32,56,56]) -> QuantLinearNode__858:0 (Int8[1,256:32,56,56])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__626 + StatefulPartitionedCall/resnet50/quant_conv2_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block1_add/add + StatefulPartitionedCall/resnet50/conv2_block1_out/Relu, Tactic: 0xeb306d27e3a7ca01, QuantLinearNode__846:0 (Int8[1,64:32,56,56]), QuantLinearNode__858:0 (Int8[1,256:32,56,56]) -> QuantLinearNode__862:0 (Int8[1,256:32,56,56])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__642 + StatefulPartitionedCall/resnet50/quant_conv2_block2_1_conv/Conv2D, Tactic: 0xcb4e43bfc9c62daf, QuantLinearNode__862:0 (Int8[1,256:32,56,56]) -> QuantLinearNode__870:0 (Int8[1,64:32,56,56])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__646 + StatefulPartitionedCall/resnet50/quant_conv2_block2_2_conv/Conv2D, Tactic: 0x2f34f689bfca5071, QuantLinearNode__870:0 (Int8[1,64:32,56,56]) -> QuantLinearNode__874:0 (Int8[1,64:32,56,56])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__650 + StatefulPartitionedCall/resnet50/quant_conv2_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block2_add/add + StatefulPartitionedCall/resnet50/conv2_block2_out/Relu, Tactic: 0xeb306d27e3a7ca01, QuantLinearNode__874:0 (Int8[1,64:32,56,56]), QuantLinearNode__862:0 (Int8[1,256:32,56,56]) -> QuantLinearNode__882:0 (Int8[1,256:32,56,56])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__654 + StatefulPartitionedCall/resnet50/quant_conv2_block3_1_conv/Conv2D, Tactic: 0xcb4e43bfc9c62daf, QuantLinearNode__882:0 (Int8[1,256:32,56,56]) -> QuantLinearNode__886:0 (Int8[1,64:32,56,56])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__658 + StatefulPartitionedCall/resnet50/quant_conv2_block3_2_conv/Conv2D, Tactic: 0x2f34f689bfca5071, QuantLinearNode__886:0 (Int8[1,64:32,56,56]) -> QuantLinearNode__890:0 (Int8[1,64:32,56,56])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__662 + StatefulPartitionedCall/resnet50/quant_conv2_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv2_block3_add/add + StatefulPartitionedCall/resnet50/conv2_block3_out/Relu, Tactic: 0xeb306d27e3a7ca01, QuantLinearNode__890:0 (Int8[1,64:32,56,56]), QuantLinearNode__882:0 (Int8[1,256:32,56,56]) -> QuantLinearNode__898:0 (Int8[1,256:32,56,56])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__670 + StatefulPartitionedCall/resnet50/quant_conv3_block1_1_conv/Conv2D, Tactic: 0xb840759575017742, QuantLinearNode__898:0 (Int8[1,256:32,56,56]) -> QuantLinearNode__902:0 (Int8[1,128:32,28,28])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__674 + StatefulPartitionedCall/resnet50/quant_conv3_block1_2_conv/Conv2D, Tactic: 0x4749124f62d8bd23, QuantLinearNode__902:0 (Int8[1,128:32,28,28]) -> QuantLinearNode__906:0 (Int8[1,128:32,28,28])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__678 + StatefulPartitionedCall/resnet50/quant_conv3_block1_3_conv/Conv2D, Tactic: 0xcb4e43bfc9c62daf, QuantLinearNode__906:0 (Int8[1,128:32,28,28]) -> QuantLinearNode__910:0 (Int8[1,512:32,28,28])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__666 + StatefulPartitionedCall/resnet50/quant_conv3_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block1_add/add + StatefulPartitionedCall/resnet50/conv3_block1_out/Relu, Tactic: 0xeb306d27e3a7ca01, QuantLinearNode__898:0 (Int8[1,256:32,56,56]), QuantLinearNode__910:0 (Int8[1,512:32,28,28]) -> QuantLinearNode__918:0 (Int8[1,512:32,28,28])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__682 + StatefulPartitionedCall/resnet50/quant_conv3_block2_1_conv/Conv2D, Tactic: 0x3912ca79eb9a8be1, QuantLinearNode__918:0 (Int8[1,512:32,28,28]) -> QuantLinearNode__922:0 (Int8[1,128:32,28,28])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__686 + StatefulPartitionedCall/resnet50/quant_conv3_block2_2_conv/Conv2D, Tactic: 0x4749124f62d8bd23, QuantLinearNode__922:0 (Int8[1,128:32,28,28]) -> QuantLinearNode__926:0 (Int8[1,128:32,28,28])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__690 + StatefulPartitionedCall/resnet50/quant_conv3_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block2_add/add + StatefulPartitionedCall/resnet50/conv3_block2_out/Relu, Tactic: 0xeb306d27e3a7ca01, QuantLinearNode__926:0 (Int8[1,128:32,28,28]), QuantLinearNode__918:0 (Int8[1,512:32,28,28]) -> QuantLinearNode__930:0 (Int8[1,512:32,28,28])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__694 + StatefulPartitionedCall/resnet50/quant_conv3_block3_1_conv/Conv2D, Tactic: 0x3912ca79eb9a8be1, QuantLinearNode__930:0 (Int8[1,512:32,28,28]) -> QuantLinearNode__938:0 (Int8[1,128:32,28,28])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__698 + StatefulPartitionedCall/resnet50/quant_conv3_block3_2_conv/Conv2D, Tactic: 0x4749124f62d8bd23, QuantLinearNode__938:0 (Int8[1,128:32,28,28]) -> QuantLinearNode__942:0 (Int8[1,128:32,28,28])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__702 + StatefulPartitionedCall/resnet50/quant_conv3_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block3_add/add + StatefulPartitionedCall/resnet50/conv3_block3_out/Relu, Tactic: 0xeb306d27e3a7ca01, QuantLinearNode__942:0 (Int8[1,128:32,28,28]), QuantLinearNode__930:0 (Int8[1,512:32,28,28]) -> QuantLinearNode__946:0 (Int8[1,512:32,28,28])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__706 + StatefulPartitionedCall/resnet50/quant_conv3_block4_1_conv/Conv2D, Tactic: 0x3912ca79eb9a8be1, QuantLinearNode__946:0 (Int8[1,512:32,28,28]) -> QuantLinearNode__954:0 (Int8[1,128:32,28,28])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__710 + StatefulPartitionedCall/resnet50/quant_conv3_block4_2_conv/Conv2D, Tactic: 0x4749124f62d8bd23, QuantLinearNode__954:0 (Int8[1,128:32,28,28]) -> QuantLinearNode__958:0 (Int8[1,128:32,28,28])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__714 + StatefulPartitionedCall/resnet50/quant_conv3_block4_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv3_block4_add/add + StatefulPartitionedCall/resnet50/conv3_block4_out/Relu, Tactic: 0xeb306d27e3a7ca01, QuantLinearNode__958:0 (Int8[1,128:32,28,28]), QuantLinearNode__946:0 (Int8[1,512:32,28,28]) -> QuantLinearNode__966:0 (Int8[1,512:32,28,28])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__722 + StatefulPartitionedCall/resnet50/quant_conv4_block1_1_conv/Conv2D, Tactic: 0xcddae68de84cc6ee, QuantLinearNode__966:0 (Int8[1,512:32,28,28]) -> QuantLinearNode__970:0 (Int8[1,256:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__726 + StatefulPartitionedCall/resnet50/quant_conv4_block1_2_conv/Conv2D, Tactic: 0x4749124f62d8bd23, QuantLinearNode__970:0 (Int8[1,256:32,14,14]) -> QuantLinearNode__974:0 (Int8[1,256:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__730 + StatefulPartitionedCall/resnet50/quant_conv4_block1_3_conv/Conv2D, Tactic: 0xcb4e43bfc9c62daf, QuantLinearNode__974:0 (Int8[1,256:32,14,14]) -> QuantLinearNode__978:0 (Int8[1,1024:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__718 + StatefulPartitionedCall/resnet50/quant_conv4_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block1_add/add + StatefulPartitionedCall/resnet50/conv4_block1_out/Relu, Tactic: 0x311b82feb19aef19, QuantLinearNode__966:0 (Int8[1,512:32,28,28]), QuantLinearNode__978:0 (Int8[1,1024:32,14,14]) -> QuantLinearNode__986:0 (Int8[1,1024:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__734 + StatefulPartitionedCall/resnet50/quant_conv4_block2_1_conv/Conv2D, Tactic: 0x3912ca79eb9a8be1, QuantLinearNode__986:0 (Int8[1,1024:32,14,14]) -> QuantLinearNode__990:0 (Int8[1,256:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__738 + StatefulPartitionedCall/resnet50/quant_conv4_block2_2_conv/Conv2D, Tactic: 0x4749124f62d8bd23, QuantLinearNode__990:0 (Int8[1,256:32,14,14]) -> QuantLinearNode__994:0 (Int8[1,256:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__742 + StatefulPartitionedCall/resnet50/quant_conv4_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block2_add/add + StatefulPartitionedCall/resnet50/conv4_block2_out/Relu, Tactic: 0xcb4e43bfc9c62daf, QuantLinearNode__994:0 (Int8[1,256:32,14,14]), QuantLinearNode__986:0 (Int8[1,1024:32,14,14]) -> QuantLinearNode__1002:0 (Int8[1,1024:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__746 + StatefulPartitionedCall/resnet50/quant_conv4_block3_1_conv/Conv2D, Tactic: 0x3912ca79eb9a8be1, QuantLinearNode__1002:0 (Int8[1,1024:32,14,14]) -> QuantLinearNode__1006:0 (Int8[1,256:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__750 + StatefulPartitionedCall/resnet50/quant_conv4_block3_2_conv/Conv2D, Tactic: 0x4749124f62d8bd23, QuantLinearNode__1006:0 (Int8[1,256:32,14,14]) -> QuantLinearNode__1010:0 (Int8[1,256:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__754 + StatefulPartitionedCall/resnet50/quant_conv4_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block3_add/add + StatefulPartitionedCall/resnet50/conv4_block3_out/Relu, Tactic: 0xcb4e43bfc9c62daf, QuantLinearNode__1010:0 (Int8[1,256:32,14,14]), QuantLinearNode__1002:0 (Int8[1,1024:32,14,14]) -> QuantLinearNode__1018:0 (Int8[1,1024:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__758 + StatefulPartitionedCall/resnet50/quant_conv4_block4_1_conv/Conv2D, Tactic: 0x3912ca79eb9a8be1, QuantLinearNode__1018:0 (Int8[1,1024:32,14,14]) -> QuantLinearNode__1022:0 (Int8[1,256:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__762 + StatefulPartitionedCall/resnet50/quant_conv4_block4_2_conv/Conv2D, Tactic: 0x4749124f62d8bd23, QuantLinearNode__1022:0 (Int8[1,256:32,14,14]) -> QuantLinearNode__1026:0 (Int8[1,256:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__766 + StatefulPartitionedCall/resnet50/quant_conv4_block4_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block4_add/add + StatefulPartitionedCall/resnet50/conv4_block4_out/Relu, Tactic: 0xcb4e43bfc9c62daf, QuantLinearNode__1026:0 (Int8[1,256:32,14,14]), QuantLinearNode__1018:0 (Int8[1,1024:32,14,14]) -> QuantLinearNode__1034:0 (Int8[1,1024:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__770 + StatefulPartitionedCall/resnet50/quant_conv4_block5_1_conv/Conv2D, Tactic: 0x3912ca79eb9a8be1, QuantLinearNode__1034:0 (Int8[1,1024:32,14,14]) -> QuantLinearNode__1038:0 (Int8[1,256:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__774 + StatefulPartitionedCall/resnet50/quant_conv4_block5_2_conv/Conv2D, Tactic: 0x4749124f62d8bd23, QuantLinearNode__1038:0 (Int8[1,256:32,14,14]) -> QuantLinearNode__1042:0 (Int8[1,256:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__778 + StatefulPartitionedCall/resnet50/quant_conv4_block5_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block5_add/add + StatefulPartitionedCall/resnet50/conv4_block5_out/Relu, Tactic: 0xcb4e43bfc9c62daf, QuantLinearNode__1042:0 (Int8[1,256:32,14,14]), QuantLinearNode__1034:0 (Int8[1,1024:32,14,14]) -> QuantLinearNode__1050:0 (Int8[1,1024:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__782 + StatefulPartitionedCall/resnet50/quant_conv4_block6_1_conv/Conv2D, Tactic: 0x3912ca79eb9a8be1, QuantLinearNode__1050:0 (Int8[1,1024:32,14,14]) -> QuantLinearNode__1054:0 (Int8[1,256:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__786 + StatefulPartitionedCall/resnet50/quant_conv4_block6_2_conv/Conv2D, Tactic: 0x4749124f62d8bd23, QuantLinearNode__1054:0 (Int8[1,256:32,14,14]) -> QuantLinearNode__1058:0 (Int8[1,256:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__790 + StatefulPartitionedCall/resnet50/quant_conv4_block6_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv4_block6_add/add + StatefulPartitionedCall/resnet50/conv4_block6_out/Relu, Tactic: 0xcb4e43bfc9c62daf, QuantLinearNode__1058:0 (Int8[1,256:32,14,14]), QuantLinearNode__1050:0 (Int8[1,1024:32,14,14]) -> QuantLinearNode__1062:0 (Int8[1,1024:32,14,14])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__798 + StatefulPartitionedCall/resnet50/quant_conv5_block1_1_conv/Conv2D, Tactic: 0xcddae68de84cc6ee, QuantLinearNode__1062:0 (Int8[1,1024:32,14,14]) -> QuantLinearNode__1070:0 (Int8[1,512:32,7,7])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__802 + StatefulPartitionedCall/resnet50/quant_conv5_block1_2_conv/Conv2D, Tactic: 0x4749124f62d8bd23, QuantLinearNode__1070:0 (Int8[1,512:32,7,7]) -> QuantLinearNode__1074:0 (Int8[1,512:32,7,7])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__806 + StatefulPartitionedCall/resnet50/quant_conv5_block1_3_conv/Conv2D, Tactic: 0x31de506085a332d4, QuantLinearNode__1074:0 (Int8[1,512:32,7,7]) -> QuantLinearNode__1078:0 (Int8[1,2048:32,7,7])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__794 + StatefulPartitionedCall/resnet50/quant_conv5_block1_0_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block1_add/add + StatefulPartitionedCall/resnet50/conv5_block1_out/Relu, Tactic: 0x596666386c88024b, QuantLinearNode__1062:0 (Int8[1,1024:32,14,14]), QuantLinearNode__1078:0 (Int8[1,2048:32,7,7]) -> QuantLinearNode__1086:0 (Int8[1,2048:32,7,7])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__810 + StatefulPartitionedCall/resnet50/quant_conv5_block2_1_conv/Conv2D, Tactic: 0x3912ca79eb9a8be1, QuantLinearNode__1086:0 (Int8[1,2048:32,7,7]) -> QuantLinearNode__1090:0 (Int8[1,512:32,7,7])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__814 + StatefulPartitionedCall/resnet50/quant_conv5_block2_2_conv/Conv2D, Tactic: 0x4749124f62d8bd23, QuantLinearNode__1090:0 (Int8[1,512:32,7,7]) -> QuantLinearNode__1094:0 (Int8[1,512:32,7,7])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__818 + StatefulPartitionedCall/resnet50/quant_conv5_block2_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block2_add/add + StatefulPartitionedCall/resnet50/conv5_block2_out/Relu, Tactic: 0x31de506085a332d4, QuantLinearNode__1094:0 (Int8[1,512:32,7,7]), QuantLinearNode__1086:0 (Int8[1,2048:32,7,7]) -> QuantLinearNode__1102:0 (Int8[1,2048:32,7,7])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__822 + StatefulPartitionedCall/resnet50/quant_conv5_block3_1_conv/Conv2D, Tactic: 0x3912ca79eb9a8be1, QuantLinearNode__1102:0 (Int8[1,2048:32,7,7]) -> QuantLinearNode__1106:0 (Int8[1,512:32,7,7])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__826 + StatefulPartitionedCall/resnet50/quant_conv5_block3_2_conv/Conv2D, Tactic: 0x4749124f62d8bd23, QuantLinearNode__1106:0 (Int8[1,512:32,7,7]) -> QuantLinearNode__1110:0 (Int8[1,512:32,7,7])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__830 + StatefulPartitionedCall/resnet50/quant_conv5_block3_3_conv/Conv2D + StatefulPartitionedCall/resnet50/quant_conv5_block3_add/add + StatefulPartitionedCall/resnet50/conv5_block3_out/Relu, Tactic: 0x31de506085a332d4, QuantLinearNode__1110:0 (Int8[1,512:32,7,7]), QuantLinearNode__1102:0 (Int8[1,2048:32,7,7]) -> QuantLinearNode__1114:0 (Int8[1,2048:32,7,7])
Layer(CaskPooling): StatefulPartitionedCall/resnet50/quant_avg_pool/Mean, Tactic: 0xa3a1a62d21de759d, QuantLinearNode__1114:0 (Int8[1,2048:32,7,7]) -> StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727:0 (Int8[1,2048:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd, Tactic: 0x0000000000000000, StatefulPartitionedCall/resnet50/quant_avg_pool/Mean_Squeeze__1727:0 (Int8[1,2048:32,1,1]) -> Reformatted Input Tensor 0 to StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (Int8[1,2048:4,1,1])
Layer(CaskConvolution): StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd, Tactic: 0xc073b0053ce90eac, Reformatted Input Tensor 0 to StatefulPartitionedCall/resnet50/quant_predictions/LastValueQuant/QuantizeAndDequantizeV4/ReadVariableOp:0 + QuantLinearNode__834 + transpose_before_StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/MatMul + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle] + unsqueeze_node_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 478) [Shuffle]_(Unnamed Layer* 478) [Shuffle]_output + StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd (Int8[1,2048:4,1,1]) -> StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd_out_tensor (Float[1,1000,1,1])
Layer(NoOp): copied_squeeze_after_StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd, Tactic: 0x0000000000000000, StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd_out_tensor (Float[1,1000,1,1]) -> StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd:0 (Float[1,1000])
Layer(CaskSoftMaxV2): StatefulPartitionedCall/resnet50/quant_predictions/Softmax, Tactic: 0x6d55c70c4c781969, StatefulPartitionedCall/resnet50/quant_predictions/BiasAdd:0 (Float[1,1000]) -> Identity:0 (Float[1,1000])
[01/10/2024-10:51:25] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +24, GPU +25, now: CPU 24, GPU 25 (MiB)
[01/10/2024-10:51:25] [V] [TRT] Adding 1 engine(s) to plan file.
[01/10/2024-10:51:26] [I] Engine built in 26.1341 sec.
[01/10/2024-10:51:26] [I] [TRT] Loaded engine size: 27 MiB
[01/10/2024-10:51:26] [V] [TRT] Deserialization required 20765 microseconds.
[01/10/2024-10:51:26] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +24, now: CPU 0, GPU 24 (MiB)
[01/10/2024-10:51:26] [I] Engine deserialized in 0.0239481 sec.
[01/10/2024-10:51:26] [V] [TRT] Total per-runner device persistent memory is 0
[01/10/2024-10:51:26] [V] [TRT] Total per-runner host persistent memory is 274928
[01/10/2024-10:51:26] [V] [TRT] Allocated activation device memory of size 2036224
[01/10/2024-10:51:26] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +2, now: CPU 0, GPU 26 (MiB)
[01/10/2024-10:51:26] [V] [TRT] CUDA lazy loading is enabled.
[01/10/2024-10:51:26] [I] Setting persistentCacheLimit to 0 bytes.
[01/10/2024-10:51:26] [V] Using enqueueV3.
[01/10/2024-10:51:26] [I] Using random values for input input_1:0
[01/10/2024-10:51:26] [I] Input binding for input_1:0 with dimensions 1x224x224x3 is created.
[01/10/2024-10:51:26] [I] Output binding for Identity:0 with dimensions 1x1000 is created.
[01/10/2024-10:51:26] [I] Starting inference
[01/10/2024-10:51:29] [I] Warmup completed 424 queries over 200 ms
[01/10/2024-10:51:29] [I] Timing trace has 6372 queries over 3.0013 s
[01/10/2024-10:51:29] [I] 
[01/10/2024-10:51:29] [I] === Trace details ===
[01/10/2024-10:51:29] [I] Trace averages of 10 runs:
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468274 ms - Host latency: 0.511591 ms (enqueue 0.195143 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467561 ms - Host latency: 0.511348 ms (enqueue 0.195329 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467247 ms - Host latency: 0.51062 ms (enqueue 0.194141 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46705 ms - Host latency: 0.510745 ms (enqueue 0.196265 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467969 ms - Host latency: 0.510947 ms (enqueue 0.194582 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467557 ms - Host latency: 0.511024 ms (enqueue 0.195767 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46817 ms - Host latency: 0.511313 ms (enqueue 0.194908 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467458 ms - Host latency: 0.510864 ms (enqueue 0.195015 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468068 ms - Host latency: 0.511153 ms (enqueue 0.195311 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.510901 ms (enqueue 0.193788 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467662 ms - Host latency: 0.511044 ms (enqueue 0.196391 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468378 ms - Host latency: 0.511395 ms (enqueue 0.193823 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46756 ms - Host latency: 0.510638 ms (enqueue 0.195114 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.511017 ms (enqueue 0.19498 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.510913 ms (enqueue 0.194656 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467459 ms - Host latency: 0.510764 ms (enqueue 0.196097 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467358 ms - Host latency: 0.510898 ms (enqueue 0.193872 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467245 ms - Host latency: 0.510663 ms (enqueue 0.196265 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468066 ms - Host latency: 0.511432 ms (enqueue 0.1948 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467355 ms - Host latency: 0.511166 ms (enqueue 0.194934 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467242 ms - Host latency: 0.510556 ms (enqueue 0.194891 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467349 ms - Host latency: 0.510641 ms (enqueue 0.194382 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467859 ms - Host latency: 0.511139 ms (enqueue 0.195676 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46756 ms - Host latency: 0.511148 ms (enqueue 0.194418 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468069 ms - Host latency: 0.511472 ms (enqueue 0.195987 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467862 ms - Host latency: 0.511514 ms (enqueue 0.194995 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468277 ms - Host latency: 0.511896 ms (enqueue 0.195389 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467563 ms - Host latency: 0.510916 ms (enqueue 0.195694 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467453 ms - Host latency: 0.51076 ms (enqueue 0.193802 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467661 ms - Host latency: 0.511282 ms (enqueue 0.195367 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46777 ms - Host latency: 0.511084 ms (enqueue 0.192941 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467767 ms - Host latency: 0.511154 ms (enqueue 0.195245 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467343 ms - Host latency: 0.510696 ms (enqueue 0.194418 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467346 ms - Host latency: 0.51055 ms (enqueue 0.193744 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467969 ms - Host latency: 0.511371 ms (enqueue 0.19563 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467361 ms - Host latency: 0.511206 ms (enqueue 0.19371 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467459 ms - Host latency: 0.510431 ms (enqueue 0.195844 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467657 ms - Host latency: 0.511282 ms (enqueue 0.19454 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467865 ms - Host latency: 0.511075 ms (enqueue 0.195361 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467462 ms - Host latency: 0.510846 ms (enqueue 0.195639 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467868 ms - Host latency: 0.511133 ms (enqueue 0.194647 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46756 ms - Host latency: 0.510956 ms (enqueue 0.195874 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467966 ms - Host latency: 0.511179 ms (enqueue 0.193335 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467758 ms - Host latency: 0.511267 ms (enqueue 0.195154 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467355 ms - Host latency: 0.510504 ms (enqueue 0.19393 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467664 ms - Host latency: 0.510928 ms (enqueue 0.195648 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.510959 ms (enqueue 0.196118 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467151 ms - Host latency: 0.51044 ms (enqueue 0.193738 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467764 ms - Host latency: 0.510626 ms (enqueue 0.196201 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467349 ms - Host latency: 0.510956 ms (enqueue 0.194232 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46817 ms - Host latency: 0.511502 ms (enqueue 0.195007 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467862 ms - Host latency: 0.512042 ms (enqueue 0.19444 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467661 ms - Host latency: 0.510602 ms (enqueue 0.195062 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467352 ms - Host latency: 0.510855 ms (enqueue 0.19559 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467453 ms - Host latency: 0.510941 ms (enqueue 0.193112 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467761 ms - Host latency: 0.511078 ms (enqueue 0.195425 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467972 ms - Host latency: 0.511258 ms (enqueue 0.194116 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467661 ms - Host latency: 0.510907 ms (enqueue 0.194177 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466937 ms - Host latency: 0.509833 ms (enqueue 0.194675 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467249 ms - Host latency: 0.51087 ms (enqueue 0.195502 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467764 ms - Host latency: 0.510965 ms (enqueue 0.197461 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467755 ms - Host latency: 0.510834 ms (enqueue 0.194 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467972 ms - Host latency: 0.511078 ms (enqueue 0.19577 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467352 ms - Host latency: 0.510941 ms (enqueue 0.194431 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467352 ms - Host latency: 0.510562 ms (enqueue 0.195172 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467459 ms - Host latency: 0.510934 ms (enqueue 0.195114 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468066 ms - Host latency: 0.511078 ms (enqueue 0.19426 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.510992 ms (enqueue 0.195343 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467963 ms - Host latency: 0.510907 ms (enqueue 0.193176 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466931 ms - Host latency: 0.510114 ms (enqueue 0.195605 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467151 ms - Host latency: 0.510175 ms (enqueue 0.19505 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467975 ms - Host latency: 0.511322 ms (enqueue 0.194769 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467657 ms - Host latency: 0.510962 ms (enqueue 0.195599 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467767 ms - Host latency: 0.511292 ms (enqueue 0.194495 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467761 ms - Host latency: 0.510944 ms (enqueue 0.195264 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467773 ms - Host latency: 0.511316 ms (enqueue 0.193488 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46756 ms - Host latency: 0.510791 ms (enqueue 0.196375 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.510657 ms (enqueue 0.195312 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467548 ms - Host latency: 0.511084 ms (enqueue 0.194507 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467242 ms - Host latency: 0.510895 ms (enqueue 0.195691 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467865 ms - Host latency: 0.511151 ms (enqueue 0.193774 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466834 ms - Host latency: 0.510254 ms (enqueue 0.196326 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.510809 ms (enqueue 0.193616 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467346 ms - Host latency: 0.510919 ms (enqueue 0.195343 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467358 ms - Host latency: 0.510852 ms (enqueue 0.195844 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46756 ms - Host latency: 0.510803 ms (enqueue 0.19389 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467035 ms - Host latency: 0.510785 ms (enqueue 0.195776 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467364 ms - Host latency: 0.510394 ms (enqueue 0.193579 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46734 ms - Host latency: 0.510358 ms (enqueue 0.195227 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467151 ms - Host latency: 0.510748 ms (enqueue 0.194745 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467261 ms - Host latency: 0.510938 ms (enqueue 0.194513 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.511121 ms (enqueue 0.195801 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467975 ms - Host latency: 0.510938 ms (enqueue 0.193524 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46817 ms - Host latency: 0.51142 ms (enqueue 0.195758 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468268 ms - Host latency: 0.511627 ms (enqueue 0.194183 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.510931 ms (enqueue 0.195392 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467352 ms - Host latency: 0.510803 ms (enqueue 0.194806 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46767 ms - Host latency: 0.511163 ms (enqueue 0.195166 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467041 ms - Host latency: 0.509851 ms (enqueue 0.196271 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467865 ms - Host latency: 0.510986 ms (enqueue 0.194104 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466949 ms - Host latency: 0.509912 ms (enqueue 0.195184 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467255 ms - Host latency: 0.510461 ms (enqueue 0.193933 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467773 ms - Host latency: 0.511072 ms (enqueue 0.195081 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468262 ms - Host latency: 0.511639 ms (enqueue 0.194641 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467352 ms - Host latency: 0.510663 ms (enqueue 0.194025 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46734 ms - Host latency: 0.510687 ms (enqueue 0.196057 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467871 ms - Host latency: 0.511035 ms (enqueue 0.193427 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467462 ms - Host latency: 0.510645 ms (enqueue 0.19563 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467566 ms - Host latency: 0.510992 ms (enqueue 0.194489 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467767 ms - Host latency: 0.511224 ms (enqueue 0.194818 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467249 ms - Host latency: 0.510663 ms (enqueue 0.196832 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466956 ms - Host latency: 0.510413 ms (enqueue 0.194165 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467865 ms - Host latency: 0.511273 ms (enqueue 0.19613 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467664 ms - Host latency: 0.511023 ms (enqueue 0.193384 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467047 ms - Host latency: 0.51012 ms (enqueue 0.195923 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467444 ms - Host latency: 0.510571 ms (enqueue 0.19516 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.510632 ms (enqueue 0.194647 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467761 ms - Host latency: 0.51134 ms (enqueue 0.195294 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467865 ms - Host latency: 0.51084 ms (enqueue 0.193536 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467041 ms - Host latency: 0.51073 ms (enqueue 0.195496 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467871 ms - Host latency: 0.511267 ms (enqueue 0.194287 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466949 ms - Host latency: 0.510114 ms (enqueue 0.19494 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467859 ms - Host latency: 0.51109 ms (enqueue 0.195111 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467053 ms - Host latency: 0.510352 ms (enqueue 0.193384 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467664 ms - Host latency: 0.511127 ms (enqueue 0.195911 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46745 ms - Host latency: 0.511304 ms (enqueue 0.194415 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467657 ms - Host latency: 0.511029 ms (enqueue 0.195624 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467462 ms - Host latency: 0.511737 ms (enqueue 0.194666 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.510663 ms (enqueue 0.195673 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.510938 ms (enqueue 0.195978 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467157 ms - Host latency: 0.510315 ms (enqueue 0.193573 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467957 ms - Host latency: 0.510956 ms (enqueue 0.196002 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467358 ms - Host latency: 0.51084 ms (enqueue 0.193762 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467364 ms - Host latency: 0.510675 ms (enqueue 0.19472 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468176 ms - Host latency: 0.511389 ms (enqueue 0.194818 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467139 ms - Host latency: 0.510632 ms (enqueue 0.194629 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466937 ms - Host latency: 0.510248 ms (enqueue 0.195667 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.510425 ms (enqueue 0.193378 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467963 ms - Host latency: 0.510846 ms (enqueue 0.195734 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467261 ms - Host latency: 0.510431 ms (enqueue 0.194287 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46767 ms - Host latency: 0.510931 ms (enqueue 0.195013 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467664 ms - Host latency: 0.510962 ms (enqueue 0.195245 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468073 ms - Host latency: 0.511737 ms (enqueue 0.194916 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467566 ms - Host latency: 0.510681 ms (enqueue 0.195959 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467352 ms - Host latency: 0.510626 ms (enqueue 0.194092 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467236 ms - Host latency: 0.510516 ms (enqueue 0.195294 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.510596 ms (enqueue 0.193903 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46745 ms - Host latency: 0.510602 ms (enqueue 0.195074 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467676 ms - Host latency: 0.510876 ms (enqueue 0.195465 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467358 ms - Host latency: 0.510706 ms (enqueue 0.193549 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468274 ms - Host latency: 0.511774 ms (enqueue 0.194696 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467041 ms - Host latency: 0.510077 ms (enqueue 0.194482 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466956 ms - Host latency: 0.510352 ms (enqueue 0.195685 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467865 ms - Host latency: 0.511121 ms (enqueue 0.195209 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467139 ms - Host latency: 0.510815 ms (enqueue 0.194147 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466742 ms - Host latency: 0.510382 ms (enqueue 0.196698 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467444 ms - Host latency: 0.511224 ms (enqueue 0.194574 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468079 ms - Host latency: 0.511597 ms (enqueue 0.196216 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467664 ms - Host latency: 0.511066 ms (enqueue 0.194525 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468274 ms - Host latency: 0.511182 ms (enqueue 0.195221 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.51098 ms (enqueue 0.195679 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467462 ms - Host latency: 0.511133 ms (enqueue 0.193475 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467358 ms - Host latency: 0.511053 ms (enqueue 0.195813 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.510919 ms (enqueue 0.194232 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467761 ms - Host latency: 0.511237 ms (enqueue 0.195386 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.510925 ms (enqueue 0.194525 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467871 ms - Host latency: 0.511267 ms (enqueue 0.194714 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46767 ms - Host latency: 0.511163 ms (enqueue 0.195978 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46767 ms - Host latency: 0.511084 ms (enqueue 0.193011 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467352 ms - Host latency: 0.510565 ms (enqueue 0.195428 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467462 ms - Host latency: 0.510571 ms (enqueue 0.194299 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46767 ms - Host latency: 0.510712 ms (enqueue 0.195239 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46806 ms - Host latency: 0.511389 ms (enqueue 0.195068 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467352 ms - Host latency: 0.510742 ms (enqueue 0.193616 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467969 ms - Host latency: 0.511072 ms (enqueue 0.195685 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467151 ms - Host latency: 0.510632 ms (enqueue 0.193994 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467444 ms - Host latency: 0.510669 ms (enqueue 0.196106 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467261 ms - Host latency: 0.510669 ms (enqueue 0.194434 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467529 ms - Host latency: 0.511377 ms (enqueue 0.194727 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467139 ms - Host latency: 0.510925 ms (enqueue 0.19574 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467944 ms - Host latency: 0.511084 ms (enqueue 0.193274 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467761 ms - Host latency: 0.51145 ms (enqueue 0.195728 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.511133 ms (enqueue 0.193396 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467053 ms - Host latency: 0.510242 ms (enqueue 0.195044 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467859 ms - Host latency: 0.510754 ms (enqueue 0.194434 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467676 ms - Host latency: 0.511645 ms (enqueue 0.193958 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46748 ms - Host latency: 0.51095 ms (enqueue 0.194543 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467908 ms - Host latency: 0.510999 ms (enqueue 0.193909 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467749 ms - Host latency: 0.510999 ms (enqueue 0.195984 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467163 ms - Host latency: 0.510596 ms (enqueue 0.193481 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467578 ms - Host latency: 0.51106 ms (enqueue 0.194946 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467566 ms - Host latency: 0.510815 ms (enqueue 0.195435 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467664 ms - Host latency: 0.510852 ms (enqueue 0.193884 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467883 ms - Host latency: 0.511487 ms (enqueue 0.195056 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.510742 ms (enqueue 0.193481 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.51084 ms (enqueue 0.195447 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467773 ms - Host latency: 0.510876 ms (enqueue 0.194177 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467468 ms - Host latency: 0.510425 ms (enqueue 0.194678 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467981 ms - Host latency: 0.511279 ms (enqueue 0.195593 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467566 ms - Host latency: 0.510681 ms (enqueue 0.194373 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467883 ms - Host latency: 0.510828 ms (enqueue 0.195618 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467786 ms - Host latency: 0.511157 ms (enqueue 0.193494 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467676 ms - Host latency: 0.511304 ms (enqueue 0.195178 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467371 ms - Host latency: 0.511279 ms (enqueue 0.193945 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.51084 ms (enqueue 0.194202 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467566 ms - Host latency: 0.511194 ms (enqueue 0.195728 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467664 ms - Host latency: 0.510889 ms (enqueue 0.192883 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467078 ms - Host latency: 0.510571 ms (enqueue 0.195703 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.510449 ms (enqueue 0.193262 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467249 ms - Host latency: 0.510864 ms (enqueue 0.194861 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467664 ms - Host latency: 0.511084 ms (enqueue 0.194849 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467334 ms - Host latency: 0.511206 ms (enqueue 0.193896 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467139 ms - Host latency: 0.510388 ms (enqueue 0.195898 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466846 ms - Host latency: 0.510376 ms (enqueue 0.193323 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467566 ms - Host latency: 0.51084 ms (enqueue 0.196033 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467578 ms - Host latency: 0.510413 ms (enqueue 0.195117 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467114 ms - Host latency: 0.51073 ms (enqueue 0.194568 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.510376 ms (enqueue 0.195264 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467957 ms - Host latency: 0.511511 ms (enqueue 0.194287 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467224 ms - Host latency: 0.51062 ms (enqueue 0.195056 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467444 ms - Host latency: 0.510522 ms (enqueue 0.193762 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467236 ms - Host latency: 0.510266 ms (enqueue 0.195239 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.510669 ms (enqueue 0.194275 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467773 ms - Host latency: 0.511365 ms (enqueue 0.193713 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467358 ms - Host latency: 0.510693 ms (enqueue 0.194702 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467566 ms - Host latency: 0.510815 ms (enqueue 0.193384 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467041 ms - Host latency: 0.510498 ms (enqueue 0.195435 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467468 ms - Host latency: 0.510791 ms (enqueue 0.194092 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467664 ms - Host latency: 0.510645 ms (enqueue 0.194531 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.510889 ms (enqueue 0.194788 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.511023 ms (enqueue 0.194458 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467542 ms - Host latency: 0.51062 ms (enqueue 0.196228 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467249 ms - Host latency: 0.510608 ms (enqueue 0.193884 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468262 ms - Host latency: 0.511523 ms (enqueue 0.1953 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467859 ms - Host latency: 0.511694 ms (enqueue 0.195056 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468152 ms - Host latency: 0.511499 ms (enqueue 0.195105 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467053 ms - Host latency: 0.510889 ms (enqueue 0.195227 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467761 ms - Host latency: 0.511218 ms (enqueue 0.192847 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467688 ms - Host latency: 0.511084 ms (enqueue 0.196448 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467664 ms - Host latency: 0.51095 ms (enqueue 0.19353 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467041 ms - Host latency: 0.510034 ms (enqueue 0.195068 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467444 ms - Host latency: 0.510925 ms (enqueue 0.194934 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.510474 ms (enqueue 0.19458 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46759 ms - Host latency: 0.510999 ms (enqueue 0.195898 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.510938 ms (enqueue 0.19281 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468103 ms - Host latency: 0.511755 ms (enqueue 0.195923 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.51106 ms (enqueue 0.19386 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467859 ms - Host latency: 0.510596 ms (enqueue 0.19458 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467432 ms - Host latency: 0.509033 ms (enqueue 0.194067 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467761 ms - Host latency: 0.509705 ms (enqueue 0.194385 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467664 ms - Host latency: 0.50957 ms (enqueue 0.196033 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467957 ms - Host latency: 0.509802 ms (enqueue 0.193872 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467542 ms - Host latency: 0.50946 ms (enqueue 0.195386 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467737 ms - Host latency: 0.509607 ms (enqueue 0.194666 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467468 ms - Host latency: 0.509436 ms (enqueue 0.195312 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467761 ms - Host latency: 0.509351 ms (enqueue 0.194568 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467371 ms - Host latency: 0.508862 ms (enqueue 0.19353 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468298 ms - Host latency: 0.50918 ms (enqueue 0.19519 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467859 ms - Host latency: 0.509631 ms (enqueue 0.193677 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468091 ms - Host latency: 0.509509 ms (enqueue 0.195654 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467773 ms - Host latency: 0.508948 ms (enqueue 0.19458 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467419 ms - Host latency: 0.509058 ms (enqueue 0.194421 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467444 ms - Host latency: 0.508936 ms (enqueue 0.196277 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467371 ms - Host latency: 0.509241 ms (enqueue 0.193555 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.509253 ms (enqueue 0.194519 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467859 ms - Host latency: 0.509033 ms (enqueue 0.192786 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467676 ms - Host latency: 0.509045 ms (enqueue 0.194678 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467053 ms - Host latency: 0.508923 ms (enqueue 0.193872 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467566 ms - Host latency: 0.509277 ms (enqueue 0.192993 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467664 ms - Host latency: 0.508997 ms (enqueue 0.194958 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467041 ms - Host latency: 0.508093 ms (enqueue 0.192334 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467151 ms - Host latency: 0.508508 ms (enqueue 0.194617 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467468 ms - Host latency: 0.508911 ms (enqueue 0.193298 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.509045 ms (enqueue 0.193579 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467151 ms - Host latency: 0.50852 ms (enqueue 0.194446 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467664 ms - Host latency: 0.509241 ms (enqueue 0.192859 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467053 ms - Host latency: 0.508814 ms (enqueue 0.194568 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.508459 ms (enqueue 0.193616 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467676 ms - Host latency: 0.509229 ms (enqueue 0.194446 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.509595 ms (enqueue 0.194019 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468079 ms - Host latency: 0.50968 ms (enqueue 0.194543 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467773 ms - Host latency: 0.508936 ms (enqueue 0.195386 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467139 ms - Host latency: 0.508984 ms (enqueue 0.192883 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467847 ms - Host latency: 0.508862 ms (enqueue 0.195129 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467542 ms - Host latency: 0.508557 ms (enqueue 0.193823 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468164 ms - Host latency: 0.509485 ms (enqueue 0.194678 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.508667 ms (enqueue 0.194177 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467078 ms - Host latency: 0.508325 ms (enqueue 0.193225 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467566 ms - Host latency: 0.508545 ms (enqueue 0.194751 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46748 ms - Host latency: 0.509387 ms (enqueue 0.193018 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467847 ms - Host latency: 0.509937 ms (enqueue 0.195898 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467542 ms - Host latency: 0.509558 ms (enqueue 0.193054 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468079 ms - Host latency: 0.509253 ms (enqueue 0.193994 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467883 ms - Host latency: 0.50907 ms (enqueue 0.19375 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467432 ms - Host latency: 0.508899 ms (enqueue 0.193445 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.509167 ms (enqueue 0.194104 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467749 ms - Host latency: 0.509143 ms (enqueue 0.192688 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467566 ms - Host latency: 0.509265 ms (enqueue 0.194434 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468066 ms - Host latency: 0.509473 ms (enqueue 0.193298 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.509131 ms (enqueue 0.193176 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467566 ms - Host latency: 0.509009 ms (enqueue 0.19425 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46626 ms - Host latency: 0.507556 ms (enqueue 0.193152 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466638 ms - Host latency: 0.507812 ms (enqueue 0.195996 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466528 ms - Host latency: 0.508203 ms (enqueue 0.193164 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466321 ms - Host latency: 0.508069 ms (enqueue 0.194885 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466553 ms - Host latency: 0.508069 ms (enqueue 0.195544 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466113 ms - Host latency: 0.507312 ms (enqueue 0.193164 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466138 ms - Host latency: 0.507336 ms (enqueue 0.194873 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466101 ms - Host latency: 0.507959 ms (enqueue 0.194092 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466528 ms - Host latency: 0.50813 ms (enqueue 0.194055 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466443 ms - Host latency: 0.507935 ms (enqueue 0.194971 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466614 ms - Host latency: 0.508301 ms (enqueue 0.193726 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466431 ms - Host latency: 0.507581 ms (enqueue 0.195337 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466663 ms - Host latency: 0.508081 ms (enqueue 0.194287 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466223 ms - Host latency: 0.507727 ms (enqueue 0.194922 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465601 ms - Host latency: 0.507275 ms (enqueue 0.195154 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466016 ms - Host latency: 0.507556 ms (enqueue 0.193115 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466675 ms - Host latency: 0.508313 ms (enqueue 0.194922 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466333 ms - Host latency: 0.507983 ms (enqueue 0.194861 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466614 ms - Host latency: 0.508032 ms (enqueue 0.194604 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466333 ms - Host latency: 0.507825 ms (enqueue 0.1953 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466125 ms - Host latency: 0.5073 ms (enqueue 0.193433 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466431 ms - Host latency: 0.50813 ms (enqueue 0.194641 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466626 ms - Host latency: 0.508313 ms (enqueue 0.193628 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466211 ms - Host latency: 0.507849 ms (enqueue 0.194641 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466321 ms - Host latency: 0.508301 ms (enqueue 0.195105 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466724 ms - Host latency: 0.508166 ms (enqueue 0.194238 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466516 ms - Host latency: 0.508057 ms (enqueue 0.195935 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467163 ms - Host latency: 0.508374 ms (enqueue 0.194629 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466333 ms - Host latency: 0.507654 ms (enqueue 0.194568 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466626 ms - Host latency: 0.507666 ms (enqueue 0.195044 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466125 ms - Host latency: 0.507947 ms (enqueue 0.193689 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46687 ms - Host latency: 0.508472 ms (enqueue 0.19563 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465918 ms - Host latency: 0.50708 ms (enqueue 0.194299 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466406 ms - Host latency: 0.507971 ms (enqueue 0.194287 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466431 ms - Host latency: 0.508118 ms (enqueue 0.195557 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466443 ms - Host latency: 0.507361 ms (enqueue 0.193018 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466467 ms - Host latency: 0.507397 ms (enqueue 0.196143 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466724 ms - Host latency: 0.507971 ms (enqueue 0.194812 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466931 ms - Host latency: 0.50791 ms (enqueue 0.193713 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466016 ms - Host latency: 0.506897 ms (enqueue 0.195215 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466541 ms - Host latency: 0.507263 ms (enqueue 0.193848 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466736 ms - Host latency: 0.507385 ms (enqueue 0.194995 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466443 ms - Host latency: 0.507459 ms (enqueue 0.193518 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466528 ms - Host latency: 0.507568 ms (enqueue 0.19436 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466943 ms - Host latency: 0.507861 ms (enqueue 0.195386 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466736 ms - Host latency: 0.507153 ms (enqueue 0.193213 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466846 ms - Host latency: 0.506274 ms (enqueue 0.196521 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465869 ms - Host latency: 0.505542 ms (enqueue 0.194287 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46582 ms - Host latency: 0.504687 ms (enqueue 0.194177 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466834 ms - Host latency: 0.504541 ms (enqueue 0.194873 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466431 ms - Host latency: 0.504883 ms (enqueue 0.192603 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466028 ms - Host latency: 0.504053 ms (enqueue 0.194885 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465808 ms - Host latency: 0.504028 ms (enqueue 0.193652 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466846 ms - Host latency: 0.504907 ms (enqueue 0.194165 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466345 ms - Host latency: 0.50481 ms (enqueue 0.195715 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466199 ms - Host latency: 0.504919 ms (enqueue 0.192944 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466248 ms - Host latency: 0.504602 ms (enqueue 0.195642 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46593 ms - Host latency: 0.504248 ms (enqueue 0.194116 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466431 ms - Host latency: 0.504871 ms (enqueue 0.192981 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466016 ms - Host latency: 0.504517 ms (enqueue 0.194006 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466248 ms - Host latency: 0.504456 ms (enqueue 0.194116 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466626 ms - Host latency: 0.504712 ms (enqueue 0.194946 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466309 ms - Host latency: 0.504565 ms (enqueue 0.193396 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466467 ms - Host latency: 0.504895 ms (enqueue 0.193298 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467334 ms - Host latency: 0.505762 ms (enqueue 0.194324 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467542 ms - Host latency: 0.505383 ms (enqueue 0.192688 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467151 ms - Host latency: 0.505566 ms (enqueue 0.195532 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467859 ms - Host latency: 0.506091 ms (enqueue 0.193921 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467444 ms - Host latency: 0.504883 ms (enqueue 0.194617 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466516 ms - Host latency: 0.503906 ms (enqueue 0.194458 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467273 ms - Host latency: 0.504639 ms (enqueue 0.193274 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467249 ms - Host latency: 0.504895 ms (enqueue 0.194495 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467261 ms - Host latency: 0.504919 ms (enqueue 0.192554 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467859 ms - Host latency: 0.505066 ms (enqueue 0.194434 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467773 ms - Host latency: 0.506201 ms (enqueue 0.193359 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467737 ms - Host latency: 0.505212 ms (enqueue 0.193298 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.505188 ms (enqueue 0.19519 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467859 ms - Host latency: 0.505237 ms (enqueue 0.192554 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467371 ms - Host latency: 0.505176 ms (enqueue 0.195349 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467468 ms - Host latency: 0.505139 ms (enqueue 0.192908 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.505017 ms (enqueue 0.194324 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467871 ms - Host latency: 0.50592 ms (enqueue 0.194556 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467969 ms - Host latency: 0.505115 ms (enqueue 0.193457 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467664 ms - Host latency: 0.50509 ms (enqueue 0.194373 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467639 ms - Host latency: 0.505054 ms (enqueue 0.192664 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467542 ms - Host latency: 0.505249 ms (enqueue 0.194287 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467078 ms - Host latency: 0.504285 ms (enqueue 0.193555 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467676 ms - Host latency: 0.504834 ms (enqueue 0.194153 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467871 ms - Host latency: 0.504883 ms (enqueue 0.194434 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467981 ms - Host latency: 0.50415 ms (enqueue 0.192432 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468005 ms - Host latency: 0.504224 ms (enqueue 0.194727 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467444 ms - Host latency: 0.503626 ms (enqueue 0.193359 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467334 ms - Host latency: 0.503711 ms (enqueue 0.194043 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467236 ms - Host latency: 0.503809 ms (enqueue 0.194214 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467383 ms - Host latency: 0.503516 ms (enqueue 0.193774 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.4677 ms - Host latency: 0.504053 ms (enqueue 0.1948 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467969 ms - Host latency: 0.504053 ms (enqueue 0.192383 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467334 ms - Host latency: 0.504321 ms (enqueue 0.194531 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467358 ms - Host latency: 0.503638 ms (enqueue 0.192725 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467627 ms - Host latency: 0.50332 ms (enqueue 0.193237 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467944 ms - Host latency: 0.504004 ms (enqueue 0.193457 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467871 ms - Host latency: 0.50376 ms (enqueue 0.192627 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467432 ms - Host latency: 0.50293 ms (enqueue 0.194385 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467847 ms - Host latency: 0.503687 ms (enqueue 0.192432 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467041 ms - Host latency: 0.502393 ms (enqueue 0.194702 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467358 ms - Host latency: 0.50332 ms (enqueue 0.193628 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467114 ms - Host latency: 0.502856 ms (enqueue 0.193115 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.503442 ms (enqueue 0.193872 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466895 ms - Host latency: 0.502515 ms (enqueue 0.192163 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467847 ms - Host latency: 0.503711 ms (enqueue 0.193823 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467773 ms - Host latency: 0.503809 ms (enqueue 0.191284 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467822 ms - Host latency: 0.503784 ms (enqueue 0.193945 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467847 ms - Host latency: 0.503613 ms (enqueue 0.193066 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467529 ms - Host latency: 0.503345 ms (enqueue 0.191992 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467407 ms - Host latency: 0.503198 ms (enqueue 0.193604 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467603 ms - Host latency: 0.503027 ms (enqueue 0.192627 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467871 ms - Host latency: 0.503418 ms (enqueue 0.194238 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467578 ms - Host latency: 0.503418 ms (enqueue 0.192578 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468018 ms - Host latency: 0.503418 ms (enqueue 0.193774 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.50332 ms (enqueue 0.194043 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.503247 ms (enqueue 0.19292 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467358 ms - Host latency: 0.502954 ms (enqueue 0.193726 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.503735 ms (enqueue 0.19209 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467578 ms - Host latency: 0.503247 ms (enqueue 0.194995 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467725 ms - Host latency: 0.503638 ms (enqueue 0.192822 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468188 ms - Host latency: 0.503906 ms (enqueue 0.192822 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467725 ms - Host latency: 0.503101 ms (enqueue 0.194629 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.50354 ms (enqueue 0.193115 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467627 ms - Host latency: 0.503516 ms (enqueue 0.194604 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467651 ms - Host latency: 0.503345 ms (enqueue 0.193188 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467065 ms - Host latency: 0.503003 ms (enqueue 0.193799 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467798 ms - Host latency: 0.503418 ms (enqueue 0.19314 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467554 ms - Host latency: 0.503101 ms (enqueue 0.192798 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467773 ms - Host latency: 0.503491 ms (enqueue 0.193799 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.503418 ms (enqueue 0.192065 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467676 ms - Host latency: 0.503125 ms (enqueue 0.194141 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467944 ms - Host latency: 0.503638 ms (enqueue 0.19248 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467456 ms - Host latency: 0.503662 ms (enqueue 0.193237 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467163 ms - Host latency: 0.502905 ms (enqueue 0.192969 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467505 ms - Host latency: 0.503296 ms (enqueue 0.192847 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.468262 ms - Host latency: 0.503906 ms (enqueue 0.193799 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467578 ms - Host latency: 0.503101 ms (enqueue 0.192432 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467065 ms - Host latency: 0.502563 ms (enqueue 0.193921 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467871 ms - Host latency: 0.503564 ms (enqueue 0.192798 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467578 ms - Host latency: 0.502832 ms (enqueue 0.193213 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467749 ms - Host latency: 0.503442 ms (enqueue 0.193262 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467261 ms - Host latency: 0.50332 ms (enqueue 0.192334 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467432 ms - Host latency: 0.503345 ms (enqueue 0.194043 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467236 ms - Host latency: 0.503101 ms (enqueue 0.192554 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466846 ms - Host latency: 0.502588 ms (enqueue 0.193311 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466211 ms - Host latency: 0.501782 ms (enqueue 0.19314 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.48396 ms - Host latency: 0.51936 ms (enqueue 0.188208 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465967 ms - Host latency: 0.501514 ms (enqueue 0.184424 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466626 ms - Host latency: 0.502246 ms (enqueue 0.185425 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466333 ms - Host latency: 0.50166 ms (enqueue 0.186377 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466406 ms - Host latency: 0.501758 ms (enqueue 0.183667 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465869 ms - Host latency: 0.501562 ms (enqueue 0.185937 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466357 ms - Host latency: 0.501855 ms (enqueue 0.184692 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466479 ms - Host latency: 0.50166 ms (enqueue 0.185425 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466626 ms - Host latency: 0.502246 ms (enqueue 0.185791 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466113 ms - Host latency: 0.501245 ms (enqueue 0.184424 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466113 ms - Host latency: 0.501416 ms (enqueue 0.185889 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46604 ms - Host latency: 0.501196 ms (enqueue 0.184814 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465894 ms - Host latency: 0.501367 ms (enqueue 0.185645 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466211 ms - Host latency: 0.501807 ms (enqueue 0.185522 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466797 ms - Host latency: 0.50188 ms (enqueue 0.183862 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466187 ms - Host latency: 0.50188 ms (enqueue 0.186621 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466284 ms - Host latency: 0.501562 ms (enqueue 0.185474 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467163 ms - Host latency: 0.502124 ms (enqueue 0.18457 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466016 ms - Host latency: 0.501562 ms (enqueue 0.186182 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466602 ms - Host latency: 0.502344 ms (enqueue 0.184058 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466455 ms - Host latency: 0.502319 ms (enqueue 0.186255 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.502954 ms - Host latency: 0.538403 ms (enqueue 0.225049 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466309 ms - Host latency: 0.501416 ms (enqueue 0.184058 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465991 ms - Host latency: 0.501538 ms (enqueue 0.18606 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46626 ms - Host latency: 0.501074 ms (enqueue 0.185498 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466895 ms - Host latency: 0.501904 ms (enqueue 0.184399 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466406 ms - Host latency: 0.501514 ms (enqueue 0.186157 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466528 ms - Host latency: 0.502246 ms (enqueue 0.184619 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466479 ms - Host latency: 0.501978 ms (enqueue 0.185864 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466138 ms - Host latency: 0.501953 ms (enqueue 0.185547 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46626 ms - Host latency: 0.501611 ms (enqueue 0.184644 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466162 ms - Host latency: 0.501685 ms (enqueue 0.185669 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466333 ms - Host latency: 0.501929 ms (enqueue 0.185205 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466431 ms - Host latency: 0.501465 ms (enqueue 0.185645 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466504 ms - Host latency: 0.501489 ms (enqueue 0.185864 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465942 ms - Host latency: 0.501489 ms (enqueue 0.184155 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466406 ms - Host latency: 0.501465 ms (enqueue 0.186523 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466504 ms - Host latency: 0.501978 ms (enqueue 0.185376 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466357 ms - Host latency: 0.501367 ms (enqueue 0.185083 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466846 ms - Host latency: 0.502393 ms (enqueue 0.186377 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465918 ms - Host latency: 0.500952 ms (enqueue 0.185254 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465894 ms - Host latency: 0.501147 ms (enqueue 0.18623 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.485474 ms - Host latency: 0.520679 ms (enqueue 0.185937 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466284 ms - Host latency: 0.502441 ms (enqueue 0.194336 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466846 ms - Host latency: 0.502344 ms (enqueue 0.192041 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.483936 ms - Host latency: 0.519751 ms (enqueue 0.193896 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46626 ms - Host latency: 0.501416 ms (enqueue 0.18501 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465796 ms - Host latency: 0.501343 ms (enqueue 0.185937 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465723 ms - Host latency: 0.500952 ms (enqueue 0.184521 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466162 ms - Host latency: 0.501538 ms (enqueue 0.185083 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466162 ms - Host latency: 0.50144 ms (enqueue 0.185449 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466284 ms - Host latency: 0.50144 ms (enqueue 0.184595 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46604 ms - Host latency: 0.501074 ms (enqueue 0.185767 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46582 ms - Host latency: 0.501147 ms (enqueue 0.184717 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465796 ms - Host latency: 0.500806 ms (enqueue 0.185596 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466797 ms - Host latency: 0.502051 ms (enqueue 0.186182 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466089 ms - Host latency: 0.501807 ms (enqueue 0.184131 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465967 ms - Host latency: 0.500952 ms (enqueue 0.18606 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466626 ms - Host latency: 0.501807 ms (enqueue 0.185107 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46687 ms - Host latency: 0.501904 ms (enqueue 0.184814 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46604 ms - Host latency: 0.501538 ms (enqueue 0.186011 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466455 ms - Host latency: 0.502319 ms (enqueue 0.183716 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466357 ms - Host latency: 0.501782 ms (enqueue 0.185522 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466016 ms - Host latency: 0.501221 ms (enqueue 0.184644 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466284 ms - Host latency: 0.501904 ms (enqueue 0.184619 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466479 ms - Host latency: 0.502173 ms (enqueue 0.186353 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466553 ms - Host latency: 0.502148 ms (enqueue 0.184033 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.500757 ms - Host latency: 0.536401 ms (enqueue 0.208862 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466748 ms - Host latency: 0.502222 ms (enqueue 0.186084 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466357 ms - Host latency: 0.50166 ms (enqueue 0.184595 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465747 ms - Host latency: 0.50061 ms (enqueue 0.184814 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466406 ms - Host latency: 0.50188 ms (enqueue 0.185303 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46582 ms - Host latency: 0.501099 ms (enqueue 0.184277 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465649 ms - Host latency: 0.501196 ms (enqueue 0.185937 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467041 ms - Host latency: 0.502344 ms (enqueue 0.185156 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465869 ms - Host latency: 0.501294 ms (enqueue 0.185107 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466553 ms - Host latency: 0.501733 ms (enqueue 0.185742 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466162 ms - Host latency: 0.501831 ms (enqueue 0.183765 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466333 ms - Host latency: 0.501855 ms (enqueue 0.186792 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466162 ms - Host latency: 0.50127 ms (enqueue 0.185181 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466089 ms - Host latency: 0.501221 ms (enqueue 0.184912 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466187 ms - Host latency: 0.501514 ms (enqueue 0.185718 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466187 ms - Host latency: 0.501538 ms (enqueue 0.183252 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465894 ms - Host latency: 0.500928 ms (enqueue 0.185962 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465747 ms - Host latency: 0.501123 ms (enqueue 0.185156 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465747 ms - Host latency: 0.501099 ms (enqueue 0.184595 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466333 ms - Host latency: 0.501538 ms (enqueue 0.185937 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465771 ms - Host latency: 0.501245 ms (enqueue 0.184473 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.47998 ms - Host latency: 0.515381 ms (enqueue 0.185889 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.483936 ms - Host latency: 0.519409 ms (enqueue 0.208667 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466431 ms - Host latency: 0.501611 ms (enqueue 0.185791 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46626 ms - Host latency: 0.501611 ms (enqueue 0.184741 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465967 ms - Host latency: 0.500928 ms (enqueue 0.185937 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466699 ms - Host latency: 0.502222 ms (enqueue 0.184546 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466992 ms - Host latency: 0.502344 ms (enqueue 0.185107 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466138 ms - Host latency: 0.501465 ms (enqueue 0.185449 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466455 ms - Host latency: 0.501807 ms (enqueue 0.184546 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466406 ms - Host latency: 0.501562 ms (enqueue 0.185571 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465918 ms - Host latency: 0.501392 ms (enqueue 0.183252 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465869 ms - Host latency: 0.501025 ms (enqueue 0.186353 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466553 ms - Host latency: 0.502222 ms (enqueue 0.185718 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466211 ms - Host latency: 0.5021 ms (enqueue 0.183618 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465771 ms - Host latency: 0.501318 ms (enqueue 0.185645 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465869 ms - Host latency: 0.501074 ms (enqueue 0.185034 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466138 ms - Host latency: 0.50105 ms (enqueue 0.18479 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466333 ms - Host latency: 0.501855 ms (enqueue 0.185522 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466382 ms - Host latency: 0.501367 ms (enqueue 0.184009 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466699 ms - Host latency: 0.502222 ms (enqueue 0.185767 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466309 ms - Host latency: 0.501953 ms (enqueue 0.184277 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466333 ms - Host latency: 0.501416 ms (enqueue 0.184766 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.482275 ms - Host latency: 0.517456 ms (enqueue 0.205078 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.484326 ms - Host latency: 0.519751 ms (enqueue 0.191333 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46604 ms - Host latency: 0.501855 ms (enqueue 0.183838 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466431 ms - Host latency: 0.501929 ms (enqueue 0.185181 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466333 ms - Host latency: 0.501587 ms (enqueue 0.184497 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466797 ms - Host latency: 0.502344 ms (enqueue 0.184863 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466504 ms - Host latency: 0.5021 ms (enqueue 0.185059 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46626 ms - Host latency: 0.501538 ms (enqueue 0.184082 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466626 ms - Host latency: 0.502075 ms (enqueue 0.185815 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465869 ms - Host latency: 0.501392 ms (enqueue 0.184448 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466528 ms - Host latency: 0.501953 ms (enqueue 0.184448 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466309 ms - Host latency: 0.502002 ms (enqueue 0.184839 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466675 ms - Host latency: 0.502002 ms (enqueue 0.183276 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46626 ms - Host latency: 0.501489 ms (enqueue 0.185571 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466724 ms - Host latency: 0.502368 ms (enqueue 0.183643 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466284 ms - Host latency: 0.501123 ms (enqueue 0.184131 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466089 ms - Host latency: 0.501782 ms (enqueue 0.185474 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466699 ms - Host latency: 0.501978 ms (enqueue 0.183521 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466016 ms - Host latency: 0.501587 ms (enqueue 0.185767 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466113 ms - Host latency: 0.501538 ms (enqueue 0.183716 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466479 ms - Host latency: 0.501904 ms (enqueue 0.184839 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465869 ms - Host latency: 0.501367 ms (enqueue 0.185571 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.50376 ms - Host latency: 0.539136 ms (enqueue 0.204834 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466382 ms - Host latency: 0.501904 ms (enqueue 0.203394 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465894 ms - Host latency: 0.501685 ms (enqueue 0.185913 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466479 ms - Host latency: 0.501392 ms (enqueue 0.184424 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466553 ms - Host latency: 0.502148 ms (enqueue 0.184985 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466333 ms - Host latency: 0.50144 ms (enqueue 0.184717 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466357 ms - Host latency: 0.50188 ms (enqueue 0.183862 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466211 ms - Host latency: 0.501636 ms (enqueue 0.185181 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466528 ms - Host latency: 0.501978 ms (enqueue 0.183374 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466455 ms - Host latency: 0.502148 ms (enqueue 0.184619 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466406 ms - Host latency: 0.501733 ms (enqueue 0.185278 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466553 ms - Host latency: 0.502026 ms (enqueue 0.18418 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465625 ms - Host latency: 0.50105 ms (enqueue 0.185986 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465869 ms - Host latency: 0.50144 ms (enqueue 0.184009 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.46626 ms - Host latency: 0.50144 ms (enqueue 0.185474 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465747 ms - Host latency: 0.500879 ms (enqueue 0.18562 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466235 ms - Host latency: 0.501489 ms (enqueue 0.183789 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466455 ms - Host latency: 0.501758 ms (enqueue 0.185278 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466626 ms - Host latency: 0.50166 ms (enqueue 0.184326 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466162 ms - Host latency: 0.501465 ms (enqueue 0.184644 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465894 ms - Host latency: 0.501099 ms (enqueue 0.185889 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465771 ms - Host latency: 0.500903 ms (enqueue 0.18374 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.480249 ms - Host latency: 0.515723 ms (enqueue 0.191211 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466431 ms - Host latency: 0.502295 ms (enqueue 0.191406 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466431 ms - Host latency: 0.501904 ms (enqueue 0.192993 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466064 ms - Host latency: 0.501758 ms (enqueue 0.191309 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466382 ms - Host latency: 0.501978 ms (enqueue 0.192773 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466162 ms - Host latency: 0.501538 ms (enqueue 0.192603 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465674 ms - Host latency: 0.50144 ms (enqueue 0.190967 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466724 ms - Host latency: 0.502417 ms (enqueue 0.193018 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466821 ms - Host latency: 0.502563 ms (enqueue 0.191797 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466479 ms - Host latency: 0.502441 ms (enqueue 0.192456 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466675 ms - Host latency: 0.502051 ms (enqueue 0.192139 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466553 ms - Host latency: 0.501685 ms (enqueue 0.191895 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466455 ms - Host latency: 0.501978 ms (enqueue 0.193652 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466357 ms - Host latency: 0.502344 ms (enqueue 0.191431 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466382 ms - Host latency: 0.5021 ms (enqueue 0.192261 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465747 ms - Host latency: 0.501538 ms (enqueue 0.192798 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466724 ms - Host latency: 0.502173 ms (enqueue 0.191406 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466675 ms - Host latency: 0.502051 ms (enqueue 0.19353 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466675 ms - Host latency: 0.502393 ms (enqueue 0.191406 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466064 ms - Host latency: 0.501904 ms (enqueue 0.192725 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467017 ms - Host latency: 0.502637 ms (enqueue 0.193677 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.467187 ms - Host latency: 0.502954 ms (enqueue 0.191821 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.465942 ms - Host latency: 0.501831 ms (enqueue 0.1927 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466284 ms - Host latency: 0.502295 ms (enqueue 0.192383 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466699 ms - Host latency: 0.502319 ms (enqueue 0.193066 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466309 ms - Host latency: 0.501929 ms (enqueue 0.193042 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466406 ms - Host latency: 0.502173 ms (enqueue 0.191382 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466138 ms - Host latency: 0.502271 ms (enqueue 0.193164 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466504 ms - Host latency: 0.502686 ms (enqueue 0.192676 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466528 ms - Host latency: 0.502661 ms (enqueue 0.193188 ms)
[01/10/2024-10:51:29] [I] Average on 10 runs - GPU latency: 0.466748 ms - Host latency: 0.502368 ms (enqueue 0.194116 ms)
[01/10/2024-10:51:29] [I] 
[01/10/2024-10:51:29] [I] === Performance summary ===
[01/10/2024-10:51:29] [I] Throughput: 2123.08 qps
[01/10/2024-10:51:29] [I] Latency: min = 0.497803 ms, max = 0.690918 ms, mean = 0.507114 ms, median = 0.50769 ms, percentile(90%) = 0.511719 ms, percentile(95%) = 0.512329 ms, percentile(99%) = 0.513428 ms
[01/10/2024-10:51:29] [I] Enqueue Time: min = 0.181396 ms, max = 0.387695 ms, mean = 0.19236 ms, median = 0.192871 ms, percentile(90%) = 0.198486 ms, percentile(95%) = 0.199707 ms, percentile(99%) = 0.201538 ms
[01/10/2024-10:51:29] [I] H2D Latency: min = 0.0285645 ms, max = 0.0439453 ms, mean = 0.0331865 ms, median = 0.03479 ms, percentile(90%) = 0.0369873 ms, percentile(95%) = 0.0371094 ms, percentile(99%) = 0.0373535 ms
[01/10/2024-10:51:29] [I] GPU Compute Time: min = 0.462891 ms, max = 0.65625 ms, mean = 0.467467 ms, median = 0.466949 ms, percentile(90%) = 0.468994 ms, percentile(95%) = 0.468994 ms, percentile(99%) = 0.470032 ms
[01/10/2024-10:51:29] [I] D2H Latency: min = 0.00512695 ms, max = 0.00845337 ms, mean = 0.00646731 ms, median = 0.0065918 ms, percentile(90%) = 0.00744629 ms, percentile(95%) = 0.00769043 ms, percentile(99%) = 0.00805664 ms
[01/10/2024-10:51:29] [I] Total Host Walltime: 3.0013 s
[01/10/2024-10:51:29] [I] Total GPU Compute Time: 2.9787 s
[01/10/2024-10:51:29] [W] * GPU compute time is unstable, with coefficient of variance = 1.74665%.
[01/10/2024-10:51:29] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.
[01/10/2024-10:51:29] [I] Explanations of the performance metrics are printed in the verbose logs.
[01/10/2024-10:51:29] [V] 
[01/10/2024-10:51:29] [V] === Explanations of the performance metrics ===
[01/10/2024-10:51:29] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[01/10/2024-10:51:29] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[01/10/2024-10:51:29] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[01/10/2024-10:51:29] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[01/10/2024-10:51:29] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[01/10/2024-10:51:29] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[01/10/2024-10:51:29] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[01/10/2024-10:51:29] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[01/10/2024-10:51:29] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8601] # trtexec --onnx=scripts/quantization/model_qat.onnx --int8 --sparsity=force --saveEngine=scripts/quantization/model_qat.engine --verbose
